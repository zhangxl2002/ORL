{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zhangxl2002/ORL/blob/main/T5_Ner_Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T11:46:03.615350Z",
     "iopub.status.busy": "2024-02-28T11:46:03.615160Z",
     "iopub.status.idle": "2024-02-28T11:46:03.618572Z",
     "shell.execute_reply": "2024-02-28T11:46:03.617968Z",
     "shell.execute_reply.started": "2024-02-28T11:46:03.615332Z"
    },
    "id": "4rfSWZLR6E7k",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr  9 18:19:01 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10          Off  | 00000000:00:08.0 Off |                    0 |\n",
      "|  0%   27C    P8    16W / 150W |      2MiB / 22731MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BlIYFZKgmOU"
   },
   "source": [
    "# Named Entity Recognition with T5\n",
    "\n",
    "This notebook shows how to finetune [T5 Model](https://https://huggingface.co/docs/transformers/model_doc/t5) for token classification or named entity recognition with pytorch lighning. In this demo, I used the T5-Small and cast the entities as a text using the text to text framework used in the t5 paper. During Eval the generated tokens are then split and classifies into their specific classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:14:23.741652Z",
     "iopub.status.busy": "2024-02-28T14:14:23.741327Z",
     "iopub.status.idle": "2024-02-28T14:14:27.411717Z",
     "shell.execute_reply": "2024-02-28T14:14:27.411232Z",
     "shell.execute_reply.started": "2024-02-28T14:14:23.741632Z"
    },
    "id": "cBQiMj-p5lfz",
    "outputId": "7802de39-2c8b-4e20-c061-164dcbb6af9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    MT5ForConditionalGeneration,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:14:29.473867Z",
     "iopub.status.busy": "2024-02-28T14:14:29.473454Z",
     "iopub.status.idle": "2024-02-28T14:14:29.527177Z",
     "shell.execute_reply": "2024-02-28T14:14:29.526681Z",
     "shell.execute_reply.started": "2024-02-28T14:14:29.473846Z"
    },
    "id": "0WqcwP916Dwq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:14:36.446536Z",
     "iopub.status.busy": "2024-02-28T14:14:36.446076Z",
     "iopub.status.idle": "2024-02-28T14:15:04.104154Z",
     "shell.execute_reply": "2024-02-28T14:15:04.103481Z",
     "shell.execute_reply.started": "2024-02-28T14:14:36.446513Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"zhangxl2002/mpqa_ORL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:15:30.477538Z",
     "iopub.status.busy": "2024-02-28T14:15:30.476989Z",
     "iopub.status.idle": "2024-02-28T14:15:30.751473Z",
     "shell.execute_reply": "2024-02-28T14:15:30.750974Z",
     "shell.execute_reply.started": "2024-02-28T14:15:30.477514Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['words', 'label_ids', 'labels', 'spans', 'dse'],\n",
      "        num_rows: 3549\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['words', 'label_ids', 'labels', 'spans', 'dse'],\n",
      "        num_rows: 893\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['words', 'label_ids', 'labels', 'spans', 'dse'],\n",
      "        num_rows: 1509\n",
      "    })\n",
      "})\n",
      "{'words': ['He', 'argued', 'that', 'had', 'the', 'West', 'not', 'continued', 'to', 'keep', 'alive', 'during', 'the', 'past', 'several', 'years', 'the', 'Cold', 'War', 'stereotype', 'of', 'a', 'threat', 'from', 'the', 'East', ',', 'but', 'would', 'have', 'concentrated', 'instead', 'on', 'terrorism', ',', 'the', 'common', 'enemy', ',', 'the', 'twin', 'towers', 'of', 'New', 'York', 'may', 'not', 'have', 'collapsed', '.'], 'label_ids': [1, 3, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0], 'labels': ['B-AGENT', 'B-DSE', 'O', 'O', 'B-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O'], 'spans': ['AGENT: He', 'TARGET: the West', 'TARGET: terrorism', 'TARGET: the twin towers of New York may not have collapsed'], 'dse': 'argued'}\n",
      "{'words': ['They', 'think', 'she', 'is', 'traveling', 'too', 'much', ',', 'while', 'internal', 'problems', 'sap', 'the', 'country', \"'s\", 'energy', ',', 'and', 'that', 'she', 'has', 'misplaced', 'strategic', 'priorities', 'in', 'her', 'overseas', 'visits', '.'], 'label_ids': [1, 3, 5, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': ['B-AGENT', 'B-DSE', 'B-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'spans': ['AGENT: They', 'TARGET: she', 'TARGET: internal problems', 'TARGET: she'], 'dse': 'think'}\n",
      "{'words': ['He', 'claims', 'that', 'he', 'belongs', 'to', 'the', 'good', 'side', 'and', 'whoever', 'is', 'on', 'the', 'other', 'side', 'is', 'the', 'evil', 'that', 'must', 'be', 'destroyed', 'or', 'at', 'least', 'deserves', 'condemnation', '.'], 'label_ids': [1, 3, 0, 5, 0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 6, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': ['B-AGENT', 'B-DSE', 'O', 'B-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'B-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'spans': ['AGENT: He', 'TARGET: he', 'TARGET: whoever is on the other side', 'TARGET: the evil'], 'dse': 'claims'}\n",
      "{'words': ['``', 'The', 'situation', 'we', 'see', 'now', 'is', 'what', 'I', 'call', 'the', 'Last', 'Supper', '--', 'it', 'is', 'ZANU-PF', \"'s\", 'final', 'feast', ',', \"''\", 'Mr.', 'Tsvangirai', 'said', '.'], 'label_ids': [0, 5, 6, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': ['O', 'B-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'B-DSE', 'O', 'O', 'O', 'O', 'B-TARGET', 'O', 'B-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'spans': ['TARGET: The situation', 'AGENT: I', 'TARGET: it', 'TARGET: ZANU-PF'], 'dse': 'call'}\n",
      "{'words': ['Protesters', 'carried', 'banners', 'reading', ',', '``', 'Ratify', 'the', 'Kyoto', 'Protocol', ',', \"''\", 'and', '``', 'Koizumi', 'say', '`', 'No', \"'\", 'to', 'Bush', ':', 'Stick', 'to', 'Kyoto', 'Protocol', '.', \"''\"], 'label_ids': [1, 3, 4, 4, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 6, 0, 0], 'labels': ['B-AGENT', 'B-DSE', 'I-DSE', 'I-DSE', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'O', 'O'], 'spans': ['AGENT: Protesters', 'TARGET: the Kyoto Protocol', 'TARGET: Bush', 'TARGET: Kyoto Protocol'], 'dse': 'carried banners reading'}\n",
      "{'words': ['Carl', 'Pope', ',', 'the', 'director', 'of', 'the', 'Sierra', 'Club', ',', 'considers', 'for', 'his', 'part', 'that', 'the', 'Bush', 'Administration', '``', 'is', 'sticking', 'to', 'the', 'polluting', 'policies', 'that', 'the', 'energy', 'industry', 'asked', 'for', 'rather', 'than', 'taking', 'the', 'sensible', 'steps', 'that', 'can', 'protect', 'our', 'health', '.', \"''\"], 'label_ids': [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 0, 0, 0], 'labels': ['B-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DSE', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'spans': ['AGENT: Carl Pope', 'TARGET: the Bush Administration', 'TARGET: the polluting policies', 'TARGET: the sensible steps'], 'dse': 'considers'}\n",
      "The Kimberley Provincial Hospital said it would probably know by Tuesday whether one of its patients had Congo Fever .\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "cnt = 0\n",
    "for i in range(len(dataset['train'])):\n",
    "    if len(dataset['train'][i]['spans']) > 3:\n",
    "        print(dataset['train'][i])\n",
    "        cnt+=1\n",
    "        if cnt>5: break\n",
    "\n",
    "print(\" \".join(dataset['train'][0]['words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:03.808350Z",
     "iopub.status.busy": "2024-02-28T14:16:03.808004Z",
     "iopub.status.idle": "2024-02-28T14:16:03.814544Z",
     "shell.execute_reply": "2024-02-28T14:16:03.814024Z",
     "shell.execute_reply.started": "2024-02-28T14:16:03.808329Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MPQADataset(Dataset):\n",
    "  def __init__(self, tokenizer, dataset, type_path, max_len=512):\n",
    "\n",
    "    self.data = dataset[type_path]\n",
    "    self.max_len = max_len\n",
    "    self.tokenizer = tokenizer\n",
    "    self.tokenizer.max_length = max_len\n",
    "    self.tokenizer.model_max_length = max_len\n",
    "    self.inputs = []\n",
    "    self.targets = []\n",
    "\n",
    "    self._build()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.inputs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
    "    target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
    "\n",
    "    src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "    target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "\n",
    "    return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "\n",
    "  def _build(self):\n",
    "    for idx in range(len(self.data)):\n",
    "      input_, target = \" \".join(self.data[idx][\"words\"]), \"; \".join(self.data[idx][\"spans\"])\n",
    "      input_ = input_ + \" DSE:\" + self.data[idx][\"dse\"]\n",
    "\n",
    "      input_ = input_.lower() + ' </s>'\n",
    "      target = target.lower() + \" </s>\"\n",
    "\n",
    "       # tokenize inputs\n",
    "      tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
    "          [input_], max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "      )\n",
    "       # tokenize targets\n",
    "      tokenized_targets = self.tokenizer.batch_encode_plus(\n",
    "          [target],max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "      )\n",
    "\n",
    "      self.inputs.append(tokenized_inputs)\n",
    "      self.targets.append(tokenized_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:07.466521Z",
     "iopub.status.busy": "2024-02-28T14:16:07.466195Z",
     "iopub.status.idle": "2024-02-28T14:16:10.213091Z",
     "shell.execute_reply": "2024-02-28T14:16:10.212619Z",
     "shell.execute_reply.started": "2024-02-28T14:16:07.466502Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5TokenizerFast(name_or_path='../T5-base', vocab_size=32100, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32000: AddedToken(\"<extra_id_99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32001: AddedToken(\"<extra_id_98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32002: AddedToken(\"<extra_id_97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32003: AddedToken(\"<extra_id_96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32004: AddedToken(\"<extra_id_95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32005: AddedToken(\"<extra_id_94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32006: AddedToken(\"<extra_id_93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32007: AddedToken(\"<extra_id_92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32008: AddedToken(\"<extra_id_91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32009: AddedToken(\"<extra_id_90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32010: AddedToken(\"<extra_id_89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32011: AddedToken(\"<extra_id_88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32012: AddedToken(\"<extra_id_87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32013: AddedToken(\"<extra_id_86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32014: AddedToken(\"<extra_id_85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32015: AddedToken(\"<extra_id_84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32016: AddedToken(\"<extra_id_83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32017: AddedToken(\"<extra_id_82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32018: AddedToken(\"<extra_id_81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32019: AddedToken(\"<extra_id_80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32020: AddedToken(\"<extra_id_79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32021: AddedToken(\"<extra_id_78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32022: AddedToken(\"<extra_id_77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32023: AddedToken(\"<extra_id_76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32024: AddedToken(\"<extra_id_75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32025: AddedToken(\"<extra_id_74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32026: AddedToken(\"<extra_id_73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32027: AddedToken(\"<extra_id_72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32028: AddedToken(\"<extra_id_71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32029: AddedToken(\"<extra_id_70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32030: AddedToken(\"<extra_id_69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32031: AddedToken(\"<extra_id_68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32032: AddedToken(\"<extra_id_67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32033: AddedToken(\"<extra_id_66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32034: AddedToken(\"<extra_id_65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32035: AddedToken(\"<extra_id_64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32036: AddedToken(\"<extra_id_63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32037: AddedToken(\"<extra_id_62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32038: AddedToken(\"<extra_id_61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32039: AddedToken(\"<extra_id_60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32040: AddedToken(\"<extra_id_59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32041: AddedToken(\"<extra_id_58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32042: AddedToken(\"<extra_id_57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32043: AddedToken(\"<extra_id_56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32044: AddedToken(\"<extra_id_55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32045: AddedToken(\"<extra_id_54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32046: AddedToken(\"<extra_id_53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32047: AddedToken(\"<extra_id_52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32048: AddedToken(\"<extra_id_51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32049: AddedToken(\"<extra_id_50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32050: AddedToken(\"<extra_id_49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32051: AddedToken(\"<extra_id_48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32052: AddedToken(\"<extra_id_47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32053: AddedToken(\"<extra_id_46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32054: AddedToken(\"<extra_id_45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32055: AddedToken(\"<extra_id_44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32056: AddedToken(\"<extra_id_43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32057: AddedToken(\"<extra_id_42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32058: AddedToken(\"<extra_id_41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32059: AddedToken(\"<extra_id_40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32060: AddedToken(\"<extra_id_39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32061: AddedToken(\"<extra_id_38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32062: AddedToken(\"<extra_id_37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32063: AddedToken(\"<extra_id_36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32064: AddedToken(\"<extra_id_35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32065: AddedToken(\"<extra_id_34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32066: AddedToken(\"<extra_id_33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32067: AddedToken(\"<extra_id_32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32068: AddedToken(\"<extra_id_31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32069: AddedToken(\"<extra_id_30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32070: AddedToken(\"<extra_id_29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32071: AddedToken(\"<extra_id_28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32072: AddedToken(\"<extra_id_27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32073: AddedToken(\"<extra_id_26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32074: AddedToken(\"<extra_id_25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32075: AddedToken(\"<extra_id_24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32076: AddedToken(\"<extra_id_23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32077: AddedToken(\"<extra_id_22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32078: AddedToken(\"<extra_id_21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32079: AddedToken(\"<extra_id_20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32080: AddedToken(\"<extra_id_19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32081: AddedToken(\"<extra_id_18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32082: AddedToken(\"<extra_id_17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32083: AddedToken(\"<extra_id_16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32084: AddedToken(\"<extra_id_15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32085: AddedToken(\"<extra_id_14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32086: AddedToken(\"<extra_id_13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32087: AddedToken(\"<extra_id_12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32088: AddedToken(\"<extra_id_11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32089: AddedToken(\"<extra_id_10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32090: AddedToken(\"<extra_id_9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32091: AddedToken(\"<extra_id_8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32092: AddedToken(\"<extra_id_7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32093: AddedToken(\"<extra_id_6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32094: AddedToken(\"<extra_id_5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32095: AddedToken(\"<extra_id_4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32096: AddedToken(\"<extra_id_3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32097: AddedToken(\"<extra_id_2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32098: AddedToken(\"<extra_id_1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32099: AddedToken(\"<extra_id_0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../T5-base\")\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "input_dataset = MPQADataset(tokenizer=tokenizer, dataset=dataset, type_path='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:13.859761Z",
     "iopub.status.busy": "2024-02-28T14:16:13.859213Z",
     "iopub.status.idle": "2024-02-28T14:16:13.865043Z",
     "shell.execute_reply": "2024-02-28T14:16:13.864610Z",
     "shell.execute_reply.started": "2024-02-28T14:16:13.859741Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>\n",
      "the kimberley\n",
      "[2, 1]\n",
      "tensor([8, 3])\n",
      "0\n",
      "the kimberley provincial hospital said it would probably know by tuesday whether one of its patients had congo fever. dse:would probably know</s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "agent: the kimberley provincial hospital; target: whether one of its patients had congo fever</s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "data = input_dataset[0]\n",
    "# print(data)\n",
    "print(tokenizer.decode(data[\"source_ids\"][400]))\n",
    "print((tokenizer.decode(data[\"source_ids\"][0:5])))\n",
    "print(tokenizer.encode(\"<unk>\"))\n",
    "print(data[\"source_ids\"][0:2])\n",
    "print(tokenizer.pad_token_id)\n",
    "print(tokenizer.decode(data[\"source_ids\"], skip_special_tokens=False))\n",
    "print(tokenizer.decode(data[\"target_ids\"], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:33.181671Z",
     "iopub.status.busy": "2024-02-28T14:16:33.181353Z",
     "iopub.status.idle": "2024-02-28T14:16:33.185008Z",
     "shell.execute_reply": "2024-02-28T14:16:33.184575Z",
     "shell.execute_reply.started": "2024-02-28T14:16:33.181650Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args_dict = dict(\n",
    "    data_dir=\"zhangxl2002/mpqa_ORL\", # path for data files\n",
    "    output_dir=\"\", # path to save the checkpoints\n",
    "    model_name_or_path='t5-base',\n",
    "    tokenizer_name_or_path='t5-base',\n",
    "    max_seq_length=256,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    gradient_accumulation_steps=16,\n",
    "    n_gpu=1,\n",
    "    early_stop_callback=False,\n",
    "    fp_16=True, # if you want to enable 16-bit training then install apex and set this to true\n",
    "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
    "    max_grad_norm=1, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:34.903982Z",
     "iopub.status.busy": "2024-02-28T14:16:34.903434Z",
     "iopub.status.idle": "2024-02-28T14:16:34.906468Z",
     "shell.execute_reply": "2024-02-28T14:16:34.905943Z",
     "shell.execute_reply.started": "2024-02-28T14:16:34.903962Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5FineTuner():\n",
    "    def __init__(self, hparam):\n",
    "        self.hparam = hparam\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "            hparam.model_name_or_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            hparam.model_name_or_path\n",
    "        )\n",
    "    def is_logger(self):\n",
    "        return True\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
    "    ):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=lm_labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self.model(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            labels=lm_labels,\n",
    "            decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        # tensorboard_logs = {\"train_loss\": loss}\n",
    "        # return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparam.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.hparam.learning_rate, eps=self.hparam.adam_epsilon)\n",
    "        self.opt = optimizer\n",
    "        return [optimizer]\n",
    "\n",
    "    def optimizer_step(self,\n",
    "                       epoch=None,\n",
    "                       batch_idx=None,\n",
    "                       optimizer=None,\n",
    "                       optimizer_idx=None,\n",
    "                       optimizer_closure=None,\n",
    "                       on_tpu=None,\n",
    "                       using_native_amp=None,\n",
    "                       using_lbfgs=None\n",
    "                       ):\n",
    "\n",
    "        # optimizer.step(closure=optimizer_closure)\n",
    "        # optimizer.zero_grad()\n",
    "        self.opt.step(closure=optimizer_closure)\n",
    "        self.opt.zero_grad()\n",
    "        self.lr_scheduler.step()\n",
    "\n",
    "    def get_tqdm_dict(self):\n",
    "        tqdm_dict = {\"loss\": \"{:.3f}\".format(\n",
    "            self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "\n",
    "        return tqdm_dict\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = get_dataset(\n",
    "            tokenizer=self.tokenizer, type_path=\"train\", args=self.hparam)\n",
    "        dataloader = DataLoader(train_dataset, batch_size=self.hparam.train_batch_size,\n",
    "                                drop_last=True, shuffle=True, num_workers=2)\n",
    "        t_total = (\n",
    "            (len(dataloader.dataset) //\n",
    "             (self.hparam.train_batch_size * max(1, self.hparam.n_gpu)))\n",
    "            // self.hparam.gradient_accumulation_steps\n",
    "            * float(self.hparam.num_train_epochs)\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.opt, num_warmup_steps=self.hparam.warmup_steps, num_training_steps=t_total\n",
    "        )\n",
    "        self.lr_scheduler = scheduler\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = get_dataset(\n",
    "            tokenizer=self.tokenizer, type_path=\"validation\", args=self.hparam)\n",
    "        return DataLoader(val_dataset, batch_size=self.hparam.eval_batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:39.522728Z",
     "iopub.status.busy": "2024-02-28T14:16:39.522408Z",
     "iopub.status.idle": "2024-02-28T14:16:46.303899Z",
     "shell.execute_reply": "2024-02-28T14:16:46.303415Z",
     "shell.execute_reply.started": "2024-02-28T14:16:39.522708Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = T5FineTuner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointPath = \"saveCheckpointPath/checkpoint.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(tokenizer, type_path, args):\n",
    "    tokenizer.max_length = args.max_seq_length\n",
    "    tokenizer.model_max_length = args.max_seq_length\n",
    "    # dataset = load_dataset(args.data_dir)\n",
    "    dataset = load_dataset(\"zhangxl2002/mpqa_ORL\")\n",
    "    return MPQADataset(tokenizer=tokenizer, dataset=dataset, type_path=type_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 13404) is killed by signal: Killed. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/workspace/ORL/test_AL copy.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m num_batches \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(model\u001b[39m.\u001b[39mtrain_dataloader()):\n\u001b[0;32m---> <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtraining_step(batch, i)\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     num_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32m/mnt/workspace/ORL/test_AL copy.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_step\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m---> <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step(batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m# tensorboard_logs = {\"train_loss\": loss}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39m# return {\"loss\": loss, \"log\": tensorboard_logs}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n",
      "\u001b[1;32m/mnt/workspace/ORL/test_AL copy.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m lm_labels \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mtarget_ids\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m lm_labels[lm_labels[:, :] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mpad_token_id] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     input_ids\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39msource_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39msource_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     labels\u001b[39m=\u001b[39;49mlm_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mbatch[\u001b[39m'\u001b[39;49m\u001b[39mtarget_mask\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m loss \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://dsw-gateway-cn-beijing.data.aliyun.com/mnt/workspace/ORL/test_AL%20copy.ipynb#Y130sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/home/pai/envs/T5/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/pai/envs/T5/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1783\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1781\u001b[0m     \u001b[39m# move labels to correct device to enable PP\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(lm_logits\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> 1783\u001b[0m     loss \u001b[39m=\u001b[39m loss_fct(lm_logits\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, lm_logits\u001b[39m.\u001b[39;49msize(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)), labels\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m   1784\u001b[0m     \u001b[39m# TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m/home/pai/envs/T5/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/pai/envs/T5/lib/python3.9/site-packages/torch/nn/modules/loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1164\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1165\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1166\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m/home/pai/envs/T5/lib/python3.9/site-packages/torch/nn/functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3013\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3014\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "File \u001b[0;32m/home/pai/envs/T5/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[39m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     _error_if_any_worker_fails()\n\u001b[1;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m previous_handler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mcallable\u001b[39m(previous_handler)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 13404) is killed by signal: Killed. "
     ]
    }
   ],
   "source": [
    "model.configure_optimizers()\n",
    "# for i, batch in enumerate(dataloader):\n",
    "#     # x, y = batch                      moved to training_step\n",
    "#     # y_hat = model(x)                  moved to training_step\n",
    "#     # loss = loss_function(y_hat, y)    moved to training_step\n",
    "#     loss = lightning_module.training_step(batch, i)\n",
    "\n",
    "#     # Lighting handles automatically:\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "max_epochs = 10\n",
    "for epoch in range(max_epochs):\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for i, batch in enumerate(model.train_dataloader()):\n",
    "        loss = model.training_step(batch, i)\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        # \n",
    "        print(f\"Epoch [{epoch + 1}/{max_epochs}], Batch [{i + 1}/{len(model.train_dataloader())}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # \n",
    "        model.optimizer_step()\n",
    "\n",
    "    # \n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{max_epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "    # model.training_epoch_end(outputs) # outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:49.405585Z",
     "iopub.status.busy": "2024-02-28T14:16:49.405011Z",
     "iopub.status.idle": "2024-02-28T14:16:49.410174Z",
     "shell.execute_reply": "2024-02-28T14:16:49.409675Z",
     "shell.execute_reply.started": "2024-02-28T14:16:49.405565Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LoggingCallback():\n",
    "  def on_validation_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Validation results *****\")\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "      # Log results\n",
    "      for key in sorted(metrics):\n",
    "        if key not in [\"log\", \"progress_bar\"]:\n",
    "          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "  def on_test_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Test results *****\")\n",
    "\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "\n",
    "      # Log and save results to file\n",
    "      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
    "      with open(output_test_results_file, \"w\") as writer:\n",
    "        for key in sorted(metrics):\n",
    "          if key not in [\"log\", \"progress_bar\"]:\n",
    "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:53.624799Z",
     "iopub.status.busy": "2024-02-28T14:16:53.624457Z",
     "iopub.status.idle": "2024-02-28T14:16:53.629524Z",
     "shell.execute_reply": "2024-02-28T14:16:53.629044Z",
     "shell.execute_reply.started": "2024-02-28T14:16:53.624778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    filename=args.output_dir+\"/checkpoint.pth\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    #early_stop_callback=False,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    #amp_level=args.opt_level,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    callbacks=[LoggingCallback()],\n",
    ")\n",
    "\n",
    "# train_params = dict(\n",
    "#     accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "#     ## gpus=args.n_gpu,\n",
    "#     max_epochs=args.num_train_epochs,\n",
    "#     #early_stop_callback=False,\n",
    "#     precision= 16 if args.fp_16 else 32,\n",
    "#     #amp_level=args.opt_level,\n",
    "#     gradient_clip_val=args.max_grad_norm,\n",
    "#     # callbacks=[LoggingCallback()],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:59.154405Z",
     "iopub.status.busy": "2024-02-28T14:16:59.153852Z",
     "iopub.status.idle": "2024-02-28T14:16:59.157263Z",
     "shell.execute_reply": "2024-02-28T14:16:59.156780Z",
     "shell.execute_reply.started": "2024-02-28T14:16:59.154380Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loops import FitLoop\n",
    "# https://pytorch-lightning.readthedocs.io/en/1.5.10/extensions/loops.html\n",
    "# FitLoopadvance\n",
    "# https://github.com/Lightning-Universe/lightning-flash/blob/try/icevision-data/flash/image/classification/integrations/baal/loop.py\n",
    "# https://github.com/Lightning-Universe/lightning-flash/blob/try/icevision-data/flash_examples/integrations/baal/image_classification_active_learning.py\n",
    "class CustomFitLoop(FitLoop):\n",
    "    def advance(self):\n",
    "        \"\"\"Advance from one iteration to the next.\"\"\"\n",
    "\n",
    "    def on_advance_end(self):\n",
    "        \"\"\"Do something at the end of an iteration.\"\"\"\n",
    "\n",
    "    def on_run_end(self):\n",
    "        \"\"\"Do something when the loop ends.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:17:03.095693Z",
     "iopub.status.busy": "2024-02-28T14:17:03.095368Z",
     "iopub.status.idle": "2024-02-28T14:17:03.102459Z",
     "shell.execute_reply": "2024-02-28T14:17:03.102015Z",
     "shell.execute_reply.started": "2024-02-28T14:17:03.095673Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7fb6a2a8c9d0>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7fb6a2a8c9d0>)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:17:04.889255Z",
     "iopub.status.busy": "2024-02-28T14:17:04.888686Z",
     "iopub.status.idle": "2024-02-28T14:54:53.783173Z",
     "shell.execute_reply": "2024-02-28T14:54:53.782617Z",
     "shell.execute_reply.started": "2024-02-28T14:17:04.889232Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T15:15:30.833864Z",
     "iopub.status.busy": "2024-02-28T15:15:30.833522Z",
     "iopub.status.idle": "2024-02-28T15:15:37.034017Z",
     "shell.execute_reply": "2024-02-28T15:15:37.033415Z",
     "shell.execute_reply.started": "2024-02-28T15:15:30.833841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.load_from_checkpoint(\"/mnt/workspace/ORL/lightning_logs/version_4/checkpoints/epoch=9-step=279.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "dataloader = DataLoader(input_dataset, batch_size=32, num_workers=2, shuffle=True)\n",
    "model.model.eval()\n",
    "model = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:15:39.989894Z",
     "iopub.status.busy": "2024-02-28T15:15:39.989324Z",
     "iopub.status.idle": "2024-02-28T15:15:53.553095Z",
     "shell.execute_reply": "2024-02-28T15:15:53.552563Z",
     "shell.execute_reply.started": "2024-02-28T15:15:39.989874Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: at the state house , where the ceremony was held , thousands of zanu-pf supporters in clothing\n",
      "emblazoned with mugabe 's portrait , were singing and dancing to celebrate his victory , with a hope\n",
      "that mugabe will finally deliver on his promises to give them the land currently owned by the\n",
      "country 's white minority . dse:with a hope\n",
      "\n",
      "Actual Entities: agent: thousands of zanu-pf supporters\n",
      "Predicted Entities: agent: thousands of zanu-pf supporters; target: mugabe will finally deliver\n",
      "=====================================================================\n",
      "\n",
      "text: nobody who has a live conscience and human feelings , whether he is palestinian or otherwise ,\n",
      "could not have been moved by these events and expressed sympathy for the families of the us victims\n",
      ", regardless of the us political stances that are totally biased to israel and israel 's use of the\n",
      "most advanced us weapons to curb the palestinian intifadah . dse:stances\n",
      "\n",
      "Actual Entities: agent: the us\n",
      "Predicted Entities: agent: the us; target: israel\n",
      "=====================================================================\n",
      "\n",
      "text: however , chatterbox notes that nbc , like every other responsible news organization that 's\n",
      "covered this story , reported that norma kelsey 's father 's killer was pardoned by gov. bill\n",
      "clinton , and remains perplexed that the journal editorial page wo n't . dse:perplexed\n",
      "\n",
      "Actual Entities: agent: chatterbox; target: that the journal editorial page wo n't\n",
      "Predicted Entities: agent: chatterbox; target: that the journal editorial page wo n't\n",
      "=====================================================================\n",
      "\n",
      "text: there are no results to speak of yet , but it is important that this area of inquiry has\n",
      "appeared . dse:there\n",
      "\n",
      "Actual Entities: target: this area of inquiry\n",
      "Predicted Entities: \n",
      "=====================================================================\n",
      "\n",
      "text: bush said ,  either you are with us or you are with the terrorists '' and  any nation that\n",
      "continues to harbor or support terrorism will be regarded by the united states as a hostile regime .\n",
      "'' dse:said\n",
      "\n",
      "Actual Entities: agent: bush; target: you\n",
      "Predicted Entities: agent: bush; target: you\n",
      "=====================================================================\n",
      "\n",
      "text: see if saddam did this , '' clarke recalls the president telling them . dse:recalls\n",
      "\n",
      "Actual Entities: agent: clarke; target: the president telling them\n",
      "Predicted Entities: agent: clarke; target: the president telling them\n",
      "=====================================================================\n",
      "\n",
      "text: usually when a japanese company is ready to sell , it has few alternatives remaining , and the\n",
      "grim demeanors of sansui 's directors at a joint news conference here left little doubt that this\n",
      "was not the company 's finest hour . dse:grim demeanors\n",
      "\n",
      "Actual Entities: agent: sansui 's directors\n",
      "Predicted Entities: agent: sansui 's directors\n",
      "=====================================================================\n",
      "\n",
      "text: but they had been told that chavez , whose friendship with libya , iraq and cuba has angered\n",
      "washington , should only be replaced by legitimate , constitutional means ; the us would not support\n",
      "a coup . dse:would not support\n",
      "\n",
      "Actual Entities: agent: the us; target: a coup\n",
      "Predicted Entities: agent: the us; target: a coup\n",
      "=====================================================================\n",
      "\n",
      "text: can you think of a story that they told you that you liked for them to read over and over ?\n",
      "dse:think\n",
      "\n",
      "Actual Entities: target: a story that they told you that you liked for them to read over and over\n",
      "Predicted Entities: agent: you\n",
      "=====================================================================\n",
      "\n",
      "text: whether the incident was plain holdup , as the pnp would like to see it , the abduction\n",
      "reinforced the growing perception in the diplomatic community and foreign governments that there is\n",
      "a breakdown in law and order and that the macapagal administration is not in control . dse:growing\n",
      "perception\n",
      "\n",
      "Actual Entities: agent: the diplomatic community and foreign governments; target: the macapagal administration\n",
      "Predicted Entities: agent: the diplomatic community and foreign governments; target: the macapagal administration\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "targets = []\n",
    "texts = []\n",
    "cnt = 0\n",
    "for batch in dataloader:\n",
    "\n",
    "    outs = model.model.generate(input_ids=batch['source_ids'],\n",
    "                                attention_mask=batch['source_mask'])\n",
    "    dec = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip() for ids in outs]\n",
    "    target = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"target_ids\"]]\n",
    "    text = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"source_ids\"]]\n",
    "    texts.extend(text)\n",
    "    outputs.extend(dec)\n",
    "    targets.extend(target)\n",
    "    break\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    c = texts[i]\n",
    "    lines = textwrap.wrap(\"text:\\n%s\\n\" % c, width=100)\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nActual Entities: %s\" % target[i])\n",
    "    print(\"Predicted Entities: %s\" % outputs[i])\n",
    "    print(\"=====================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.keys():  odict_keys(['sequences', 'scores', 'past_key_values'])\n",
      "outputs.scores[0].shape: torch.Size([2, 32128])\n",
      "len(outputs.scores): 13\n",
      "outputs.scores: torch.Size([2, 32128])\n",
      "ddddddddddddddddddddddddddddddddddddd tensor(-22.2044)\n",
      "len(transition_scores[0]):  13\n",
      "transition_scores:  tensor([[-7.3570e-02, -1.5182e-04, -1.8435e-02, -1.8597e-01, -1.7682e-03,\n",
      "         -9.1794e-05, -1.1499e-02, -1.4008e-04, -2.0066e-01, -2.2774e-02,\n",
      "         -1.1470e-03, -4.0414e-04, -5.3514e-03],\n",
      "        [-9.9976e-02, -7.1911e-05, -1.6243e-02, -1.4897e-01, -1.2826e-04,\n",
      "         -1.0216e-04, -2.3009e-03, -3.8949e-05, -8.3902e-03, -5.1038e+01,\n",
      "         -2.2564e+01, -2.2113e+01, -2.1953e+01]])\n",
      "outputs.sequences:  tensor([[   0, 3102,   10,   27,  117, 2387,   10,    8,  568,  113,  114,    7,\n",
      "          140,    1],\n",
      "        [   0, 3102,   10,  216,  117, 2387,   10,  112, 2512,    1,    0,    0,\n",
      "            0,    0]])\n",
      "len(generated_tokens[0]): 13\n",
      "generated_tokens:  tensor([[3102,   10,   27,  117, 2387,   10,    8,  568,  113,  114,    7,  140,\n",
      "            1],\n",
      "        [3102,   10,  216,  117, 2387,   10,  112, 2512,    1,    0,    0,    0,\n",
      "            0]])\n",
      "|  3102 | agent    | -0.0736 |92.91%\n",
      "|    10 | :        | -0.0002 |99.98%\n",
      "|    27 | I        | -0.0184 |98.17%\n",
      "|   117 | ;        | -0.1860 |83.03%\n",
      "|  2387 | target   | -0.0018 |99.82%\n",
      "|    10 | :        | -0.0001 |99.99%\n",
      "|     8 | the      | -0.0115 |98.86%\n",
      "|   568 | person   | -0.0001 |99.99%\n",
      "|   113 | who      | -0.2007 |81.82%\n",
      "|   114 | like     | -0.0228 |97.75%\n",
      "|     7 | s        | -0.0011 |99.89%\n",
      "|   140 | me       | -0.0004 |99.96%\n",
      "|     1 | </s>     | -0.0054 |99.47%\n",
      "----------------------------------------------\n",
      "|  3102 | agent    | -0.1000 |90.49%\n",
      "|    10 | :        | -0.0001 |99.99%\n",
      "|   216 | He       | -0.0162 |98.39%\n",
      "|   117 | ;        | -0.1490 |86.16%\n",
      "|  2387 | target   | -0.0001 |99.99%\n",
      "|    10 | :        | -0.0001 |99.99%\n",
      "|   112 | his      | -0.0023 |99.77%\n",
      "|  2512 | wife     | -0.0000 |100.00%\n",
      "|     1 | </s>     | -0.0084 |99.16%\n",
      "|     0 | <pad>    | -51.0377 |0.00%\n",
      "|     0 | <pad>    | -22.5637 |0.00%\n",
      "|     0 | <pad>    | -22.1130 |0.00%\n",
      "|     0 | <pad>    | -21.9531 |0.00%\n",
      "----------------------------------------------\n",
      "agent: I; target: the person who likes me\n"
     ]
    }
   ],
   "source": [
    "# search:how to get the probability huggingface\n",
    "# https://discuss.huggingface.co/t/announcement-generation-get-probabilities-for-generated-output/30075\n",
    "\n",
    "# \n",
    "input_text = \"I love the person who likes me. dse:love\"\n",
    "input_texts = [\"I love the person who likes me. dse:love\",\"He loves his wife. dse:loves\"]\n",
    "max_length = 32\n",
    "temperature = 1.0\n",
    "num_samples = 1\n",
    "\n",
    "# \n",
    "# inputs = tokenizer([input_text], return_tensors=\"pt\")\n",
    "\n",
    "inputs = tokenizer.batch_encode_plus(\n",
    "    input_texts, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    ")\n",
    "# input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "outputs = model.model.generate(**inputs,return_dict_in_generate=True,output_scores=True)\n",
    "# print(outputs)\n",
    "print(\"outputs.keys(): \",outputs.keys())\n",
    "print(\"outputs.scores[0].shape:\",outputs.scores[0].shape)\n",
    "print(\"len(outputs.scores):\",len(outputs.scores))\n",
    "#output.scorestokenbatchsize*tensor\n",
    "print(\"outputs.scores[0].shape:\",outputs.scores[0].shape) \n",
    "print(\"ddddddddddddddddddddddddddddddddddddd\",outputs.scores[0][0][0])\n",
    "\n",
    "transition_scores = model.model.compute_transition_scores(\n",
    "    outputs.sequences, outputs.scores, normalize_logits=True\n",
    ")\n",
    "print(\"len(transition_scores[0]): \", len(transition_scores[0]))\n",
    "print(\"transition_scores: \", transition_scores)\n",
    "\n",
    "# input_length = 1 if model.config.is_encoder_decoder else inputs.input_ids.shape[1]\n",
    "# t5encoder-decoderinput_length1\n",
    "generated_tokens = outputs.sequences[:, 1:] \n",
    "print(\"outputs.sequences: \", outputs.sequences)\n",
    "print(\"len(generated_tokens[0]):\",len(generated_tokens[0]))\n",
    "print(\"generated_tokens: \",generated_tokens)\n",
    "for i in range(generated_tokens.shape[0]):\n",
    "    for tok, score in zip(generated_tokens[i], transition_scores[i]):\n",
    "        # | token | token string | logits | probability\n",
    "        print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {score.numpy():.4f} |{np.exp(score.numpy()):.2%}\")\n",
    "    print(\"----------------------------------------------\")\n",
    "\n",
    "print(tokenizer.decode(outputs.sequences[0], skip_special_tokens=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  2387,    10,     8, 23997,  3368,   628,  2478,     1,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,     3,    23,   117,  2387,    10,     3,  1258,\n",
      "           189,    63,   410,    48, 24522,     1,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,     8,   126, 25453,   648,     3,     6, 10381,\n",
      "         11831,    15,     7,   648,    11,  6179,  6029,   442,   117,  2387],\n",
      "        [    0,  2387,    10,     8,     3,   102,    29,   102,     1,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,  7609,   261,    12,     8,  1075,    13,  1291,\n",
      "          4028,   127,     7,   117,  2387,    10,  4297,  3101,    84,  4840],\n",
      "        [    0,  3102,    10,   112,   117,  2387,    10, 26504,   323,    30,\n",
      "             8,   962,     1,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,     3,     9,  1021,  1370,   117,  2387,    10,\n",
      "          4326,  2856,   840,     3,     6,  2425,   871,    11,  8033,     3],\n",
      "        [    0,  3102,    10,  1440,   117,  2387,    10,     8,     3,  1795,\n",
      "          2420,    13,     8,     3,  3781,    32,   235, 10015,     1,     0],\n",
      "        [    0,  3102,    10,     8,     3, 26165,    29,     3, 16812,   257,\n",
      "           117,  2387,    10,     8,     3,  3781,    32,   235, 10015,     1],\n",
      "        [    0,  3102,    10,     3,    23,   117,  2387,    10,     3,    23,\n",
      "            47,   838,  1456,     7,     1,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,     8, 14864,  7021,   117,  2387,    10,   487,\n",
      "          1151,  7774,  3629,   581,   165,   789,     1,     0,     0,     0],\n",
      "        [    0,  2387,    10,     8,   711,  5492,    76,  1222,  4373,     1,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,     3,  2781,     7,  5003,   117,  2387,    10,\n",
      "           662,   931,     1,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,   381,    13, 28480,     1,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,     3,    88,   117,  2387,    10,     3, 23064,\n",
      "             1,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  2387,    10,   112, 12914, 12028,    45,  6525,     1,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,    62,   117,  2387,    10,     8,  6032,     1,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,   178,     9,   469,     1,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  2387,    10,     8,  7648,     1,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,    79,   117,  2387,    10,     8,     3,  3781,\n",
      "            32,   235, 10015,     1,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,  2753, 17907,     1,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,     3,    23,   117,  2387,    10,   125,     3,\n",
      "            23,   103,     1,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  2387,    10,   255,     3,    31,     7,  4896,   117,  2387,\n",
      "            10,   255,     3,    31,     7,   182,  2592,     3,     6,    11],\n",
      "        [    0,  3102,    10,  4942,   117,  2387,    10,     8,     3,  1033,\n",
      "          1559, 12315,  2426,     1,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  2387,    10,    21,     8,     3,    76,     5,     7,     5,\n",
      "          2716,    12,  2665,     8, 22040,   136, 10302,   117,  3102,    10],\n",
      "        [    0,  3102,    10,     3,    88,   117,  2387,    10,     8,  1296,\n",
      "           779,  5217, 20576,    56, 11230,     1,     0,     0,     0,     0],\n",
      "        [    0,  2387,    10,     3,    17, 31081,   117,  3102,    10,     8,\n",
      "         12392,    13,     8,     3,    32,    17,    17,  7396, 13008, 14829],\n",
      "        [    0,  3102,    10,     3,  2781,     7,  5003,   117,  2387,    10,\n",
      "             3,    76,     5,     7,     5,  1058,    13,    20, 15354,    15],\n",
      "        [    0,  3102,    10,     3,    88,   117,  2387,    10,  4028,   112,\n",
      "          1291,    13, 17323,  9569,     1,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,    11,     1,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,  3102,    10,   126,     3,   776,   138,   232,  2959, 12748,\n",
      "          6323,     3, 18118,     3,   122,  1647,   117,  2387,    10,   126],\n",
      "        [    0,  3102,    10,   452,     1,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "target: the christmas island space station\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "\n",
    "    outs = model.model.generate(input_ids=batch['source_ids'],\n",
    "                                attention_mask=batch['source_mask'])\n",
    "    # dec = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip() for ids in outs]\n",
    "    # target = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n",
    "    #             for ids in batch[\"target_ids\"]]\n",
    "    # text = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n",
    "    #             for ids in batch[\"source_ids\"]]\n",
    "    # texts.extend(text)\n",
    "    # outputs.extend(dec)\n",
    "    # targets.extend(target)\n",
    "    # cnt += 1\n",
    "    # if cnt > 10:\n",
    "    #     break\n",
    "    print(outs)\n",
    "    print(tokenizer.decode(outs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False).strip())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,  2387,    10,     8, 23997,  3368,   628,  2478,     1,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "target: the christmas island space station\n",
      "tensor([    0,  3102,    10,     3,    23,   117,  2387,    10,     3,  1258,\n",
      "          189,    63,   410,    48, 24522,     1,     0,     0,     0,     0])\n",
      "agent: i; target: kathy did this intentionally\n",
      "tensor(0)\n",
      "\n",
      "tensor(3102)\n",
      "agent\n",
      "tensor(10)\n",
      ":\n",
      "tensor(3)\n",
      "\n",
      "tensor(23)\n",
      "i\n",
      "tensor(117)\n",
      ";\n",
      "tensor(2387)\n",
      "target\n",
      "tensor(10)\n",
      ":\n",
      "tensor(3)\n",
      "\n",
      "tensor(1258)\n",
      "ka\n",
      "tensor(189)\n",
      "th\n",
      "tensor(63)\n",
      "y\n",
      "tensor(410)\n",
      "did\n",
      "tensor(48)\n",
      "this\n",
      "tensor(24522)\n",
      "intentionally\n"
     ]
    }
   ],
   "source": [
    "print(outs[0])\n",
    "print(tokenizer.decode(outs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False).strip())\n",
    "\n",
    "print(outs[1])\n",
    "print(tokenizer.decode(outs[1], skip_special_tokens=True, clean_up_tokenization_spaces=False).strip())\n",
    "for i in range(15):\n",
    "    print(outs[1][i])\n",
    "    print(tokenizer.decode(outs[1][i], skip_special_tokens=True, clean_up_tokenization_spaces=False).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:16:17.579251Z",
     "iopub.status.busy": "2024-02-28T15:16:17.578902Z",
     "iopub.status.idle": "2024-02-28T15:16:17.585178Z",
     "shell.execute_reply": "2024-02-28T15:16:17.584743Z",
     "shell.execute_reply.started": "2024-02-28T15:16:17.579228Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_sub_list(sl, l):\n",
    "    results = []\n",
    "    sll = len(sl)\n",
    "    for ind in (i for i, e in enumerate(l) if e == sl[0]):\n",
    "        if l[ind:ind+sll] == sl:\n",
    "            results.append((ind, ind+sll-1))\n",
    "    return results\n",
    "\n",
    "def generate_label(input: str, target: str):\n",
    "    mapper = {\n",
    "        \"O\": 0,\n",
    "        \"B-AGENT\": 1,\n",
    "        \"I-AGENT\": 2,\n",
    "        \"B-DSE\": 3,\n",
    "        \"I-DSE\": 4,\n",
    "        \"B-TARGET\": 5,\n",
    "        \"I-TARGET\": 6\n",
    "    }\n",
    "    inv_mapper = {v: k for k, v in mapper.items()}\n",
    "\n",
    "    input = input.split(\" \")\n",
    "    target = target.split(\"; \")\n",
    "\n",
    "    init_target_label = [mapper['O']]*len(input)\n",
    "\n",
    "    for ent in target:\n",
    "        ent = ent.split(\": \")\n",
    "        try:\n",
    "            sent_end = ent[1].split(\" \")\n",
    "            index = find_sub_list(sent_end, input)\n",
    "        except:\n",
    "            continue\n",
    "        # print(index)\n",
    "        try:\n",
    "            init_target_label[index[0][0]] = mapper[f\"B-{ent[0].upper()}\"]\n",
    "            for i in range(index[0][0]+1, index[0][1]+1):\n",
    "                init_target_label[i] = mapper[f\"I-{ent[0].upper()}\"]\n",
    "        except:\n",
    "            continue\n",
    "    init_target_label = [inv_mapper[j] for j in init_target_label]\n",
    "    return init_target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:16:22.561581Z",
     "iopub.status.busy": "2024-02-28T15:16:22.560990Z",
     "iopub.status.idle": "2024-02-28T15:16:57.335332Z",
     "shell.execute_reply": "2024-02-28T15:16:57.334689Z",
     "shell.execute_reply.started": "2024-02-28T15:16:22.561561Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|| 48/48 [00:35<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "test_dataset = MPQADataset(tokenizer=tokenizer, dataset=dataset, type_path='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=32,\n",
    "                             num_workers=2, shuffle=True)\n",
    "model.model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "outputs = []\n",
    "targets = []\n",
    "all_text = []\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "for batch in tqdm(test_loader):\n",
    "    input_ids = batch['source_ids'].to(\"cuda\")\n",
    "    attention_mask = batch['source_mask'].to(\"cuda\")\n",
    "    outs = model.model.generate(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "    dec = [tokenizer.decode(ids, skip_special_tokens=True,\n",
    "                            clean_up_tokenization_spaces=False).strip() for ids in outs]\n",
    "    target = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"target_ids\"]]\n",
    "    texts = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"source_ids\"]]\n",
    "    true_label = [generate_label(texts[i].strip(), target[i].strip()) if target[i].strip() != 'none' else [\n",
    "        \"O\"]*len(texts[i].strip().split()) for i in range(len(texts))]\n",
    "    pred_label = [generate_label(texts[i].strip(), dec[i].strip()) if dec[i].strip() != 'none' else [\n",
    "        \"O\"]*len(texts[i].strip().split()) for i in range(len(texts))]\n",
    "\n",
    "    outputs.extend(dec)\n",
    "    targets.extend(target)\n",
    "    true_labels.extend(true_label)\n",
    "    pred_labels.extend(pred_label)\n",
    "    all_text.extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:17:33.521899Z",
     "iopub.status.busy": "2024-02-28T15:17:33.521562Z",
     "iopub.status.idle": "2024-02-28T15:17:35.880177Z",
     "shell.execute_reply": "2024-02-28T15:17:35.879656Z",
     "shell.execute_reply.started": "2024-02-28T15:17:33.521876Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2503/1300780915.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library  Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/datasets/load.py:753: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.1/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/seqeval/c8563af43bdce095d0f9e8b8b79c9c96d5ea5499b3bf66f90301c9cb82910f11 (last modified on Tue Feb 27 21:06:26 2024) since it couldn't be found locally at seqeval, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  garcia ponce , who said he was speaking on behalf of the entire cpr , pointed out that it would be  truly inconceivable '' that the interference of a state to approve or disapprove the decisions of another or other states became a trait of foreign policy . dse:pointed out\n",
      "Predicted Token Class:  ['B-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'B-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  in the eyes of japan and many us allies , the bush administration 's decision not to ratify the kyoto protocol is one of many signals that washington is growing increasingly unilateralist in the six months since the sept. 11 attacks on america . dse:in the eyes of\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'B-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  not everyone in japan is upset with bush 's alternative . dse:is upset\n",
      "Predicted Token Class:  ['B-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O']\n",
      "True Token Class:  ['B-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  which is also a bank , agreed in june to buy trustcorp for 12.4 million shares of stock with a market value of about $ 450 million . dse:agreed\n",
      "Predicted Token Class:  ['B-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  one of these people that believes that we should not be able to buy guns but i do n't think we should be carrying uzis either you know what i mean yeah i know i mean i do n't think machine guns automatic weapons i do n't believe in things like that but i think dse:do n't think\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  to the president 's misfortune , 80 percent of venezuelans believe there is a solution for the unemployment problem . dse:believe\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  john c. marous , chairman and chief executive officer , also said the company expects sales from continuing businesses to rise 8.5 % annually through the next three years . dse:expects\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'I-AGENT', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'I-AGENT', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  he said all parties concerned should work for resuming peace negotiations as soon as possible , based on the united nations resolutions on the middle east issues , the principle of land for peace and commitment to agreements and notes of understandings which have been reached . dse:said\n",
      "Predicted Token Class:  ['B-AGENT', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['B-AGENT', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  capitalizing on a major restructuring program , expects operating margins of more than 10 % and double-digit per-share earnings growth next year , top officers told securities analysts here . dse:expects\n",
      "Predicted Token Class:  ['B-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  mr. chretien , who this month headed off a move to suspend zimbabwe from the commonwealth in advance of the vote , said the election of mr. mugabe  does not look very good '' but insisted canada must wait for the results of a commonwealth report before acting . dse:said\n",
      "Predicted Token Class:  ['B-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['B-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "{'AGENT': {'precision': 0.7463054187192119, 'recall': 0.7625838926174496, 'f1': 0.754356846473029, 'number': 1192}, 'TARGET': {'precision': 0.5105820105820106, 'recall': 0.4613545816733068, 'f1': 0.4847216408539138, 'number': 1255}, 'overall_precision': 0.6326530612244898, 'overall_recall': 0.6080915406620352, 'overall_f1': 0.6201291935819964, 'overall_accuracy': 0.8762390257717361}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Text:  {all_text[i]}\")\n",
    "    print(f\"Predicted Token Class:  {pred_labels[i]}\")\n",
    "    print(f\"True Token Class:  {true_labels[i]}\")\n",
    "    print(\"=====================================================================\\n\")\n",
    "\n",
    "print(metric.compute(predictions=pred_labels, references=true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8h8R2bLDhjlc"
   },
   "source": [
    "# Model\n",
    "\n",
    "Majority of the code here is adapted from [here](https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb) which uses the pytorch-lightning framework for training neural networks. T5 has shown that it can generate state of the art on many tasks as long as it can be cast as a text-to-text problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:24:59.853431Z",
     "iopub.status.busy": "2024-02-27T12:24:59.853050Z",
     "iopub.status.idle": "2024-02-27T12:24:59.864657Z",
     "shell.execute_reply": "2024-02-27T12:24:59.863958Z",
     "shell.execute_reply.started": "2024-02-27T12:24:59.853410Z"
    },
    "id": "KL8_p4YS6H0a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "    def __init__(self, hparam):\n",
    "        super(T5FineTuner, self).__init__()\n",
    "        self.hparam = hparam\n",
    "\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "            hparam.model_name_or_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            hparam.model_name_or_path\n",
    "        )\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def is_logger(self):\n",
    "        return True\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
    "    ):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=lm_labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            lm_labels=lm_labels,\n",
    "            decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        tensorboard_logs = {\"train_loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparam.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.hparam.learning_rate, eps=self.hparam.adam_epsilon)\n",
    "        self.opt = optimizer\n",
    "        return [optimizer]\n",
    "\n",
    "    def optimizer_step(self,\n",
    "                       epoch=None,\n",
    "                       batch_idx=None,\n",
    "                       optimizer=None,\n",
    "                       optimizer_idx=None,\n",
    "                       optimizer_closure=None,\n",
    "                       on_tpu=None,\n",
    "                       using_native_amp=None,\n",
    "                       using_lbfgs=None\n",
    "                       ):\n",
    "\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "        optimizer.zero_grad()\n",
    "        self.lr_scheduler.step()\n",
    "\n",
    "    def get_tqdm_dict(self):\n",
    "        tqdm_dict = {\"loss\": \"{:.3f}\".format(\n",
    "            self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "\n",
    "        return tqdm_dict\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = get_dataset(\n",
    "            tokenizer=self.tokenizer, type_path=\"train\", args=self.hparam)\n",
    "        dataloader = DataLoader(train_dataset, batch_size=self.hparam.train_batch_size,\n",
    "                                drop_last=True, shuffle=True, num_workers=2)\n",
    "        t_total = (\n",
    "            (len(dataloader.dataset) //\n",
    "             (self.hparam.train_batch_size * max(1, self.hparam.n_gpu)))\n",
    "            // self.hparam.gradient_accumulation_steps\n",
    "            * float(self.hparam.num_train_epochs)\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.opt, num_warmup_steps=self.hparam.warmup_steps, num_training_steps=t_total\n",
    "        )\n",
    "        self.lr_scheduler = scheduler\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = get_dataset(\n",
    "            tokenizer=self.tokenizer, type_path=\"validation\", args=self.hparam)\n",
    "        return DataLoader(val_dataset, batch_size=self.hparam.eval_batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:01.768401Z",
     "iopub.status.busy": "2024-02-27T12:25:01.767846Z",
     "iopub.status.idle": "2024-02-27T12:25:01.773286Z",
     "shell.execute_reply": "2024-02-27T12:25:01.772660Z",
     "shell.execute_reply.started": "2024-02-27T12:25:01.768381Z"
    },
    "id": "6VQpUMNe6Wf8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LoggingCallback(pl.Callback):\n",
    "  def on_validation_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Validation results *****\")\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "      # Log results\n",
    "      for key in sorted(metrics):\n",
    "        if key not in [\"log\", \"progress_bar\"]:\n",
    "          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "  def on_test_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Test results *****\")\n",
    "\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "\n",
    "      # Log and save results to file\n",
    "      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
    "      with open(output_test_results_file, \"w\") as writer:\n",
    "        for key in sorted(metrics):\n",
    "          if key not in [\"log\", \"progress_bar\"]:\n",
    "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:02.692693Z",
     "iopub.status.busy": "2024-02-27T12:25:02.692356Z",
     "iopub.status.idle": "2024-02-27T12:25:02.697059Z",
     "shell.execute_reply": "2024-02-27T12:25:02.696544Z",
     "shell.execute_reply.started": "2024-02-27T12:25:02.692672Z"
    },
    "id": "I55QMghp6YbE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args_dict = dict(\n",
    "    data_dir=\"wikiann\", # path for data files\n",
    "    output_dir=\"\", # path to save the checkpoints\n",
    "    model_name_or_path='t5-small',\n",
    "    tokenizer_name_or_path='t5-small',\n",
    "    max_seq_length=256,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    gradient_accumulation_steps=16,\n",
    "    n_gpu=1,\n",
    "    early_stop_callback=False,\n",
    "    fp_16=True, # if you want to enable 16-bit training then install apex and set this to true\n",
    "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
    "    max_grad_norm=1, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxV5l0Wcinfb"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "Here, I used the popular [WikiANN](https://https://huggingface.co/datasets/wikiann) dataset which is a multilingual named entity recognition dataset consisting of Wikipedia articles annotated with LOC (location), PER (person), and ORG (organisation) tags in the IOB2 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "b112c9a8184d4b479fc0e59698789b43",
      "e550224ab580420cb4973b805c2393af",
      "ebcc288979ff4cd5901e9223063751d1",
      "304c605d63584a298e8cefd4ffcf4ead",
      "7ca93c1fe9a9415e9c7d6f22a58b90d1",
      "56496f0e8cef4b5cb989f289af418f9f",
      "388d8e1e34a143c3afe9e4082be44ebb",
      "5d88a23982ac46b3b8077264a6998b9a",
      "dfdd904fb4924ad8948793222255cc3b",
      "43278de125c54c1e8b55baa0370c4cc1",
      "fa0489927bdd4bf4809c9fcc92d9d7b4"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:09.149655Z",
     "iopub.status.busy": "2024-02-27T12:25:09.149329Z",
     "iopub.status.idle": "2024-02-27T12:25:26.708433Z",
     "shell.execute_reply": "2024-02-27T12:25:26.707926Z",
     "shell.execute_reply.started": "2024-02-27T12:25:09.149635Z"
    },
    "id": "soCZS7n07Ts1",
    "outputId": "6e0d1772-838a-414e-b028-e6362faeb653",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikiann\", \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:26.709771Z",
     "iopub.status.busy": "2024-02-27T12:25:26.709381Z",
     "iopub.status.idle": "2024-02-27T12:25:26.713447Z",
     "shell.execute_reply": "2024-02-27T12:25:26.712901Z",
     "shell.execute_reply.started": "2024-02-27T12:25:26.709753Z"
    },
    "id": "7eSAir8g80rm",
    "outputId": "aaf53c53-939a-424a-e625-9ba8059fee67",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 20000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:26.714288Z",
     "iopub.status.busy": "2024-02-27T12:25:26.713990Z",
     "iopub.status.idle": "2024-02-27T12:25:26.720368Z",
     "shell.execute_reply": "2024-02-27T12:25:26.719900Z",
     "shell.execute_reply.started": "2024-02-27T12:25:26.714273Z"
    },
    "id": "cWCXP8F373Nm",
    "outputId": "bc803c3d-6947-4c16-eb68-0fde40b8289c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R.H. Saunders ( St. Lawrence River ) ( 968 MW )'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(dataset['train'][0]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:26.721462Z",
     "iopub.status.busy": "2024-02-27T12:25:26.721156Z",
     "iopub.status.idle": "2024-02-27T12:25:26.725372Z",
     "shell.execute_reply": "2024-02-27T12:25:26.724914Z",
     "shell.execute_reply.started": "2024-02-27T12:25:26.721445Z"
    },
    "id": "rXjs7Khn9oi6",
    "outputId": "c96fa06e-f32d-4cad-bd85-513ffde91282",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['R.H.',\n",
       "  'Saunders',\n",
       "  '(',\n",
       "  'St.',\n",
       "  'Lawrence',\n",
       "  'River',\n",
       "  ')',\n",
       "  '(',\n",
       "  '968',\n",
       "  'MW',\n",
       "  ')'],\n",
       " 'ner_tags': [3, 4, 0, 3, 4, 4, 0, 0, 0, 0, 0],\n",
       " 'langs': ['en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en'],\n",
       " 'spans': ['ORG: R.H. Saunders', 'ORG: St. Lawrence River']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5KDQPACi8FT"
   },
   "source": [
    "In this section, we create a custom dataset class where we cast the NER task as a text to text problem. This is done by concatenating the spans in the data as one line of string separated by a semi-colon (;). e.g\n",
    "\n",
    "*   **Input**: R.H. Saunders ( St. Lawrence River ) ( 968 MW )\n",
    "*   **Target**: ORG: R.H. Saunders; ORG: St. Lawrence River\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:28.595917Z",
     "iopub.status.busy": "2024-02-27T12:25:28.595563Z",
     "iopub.status.idle": "2024-02-27T12:25:28.602276Z",
     "shell.execute_reply": "2024-02-27T12:25:28.601623Z",
     "shell.execute_reply.started": "2024-02-27T12:25:28.595896Z"
    },
    "id": "LgZKb7T48Mzw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WikiAnnDataset(Dataset):\n",
    "  def __init__(self, tokenizer, dataset, type_path, max_len=512):\n",
    "\n",
    "    self.data = dataset[type_path]\n",
    "    self.max_len = max_len\n",
    "    self.tokenizer = tokenizer\n",
    "    self.tokenizer.max_length = max_len\n",
    "    self.tokenizer.model_max_length = max_len\n",
    "    self.inputs = []\n",
    "    self.targets = []\n",
    "\n",
    "    self._build()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.inputs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
    "    target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
    "\n",
    "    src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "    target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "\n",
    "    return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "\n",
    "  def _build(self):\n",
    "    for idx in range(len(self.data)):\n",
    "      input_, target = \" \".join(self.data[idx][\"tokens\"]), \"; \".join(self.data[idx][\"spans\"])\n",
    "\n",
    "      input_ = input_.lower() + ' </s>'\n",
    "      target = target.lower() + \" </s>\"\n",
    "\n",
    "       # tokenize inputs\n",
    "      tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
    "          [input_], max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "      )\n",
    "       # tokenize targets\n",
    "      tokenized_targets = self.tokenizer.batch_encode_plus(\n",
    "          [target],max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "      )\n",
    "\n",
    "      self.inputs.append(tokenized_inputs)\n",
    "      self.targets.append(tokenized_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:33.140341Z",
     "iopub.status.busy": "2024-02-27T12:25:33.140007Z",
     "iopub.status.idle": "2024-02-27T12:25:42.716000Z",
     "shell.execute_reply": "2024-02-27T12:25:42.715500Z",
     "shell.execute_reply.started": "2024-02-27T12:25:33.140323Z"
    },
    "id": "XrlJEayI-4tS",
    "outputId": "97284917-3b24-462e-fd2c-930f0061f79f",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5TokenizerFast(name_or_path='../T5-base', vocab_size=32100, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32000: AddedToken(\"<extra_id_99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32001: AddedToken(\"<extra_id_98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32002: AddedToken(\"<extra_id_97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32003: AddedToken(\"<extra_id_96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32004: AddedToken(\"<extra_id_95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32005: AddedToken(\"<extra_id_94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32006: AddedToken(\"<extra_id_93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32007: AddedToken(\"<extra_id_92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32008: AddedToken(\"<extra_id_91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32009: AddedToken(\"<extra_id_90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32010: AddedToken(\"<extra_id_89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32011: AddedToken(\"<extra_id_88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32012: AddedToken(\"<extra_id_87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32013: AddedToken(\"<extra_id_86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32014: AddedToken(\"<extra_id_85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32015: AddedToken(\"<extra_id_84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32016: AddedToken(\"<extra_id_83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32017: AddedToken(\"<extra_id_82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32018: AddedToken(\"<extra_id_81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32019: AddedToken(\"<extra_id_80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32020: AddedToken(\"<extra_id_79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32021: AddedToken(\"<extra_id_78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32022: AddedToken(\"<extra_id_77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32023: AddedToken(\"<extra_id_76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32024: AddedToken(\"<extra_id_75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32025: AddedToken(\"<extra_id_74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32026: AddedToken(\"<extra_id_73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32027: AddedToken(\"<extra_id_72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32028: AddedToken(\"<extra_id_71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32029: AddedToken(\"<extra_id_70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32030: AddedToken(\"<extra_id_69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32031: AddedToken(\"<extra_id_68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32032: AddedToken(\"<extra_id_67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32033: AddedToken(\"<extra_id_66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32034: AddedToken(\"<extra_id_65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32035: AddedToken(\"<extra_id_64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32036: AddedToken(\"<extra_id_63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32037: AddedToken(\"<extra_id_62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32038: AddedToken(\"<extra_id_61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32039: AddedToken(\"<extra_id_60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32040: AddedToken(\"<extra_id_59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32041: AddedToken(\"<extra_id_58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32042: AddedToken(\"<extra_id_57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32043: AddedToken(\"<extra_id_56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32044: AddedToken(\"<extra_id_55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32045: AddedToken(\"<extra_id_54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32046: AddedToken(\"<extra_id_53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32047: AddedToken(\"<extra_id_52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32048: AddedToken(\"<extra_id_51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32049: AddedToken(\"<extra_id_50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32050: AddedToken(\"<extra_id_49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32051: AddedToken(\"<extra_id_48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32052: AddedToken(\"<extra_id_47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32053: AddedToken(\"<extra_id_46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32054: AddedToken(\"<extra_id_45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32055: AddedToken(\"<extra_id_44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32056: AddedToken(\"<extra_id_43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32057: AddedToken(\"<extra_id_42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32058: AddedToken(\"<extra_id_41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32059: AddedToken(\"<extra_id_40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32060: AddedToken(\"<extra_id_39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32061: AddedToken(\"<extra_id_38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32062: AddedToken(\"<extra_id_37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32063: AddedToken(\"<extra_id_36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32064: AddedToken(\"<extra_id_35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32065: AddedToken(\"<extra_id_34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32066: AddedToken(\"<extra_id_33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32067: AddedToken(\"<extra_id_32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32068: AddedToken(\"<extra_id_31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32069: AddedToken(\"<extra_id_30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32070: AddedToken(\"<extra_id_29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32071: AddedToken(\"<extra_id_28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32072: AddedToken(\"<extra_id_27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32073: AddedToken(\"<extra_id_26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32074: AddedToken(\"<extra_id_25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32075: AddedToken(\"<extra_id_24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32076: AddedToken(\"<extra_id_23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32077: AddedToken(\"<extra_id_22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32078: AddedToken(\"<extra_id_21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32079: AddedToken(\"<extra_id_20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32080: AddedToken(\"<extra_id_19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32081: AddedToken(\"<extra_id_18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32082: AddedToken(\"<extra_id_17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32083: AddedToken(\"<extra_id_16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32084: AddedToken(\"<extra_id_15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32085: AddedToken(\"<extra_id_14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32086: AddedToken(\"<extra_id_13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32087: AddedToken(\"<extra_id_12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32088: AddedToken(\"<extra_id_11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32089: AddedToken(\"<extra_id_10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32090: AddedToken(\"<extra_id_9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32091: AddedToken(\"<extra_id_8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32092: AddedToken(\"<extra_id_7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32093: AddedToken(\"<extra_id_6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32094: AddedToken(\"<extra_id_5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32095: AddedToken(\"<extra_id_4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32096: AddedToken(\"<extra_id_3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32097: AddedToken(\"<extra_id_2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32098: AddedToken(\"<extra_id_1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32099: AddedToken(\"<extra_id_0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../T5-base\")\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "input_dataset = WikiAnnDataset(tokenizer=tokenizer, dataset=dataset, type_path='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:42.717524Z",
     "iopub.status.busy": "2024-02-27T12:25:42.717015Z",
     "iopub.status.idle": "2024-02-27T12:25:42.871971Z",
     "shell.execute_reply": "2024-02-27T12:25:42.871475Z",
     "shell.execute_reply.started": "2024-02-27T12:25:42.717506Z"
    },
    "id": "Cyrnvv1zTKaw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(input_dataset)):\n",
    "    _ = input_dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:42.873108Z",
     "iopub.status.busy": "2024-02-27T12:25:42.872825Z",
     "iopub.status.idle": "2024-02-27T12:25:42.876923Z",
     "shell.execute_reply": "2024-02-27T12:25:42.876466Z",
     "shell.execute_reply.started": "2024-02-27T12:25:42.873090Z"
    },
    "id": "OJ02SXgv_UW8",
    "outputId": "5c541c8e-9376-47ed-bc9f-7e138caee0e7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r.h. saunders ( st. lawrence river ) ( 968 mw )</s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "org: r.h. saunders; org: st. lawrence river</s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "data = input_dataset[0]\n",
    "\n",
    "print(tokenizer.decode(data[\"source_ids\"], skip_special_tokens=False))\n",
    "print(tokenizer.decode(data[\"target_ids\"], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:43.437406Z",
     "iopub.status.busy": "2024-02-27T12:25:43.437088Z",
     "iopub.status.idle": "2024-02-27T12:25:43.685932Z",
     "shell.execute_reply": "2024-02-27T12:25:43.685362Z",
     "shell.execute_reply.started": "2024-02-27T12:25:43.437387Z"
    },
    "id": "Sepl17_eCHy4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p t5_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:53.021540Z",
     "iopub.status.busy": "2024-02-27T12:25:53.021188Z",
     "iopub.status.idle": "2024-02-27T12:25:54.752236Z",
     "shell.execute_reply": "2024-02-27T12:25:54.751686Z",
     "shell.execute_reply.started": "2024-02-27T12:25:53.021519Z"
    },
    "id": "4Toa_qnXDrTw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace(**args_dict)\n",
    "model = T5FineTuner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:57.604520Z",
     "iopub.status.busy": "2024-02-27T12:25:57.604156Z",
     "iopub.status.idle": "2024-02-27T12:25:57.608734Z",
     "shell.execute_reply": "2024-02-27T12:25:57.608252Z",
     "shell.execute_reply.started": "2024-02-27T12:25:57.604493Z"
    },
    "id": "dIZ3LwE3DXNo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    filename=args.output_dir+\"/checkpoint.pth\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    #early_stop_callback=False,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    #amp_level=args.opt_level,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    callbacks=[LoggingCallback()],\n",
    ")\n",
    "\n",
    "# train_params = dict(\n",
    "#     accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "#     ## gpus=args.n_gpu,\n",
    "#     max_epochs=args.num_train_epochs,\n",
    "#     #early_stop_callback=False,\n",
    "#     precision= 16 if args.fp_16 else 32,\n",
    "#     #amp_level=args.opt_level,\n",
    "#     gradient_clip_val=args.max_grad_norm,\n",
    "#     # callbacks=[LoggingCallback()],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:26:01.158877Z",
     "iopub.status.busy": "2024-02-27T12:26:01.158529Z",
     "iopub.status.idle": "2024-02-27T12:26:01.162217Z",
     "shell.execute_reply": "2024-02-27T12:26:01.161716Z",
     "shell.execute_reply.started": "2024-02-27T12:26:01.158856Z"
    },
    "id": "MxBEgT6MDqe3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset(tokenizer, type_path, args):\n",
    "    tokenizer.max_length = args.max_seq_length\n",
    "    tokenizer.model_max_length = args.max_seq_length\n",
    "    dataset = load_dataset(args.data_dir, \"en\")\n",
    "    return WikiAnnDataset(tokenizer=tokenizer, dataset=dataset, type_path=type_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:26:01.731175Z",
     "iopub.status.busy": "2024-02-27T12:26:01.730847Z",
     "iopub.status.idle": "2024-02-27T12:26:01.738097Z",
     "shell.execute_reply": "2024-02-27T12:26:01.737626Z",
     "shell.execute_reply.started": "2024-02-27T12:26:01.731149Z"
    },
    "id": "KCKmlJ5DDaHw",
    "outputId": "e5db4e86-8699-475a-a794-cc03d8b615cc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f6e53eb2f70>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f6e53eb2f70>)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445,
     "referenced_widgets": [
      "d2b327e2b0074354a6b889afc169a62e",
      "84ab2eb4f0b74ac3a334eb7ecd7c4d63",
      "f8ebf6d2f2954cbbb525e67de58a766a",
      "a0a3db286a1843b293b1d3b944a3d33a",
      "d68d5a7c97bd47719eb1e19f67d64805",
      "1fac6af61b4d411a94f3916061731428",
      "127c67d7658d4bf392408e7d5600a09c",
      "25b71debb82040a2960eb8348df2a4ca",
      "9428191170994f0aa7fd400caf0d1d07",
      "ef4fa30c44df4726a36cfc1da100fb4f",
      "dffd33c1015f4bfd91fd702095c2127e",
      "ba1298c2f3db42c48b7e3e3ee83d5000",
      "0e46dd857d504def992f555a9e9c9c5f",
      "285649e2ae134f87bd2f8dcf40a7758d",
      "83ec7a9ea11e410bb3fcad13c082d664",
      "5fd2178313d34631a030d79934dcffe0",
      "c3c43f7938044239b4eca004d07874ae",
      "b3e24f0b77884455868b103ab69ddd5d",
      "79385887dd0f479d993b251748f8cb2f",
      "429fbc36c65446d09d32298cfc4b606e",
      "b449b3c3b1b944a38293f2f13d517860",
      "c4dc2a989d794b44b8000ca88cf095fa",
      "97e269fbcb954d629b2314d30c41c57b",
      "84c7612e3ed740958159eec4ee147476",
      "93c2ea7279794b88b6264f832400e3c7",
      "45340f3b0bf4413182060f27c7458334",
      "6bf0078bd11d4ed980f1b7a9b612a091",
      "4fb2b190729943cb8c1f1fd2b84d6935",
      "a5a571c48de54900b2b696f2c6817a2e",
      "966b77941ef046babfb1e9ed597a6aee",
      "f16174670d2c4182ace507dda7812328",
      "e61579f72d51414782f8fe3c28e12e86",
      "dbcd62725c684fcc897583042ca44888",
      "ba6f4922558c41fea4a4b171a021b871",
      "5587ced0255640dd9bec68478cd973fb",
      "48bb2d6d069e411a9e969187d5ddf17d",
      "4fffbd7c89314024a7b8c128ad1ba248",
      "dea06faaa22b41b6bbfd7ff6d8ee39f6",
      "347f2c97cd4f46aa8bd1d30f79041b29",
      "81211b58e69b4973a9e1b500e621656b",
      "ce97e8d1d6b54e17a16ec75e1b3abf7f",
      "5d4e33c5404f49caa4811bfd55b0bee5",
      "d37bf18a5e9346fcb59242e0e5288307",
      "005a930db3d242a4be28a9c5923eed76",
      "0573bd35717d4189ab4d74fdc489653b",
      "06e6627b73a24e4291f316a281a20aea",
      "bd7b7a9f5f80492997ec2cbd4bf22627",
      "1b08c691a8db4cb79e6f7837a08ac799",
      "b904bbebe38943728a23a0d630f86a88",
      "9cd468cf60c643db96d0cd35923c8258",
      "cddc7d98bbb740a9a81bf8e244d4595d",
      "cfcb95376da04ce884ab18c57c2d63ed",
      "f69895f136a14e629614a45f2e7d8557",
      "47144694b20f49f0aa54ee1d83119fda",
      "3898654592194daca51999f513192a24",
      "39ceb75a4fa14f6e9a8a5f4ae1324cbc",
      "49901550f7c14e439505f80faaaa8357",
      "4bba40ddade644b79cce613925a4f47e",
      "aa38ae45e85545bebec6c8b43db7abbf",
      "37a7f3f9244a4fd991fe9e8847268ec1",
      "b537afbec50e4567885220cf27a5b761",
      "ce10ff94a3454674a5deb511394387ff",
      "be10758757c1426c8779c6706a445ecd",
      "d26f30f1432e4f2ab1c53484b44989ee",
      "0305993a3c1a4f8296faeb1aba61fa38",
      "fce9ba2896164d4391fea7f32dc3d811",
      "ffe6027ef4bb4fd9964717116a39f1a3",
      "4b15ff3c6b044b40a15b21f051bf53c8",
      "3ddd6cf350fb4378ad6cf2698f67d68f",
      "ceca8a9a02fe46d5a1a3aa093fdbcde7",
      "20d7306a9b474da3b0c8e80a3d7abe09",
      "3b924323276f4f92a66a64d295ba6c78",
      "21b88aca18f048759fb25ce63540c992",
      "b58e5e54e53e46d7a4f196a93812373c",
      "b849b43f5c4649deb018fb959191edc5",
      "95d7c71216094ea0b466a79efc95341d",
      "264fdba12e854d54b3ed2510458c7a1b"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:26:10.156541Z",
     "iopub.status.busy": "2024-02-27T12:26:10.156209Z",
     "iopub.status.idle": "2024-02-27T12:50:26.838508Z",
     "shell.execute_reply": "2024-02-27T12:50:26.837953Z",
     "shell.execute_reply.started": "2024-02-27T12:26:10.156522Z"
    },
    "id": "sxQ-s0izFQGQ",
    "outputId": "fd7d2eef-efef-4367-dcc3-70ff9e3d18fb",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:102: UserWarning: When using `Trainer(accumulate_grad_batches != 1)` and overriding `LightningModule.optimizer_{step,zero_grad}`, the hooks will not be called on every batch (rather, they are called on every optimization step).\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "121.013   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/3750 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/closure.py:35: LightningDeprecationWarning: One of the returned values {'log'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|   | 2500/3750 [06:36<03:18,  6.30it/s, loss=0.138, v_num=0] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1250 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  67%|   | 2502/3750 [06:37<03:18,  6.30it/s, loss=0.138, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  67%|   | 2504/3750 [06:37<03:17,  6.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|   | 2506/3750 [06:37<03:17,  6.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|   | 2508/3750 [06:37<03:16,  6.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|   | 2510/3750 [06:37<03:16,  6.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|   | 2512/3750 [06:37<03:15,  6.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|   | 2514/3750 [06:37<03:15,  6.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|   | 2516/3750 [06:37<03:15,  6.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|   | 2518/3750 [06:37<03:14,  6.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|   | 2520/3750 [06:38<03:14,  6.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|   | 2522/3750 [06:38<03:13,  6.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|   | 2524/3750 [06:38<03:13,  6.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|   | 2526/3750 [06:38<03:13,  6.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|   | 2528/3750 [06:38<03:12,  6.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|   | 2530/3750 [06:38<03:12,  6.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2532/3750 [06:38<03:11,  6.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2534/3750 [06:38<03:11,  6.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2536/3750 [06:38<03:10,  6.36it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2538/3750 [06:39<03:10,  6.36it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2540/3750 [06:39<03:10,  6.36it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2542/3750 [06:39<03:09,  6.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2544/3750 [06:39<03:09,  6.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2546/3750 [06:39<03:08,  6.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2548/3750 [06:39<03:08,  6.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2550/3750 [06:39<03:08,  6.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2552/3750 [06:39<03:07,  6.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2554/3750 [06:39<03:07,  6.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2556/3750 [06:40<03:06,  6.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2558/3750 [06:40<03:06,  6.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2560/3750 [06:40<03:06,  6.40it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2562/3750 [06:40<03:05,  6.40it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2564/3750 [06:40<03:05,  6.40it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2566/3750 [06:40<03:04,  6.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|   | 2568/3750 [06:40<03:04,  6.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2570/3750 [06:40<03:04,  6.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2572/3750 [06:40<03:03,  6.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2574/3750 [06:41<03:03,  6.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2576/3750 [06:41<03:02,  6.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2578/3750 [06:41<03:02,  6.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2580/3750 [06:41<03:02,  6.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2582/3750 [06:41<03:01,  6.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2584/3750 [06:41<03:01,  6.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2586/3750 [06:41<03:00,  6.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2588/3750 [06:41<03:00,  6.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2590/3750 [06:41<03:00,  6.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2592/3750 [06:42<02:59,  6.45it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2594/3750 [06:42<02:59,  6.45it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2596/3750 [06:42<02:58,  6.45it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2598/3750 [06:42<02:58,  6.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2600/3750 [06:42<02:58,  6.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2602/3750 [06:42<02:57,  6.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2604/3750 [06:42<02:57,  6.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|   | 2606/3750 [06:42<02:56,  6.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2608/3750 [06:42<02:56,  6.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2610/3750 [06:43<02:56,  6.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2612/3750 [06:43<02:55,  6.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2614/3750 [06:43<02:55,  6.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2616/3750 [06:43<02:54,  6.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2618/3750 [06:43<02:54,  6.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2620/3750 [06:43<02:54,  6.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2622/3750 [06:43<02:53,  6.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2624/3750 [06:43<02:53,  6.50it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2626/3750 [06:43<02:52,  6.50it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2628/3750 [06:44<02:52,  6.50it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2630/3750 [06:44<02:52,  6.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2632/3750 [06:44<02:51,  6.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2634/3750 [06:44<02:51,  6.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2636/3750 [06:44<02:50,  6.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2638/3750 [06:44<02:50,  6.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2640/3750 [06:44<02:50,  6.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|   | 2642/3750 [06:44<02:49,  6.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2644/3750 [06:45<02:49,  6.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2646/3750 [06:45<02:49,  6.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2648/3750 [06:45<02:48,  6.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2650/3750 [06:45<02:48,  6.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2652/3750 [06:45<02:47,  6.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2654/3750 [06:45<02:47,  6.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2656/3750 [06:45<02:47,  6.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2658/3750 [06:45<02:46,  6.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2660/3750 [06:45<02:46,  6.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2662/3750 [06:46<02:45,  6.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2664/3750 [06:46<02:45,  6.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2666/3750 [06:46<02:45,  6.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2668/3750 [06:46<02:44,  6.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|   | 2670/3750 [06:46<02:44,  6.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|  | 2672/3750 [06:46<02:44,  6.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|  | 2674/3750 [06:46<02:43,  6.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|  | 2676/3750 [06:46<02:43,  6.58it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|  | 2678/3750 [06:46<02:42,  6.58it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|  | 2680/3750 [06:47<02:42,  6.58it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2682/3750 [06:47<02:42,  6.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2684/3750 [06:47<02:41,  6.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2686/3750 [06:47<02:41,  6.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2688/3750 [06:47<02:40,  6.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2690/3750 [06:47<02:40,  6.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2692/3750 [06:47<02:40,  6.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2694/3750 [06:47<02:39,  6.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2696/3750 [06:47<02:39,  6.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2698/3750 [06:48<02:39,  6.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2700/3750 [06:48<02:38,  6.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2702/3750 [06:48<02:38,  6.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2704/3750 [06:48<02:37,  6.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2706/3750 [06:48<02:37,  6.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2708/3750 [06:48<02:37,  6.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2710/3750 [06:48<02:36,  6.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2712/3750 [06:48<02:36,  6.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2714/3750 [06:48<02:36,  6.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2716/3750 [06:49<02:35,  6.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|  | 2718/3750 [06:49<02:35,  6.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2720/3750 [06:49<02:34,  6.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2722/3750 [06:49<02:34,  6.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2724/3750 [06:49<02:34,  6.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2726/3750 [06:49<02:33,  6.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2728/3750 [06:49<02:33,  6.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2730/3750 [06:49<02:33,  6.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2732/3750 [06:49<02:32,  6.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2734/3750 [06:50<02:32,  6.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2736/3750 [06:50<02:32,  6.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2738/3750 [06:50<02:31,  6.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2740/3750 [06:50<02:31,  6.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2742/3750 [06:50<02:30,  6.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2744/3750 [06:50<02:30,  6.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2746/3750 [06:50<02:30,  6.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2748/3750 [06:50<02:29,  6.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2750/3750 [06:50<02:29,  6.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2752/3750 [06:51<02:29,  6.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2754/3750 [06:51<02:28,  6.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|  | 2756/3750 [06:51<02:28,  6.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2758/3750 [06:51<02:27,  6.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2760/3750 [06:51<02:27,  6.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2762/3750 [06:51<02:27,  6.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2764/3750 [06:51<02:26,  6.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2766/3750 [06:51<02:26,  6.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2768/3750 [06:52<02:26,  6.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2770/3750 [06:52<02:25,  6.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2772/3750 [06:52<02:25,  6.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2774/3750 [06:52<02:25,  6.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2776/3750 [06:52<02:24,  6.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2778/3750 [06:52<02:24,  6.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2780/3750 [06:52<02:23,  6.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2782/3750 [06:52<02:23,  6.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2784/3750 [06:52<02:23,  6.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2786/3750 [06:53<02:22,  6.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2788/3750 [06:53<02:22,  6.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2790/3750 [06:53<02:22,  6.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|  | 2792/3750 [06:53<02:21,  6.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2794/3750 [06:53<02:21,  6.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2796/3750 [06:53<02:21,  6.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2798/3750 [06:53<02:20,  6.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2800/3750 [06:53<02:20,  6.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2802/3750 [06:53<02:20,  6.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2804/3750 [06:54<02:19,  6.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2806/3750 [06:54<02:19,  6.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2808/3750 [06:54<02:18,  6.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2810/3750 [06:54<02:18,  6.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2812/3750 [06:54<02:18,  6.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2814/3750 [06:54<02:17,  6.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2816/3750 [06:54<02:17,  6.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2818/3750 [06:54<02:17,  6.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2820/3750 [06:54<02:16,  6.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2822/3750 [06:55<02:16,  6.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2824/3750 [06:55<02:16,  6.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2826/3750 [06:55<02:15,  6.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2828/3750 [06:55<02:15,  6.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|  | 2830/3750 [06:55<02:15,  6.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2832/3750 [06:55<02:14,  6.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2834/3750 [06:55<02:14,  6.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2836/3750 [06:55<02:14,  6.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2838/3750 [06:55<02:13,  6.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2840/3750 [06:56<02:13,  6.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2842/3750 [06:56<02:12,  6.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2844/3750 [06:56<02:12,  6.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2846/3750 [06:56<02:12,  6.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2848/3750 [06:56<02:11,  6.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2850/3750 [06:56<02:11,  6.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2852/3750 [06:56<02:11,  6.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2854/3750 [06:56<02:10,  6.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2856/3750 [06:56<02:10,  6.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2858/3750 [06:57<02:10,  6.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2860/3750 [06:57<02:09,  6.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2862/3750 [06:57<02:09,  6.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2864/3750 [06:57<02:09,  6.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2866/3750 [06:57<02:08,  6.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|  | 2868/3750 [06:57<02:08,  6.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2870/3750 [06:57<02:08,  6.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2872/3750 [06:57<02:07,  6.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2874/3750 [06:57<02:07,  6.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2876/3750 [06:58<02:07,  6.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2878/3750 [06:58<02:06,  6.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2880/3750 [06:58<02:06,  6.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2882/3750 [06:58<02:06,  6.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2884/3750 [06:58<02:05,  6.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2886/3750 [06:58<02:05,  6.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2888/3750 [06:58<02:04,  6.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2890/3750 [06:58<02:04,  6.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2892/3750 [06:58<02:04,  6.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2894/3750 [06:59<02:03,  6.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2896/3750 [06:59<02:03,  6.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2898/3750 [06:59<02:03,  6.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2900/3750 [06:59<02:02,  6.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2902/3750 [06:59<02:02,  6.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2904/3750 [06:59<02:02,  6.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|  | 2906/3750 [06:59<02:01,  6.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2908/3750 [06:59<02:01,  6.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2910/3750 [07:00<02:01,  6.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2912/3750 [07:00<02:00,  6.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2914/3750 [07:00<02:00,  6.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2916/3750 [07:00<02:00,  6.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2918/3750 [07:00<01:59,  6.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2920/3750 [07:00<01:59,  6.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2922/3750 [07:00<01:59,  6.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2924/3750 [07:00<01:58,  6.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2926/3750 [07:00<01:58,  6.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2928/3750 [07:01<01:58,  6.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2930/3750 [07:01<01:57,  6.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2932/3750 [07:01<01:57,  6.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2934/3750 [07:01<01:57,  6.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2936/3750 [07:01<01:56,  6.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2938/3750 [07:01<01:56,  6.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2940/3750 [07:01<01:56,  6.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|  | 2942/3750 [07:01<01:55,  6.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2944/3750 [07:01<01:55,  6.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2946/3750 [07:02<01:55,  6.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2948/3750 [07:02<01:54,  6.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2950/3750 [07:02<01:54,  6.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2952/3750 [07:02<01:54,  6.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2954/3750 [07:02<01:53,  6.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2956/3750 [07:02<01:53,  6.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2958/3750 [07:02<01:53,  7.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2960/3750 [07:02<01:52,  7.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2962/3750 [07:02<01:52,  7.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2964/3750 [07:03<01:52,  7.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2966/3750 [07:03<01:51,  7.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2968/3750 [07:03<01:51,  7.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2970/3750 [07:03<01:51,  7.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2972/3750 [07:03<01:50,  7.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2974/3750 [07:03<01:50,  7.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2976/3750 [07:03<01:50,  7.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2978/3750 [07:03<01:49,  7.03it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|  | 2980/3750 [07:03<01:49,  7.03it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 2982/3750 [07:04<01:49,  7.03it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 2984/3750 [07:04<01:48,  7.03it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 2986/3750 [07:04<01:48,  7.04it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 2988/3750 [07:04<01:48,  7.04it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 2990/3750 [07:04<01:47,  7.04it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 2992/3750 [07:04<01:47,  7.05it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 2994/3750 [07:04<01:47,  7.05it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 2996/3750 [07:04<01:46,  7.05it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 2998/3750 [07:04<01:46,  7.05it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 3000/3750 [07:05<01:46,  7.06it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 3002/3750 [07:05<01:45,  7.06it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 3004/3750 [07:05<01:45,  7.06it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 3006/3750 [07:05<01:45,  7.07it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 3008/3750 [07:05<01:44,  7.07it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 3010/3750 [07:05<01:44,  7.07it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 3012/3750 [07:05<01:44,  7.07it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 3014/3750 [07:05<01:43,  7.08it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 3016/3750 [07:05<01:43,  7.08it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|  | 3018/3750 [07:06<01:43,  7.08it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3020/3750 [07:06<01:43,  7.09it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3022/3750 [07:06<01:42,  7.09it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3024/3750 [07:06<01:42,  7.09it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3026/3750 [07:06<01:42,  7.09it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3028/3750 [07:06<01:41,  7.10it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3030/3750 [07:06<01:41,  7.10it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3032/3750 [07:06<01:41,  7.10it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3034/3750 [07:06<01:40,  7.11it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3036/3750 [07:07<01:40,  7.11it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3038/3750 [07:07<01:40,  7.11it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3040/3750 [07:07<01:39,  7.11it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3042/3750 [07:07<01:39,  7.12it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3044/3750 [07:07<01:39,  7.12it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|  | 3046/3750 [07:07<01:38,  7.12it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%| | 3048/3750 [07:07<01:38,  7.13it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%| | 3050/3750 [07:07<01:38,  7.13it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%| | 3052/3750 [07:08<01:37,  7.13it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%| | 3054/3750 [07:08<01:37,  7.13it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%| | 3056/3750 [07:08<01:37,  7.14it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3058/3750 [07:08<01:36,  7.14it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3060/3750 [07:08<01:36,  7.14it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3062/3750 [07:08<01:36,  7.14it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3064/3750 [07:08<01:35,  7.15it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3066/3750 [07:08<01:35,  7.15it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3068/3750 [07:08<01:35,  7.15it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3070/3750 [07:09<01:35,  7.16it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3072/3750 [07:09<01:34,  7.16it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3074/3750 [07:09<01:34,  7.16it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3076/3750 [07:09<01:34,  7.16it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3078/3750 [07:09<01:33,  7.17it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3080/3750 [07:09<01:33,  7.17it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3082/3750 [07:09<01:33,  7.17it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3084/3750 [07:09<01:32,  7.18it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3086/3750 [07:09<01:32,  7.18it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3088/3750 [07:10<01:32,  7.18it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3090/3750 [07:10<01:31,  7.18it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%| | 3092/3750 [07:10<01:31,  7.19it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3094/3750 [07:10<01:31,  7.19it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3096/3750 [07:10<01:30,  7.19it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3098/3750 [07:10<01:30,  7.19it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3100/3750 [07:10<01:30,  7.20it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3102/3750 [07:10<01:30,  7.20it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3104/3750 [07:10<01:29,  7.20it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3106/3750 [07:11<01:29,  7.21it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3108/3750 [07:11<01:29,  7.21it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3110/3750 [07:11<01:28,  7.21it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3112/3750 [07:11<01:28,  7.21it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3114/3750 [07:11<01:28,  7.22it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3116/3750 [07:11<01:27,  7.22it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3118/3750 [07:11<01:27,  7.22it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3120/3750 [07:11<01:27,  7.22it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3122/3750 [07:11<01:26,  7.23it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3124/3750 [07:12<01:26,  7.23it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3126/3750 [07:12<01:26,  7.23it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3128/3750 [07:12<01:25,  7.24it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%| | 3130/3750 [07:12<01:25,  7.24it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3132/3750 [07:12<01:25,  7.24it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3134/3750 [07:12<01:25,  7.24it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3136/3750 [07:12<01:24,  7.25it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3138/3750 [07:12<01:24,  7.25it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3140/3750 [07:12<01:24,  7.25it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3142/3750 [07:13<01:23,  7.25it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3144/3750 [07:13<01:23,  7.26it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3146/3750 [07:13<01:23,  7.26it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3148/3750 [07:13<01:22,  7.26it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3150/3750 [07:13<01:22,  7.27it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3152/3750 [07:13<01:22,  7.27it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3154/3750 [07:13<01:21,  7.27it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3156/3750 [07:13<01:21,  7.27it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3158/3750 [07:13<01:21,  7.28it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3160/3750 [07:14<01:21,  7.28it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3162/3750 [07:14<01:20,  7.28it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3164/3750 [07:14<01:20,  7.28it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3166/3750 [07:14<01:20,  7.29it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%| | 3168/3750 [07:14<01:19,  7.29it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3170/3750 [07:14<01:19,  7.29it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3172/3750 [07:14<01:19,  7.30it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3174/3750 [07:14<01:18,  7.30it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3176/3750 [07:15<01:18,  7.30it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3178/3750 [07:15<01:18,  7.30it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3180/3750 [07:15<01:18,  7.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3182/3750 [07:15<01:17,  7.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3184/3750 [07:15<01:17,  7.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3186/3750 [07:15<01:17,  7.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3188/3750 [07:15<01:16,  7.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3190/3750 [07:15<01:16,  7.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3192/3750 [07:15<01:16,  7.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3194/3750 [07:16<01:15,  7.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3196/3750 [07:16<01:15,  7.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3198/3750 [07:16<01:15,  7.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3200/3750 [07:16<01:15,  7.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3202/3750 [07:16<01:14,  7.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3204/3750 [07:16<01:14,  7.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%| | 3206/3750 [07:16<01:14,  7.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3208/3750 [07:16<01:13,  7.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3210/3750 [07:16<01:13,  7.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3212/3750 [07:17<01:13,  7.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3214/3750 [07:17<01:12,  7.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3216/3750 [07:17<01:12,  7.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3218/3750 [07:17<01:12,  7.36it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3220/3750 [07:17<01:12,  7.36it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3222/3750 [07:17<01:11,  7.36it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3224/3750 [07:17<01:11,  7.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3226/3750 [07:17<01:11,  7.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3228/3750 [07:17<01:10,  7.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3230/3750 [07:18<01:10,  7.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3232/3750 [07:18<01:10,  7.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3234/3750 [07:18<01:09,  7.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3236/3750 [07:18<01:09,  7.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3238/3750 [07:18<01:09,  7.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3240/3750 [07:18<01:09,  7.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%| | 3242/3750 [07:18<01:08,  7.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3244/3750 [07:18<01:08,  7.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3246/3750 [07:18<01:08,  7.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3248/3750 [07:19<01:07,  7.40it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3250/3750 [07:19<01:07,  7.40it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3252/3750 [07:19<01:07,  7.40it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3254/3750 [07:19<01:06,  7.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3256/3750 [07:19<01:06,  7.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3258/3750 [07:19<01:06,  7.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3260/3750 [07:19<01:06,  7.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3262/3750 [07:19<01:05,  7.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3264/3750 [07:19<01:05,  7.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3266/3750 [07:20<01:05,  7.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3268/3750 [07:20<01:04,  7.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3270/3750 [07:20<01:04,  7.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3272/3750 [07:20<01:04,  7.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3274/3750 [07:20<01:04,  7.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3276/3750 [07:20<01:03,  7.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3278/3750 [07:20<01:03,  7.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%| | 3280/3750 [07:20<01:03,  7.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3282/3750 [07:20<01:02,  7.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3284/3750 [07:21<01:02,  7.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3286/3750 [07:21<01:02,  7.45it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3288/3750 [07:21<01:02,  7.45it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3290/3750 [07:21<01:01,  7.45it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3292/3750 [07:21<01:01,  7.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3294/3750 [07:21<01:01,  7.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3296/3750 [07:21<01:00,  7.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3298/3750 [07:21<01:00,  7.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3300/3750 [07:22<01:00,  7.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3302/3750 [07:22<00:59,  7.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3304/3750 [07:22<00:59,  7.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3306/3750 [07:22<00:59,  7.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3308/3750 [07:22<00:59,  7.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3310/3750 [07:22<00:58,  7.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3312/3750 [07:22<00:58,  7.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3314/3750 [07:22<00:58,  7.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3316/3750 [07:22<00:57,  7.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%| | 3318/3750 [07:23<00:57,  7.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3320/3750 [07:23<00:57,  7.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3322/3750 [07:23<00:57,  7.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3324/3750 [07:23<00:56,  7.50it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3326/3750 [07:23<00:56,  7.50it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3328/3750 [07:23<00:56,  7.50it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3330/3750 [07:23<00:55,  7.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3332/3750 [07:23<00:55,  7.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3334/3750 [07:23<00:55,  7.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3336/3750 [07:24<00:55,  7.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3338/3750 [07:24<00:54,  7.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3340/3750 [07:24<00:54,  7.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3342/3750 [07:24<00:54,  7.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3344/3750 [07:24<00:53,  7.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3346/3750 [07:24<00:53,  7.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3348/3750 [07:24<00:53,  7.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3350/3750 [07:24<00:53,  7.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3352/3750 [07:24<00:52,  7.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3354/3750 [07:25<00:52,  7.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%| | 3356/3750 [07:25<00:52,  7.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3358/3750 [07:25<00:51,  7.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3360/3750 [07:25<00:51,  7.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3362/3750 [07:25<00:51,  7.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3364/3750 [07:25<00:51,  7.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3366/3750 [07:25<00:50,  7.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3368/3750 [07:25<00:50,  7.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3370/3750 [07:25<00:50,  7.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3372/3750 [07:26<00:50,  7.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3374/3750 [07:26<00:49,  7.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3376/3750 [07:26<00:49,  7.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3378/3750 [07:26<00:49,  7.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3380/3750 [07:26<00:48,  7.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3382/3750 [07:26<00:48,  7.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3384/3750 [07:26<00:48,  7.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3386/3750 [07:26<00:48,  7.58it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3388/3750 [07:26<00:47,  7.58it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3390/3750 [07:27<00:47,  7.58it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%| | 3392/3750 [07:27<00:47,  7.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3394/3750 [07:27<00:46,  7.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3396/3750 [07:27<00:46,  7.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3398/3750 [07:27<00:46,  7.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3400/3750 [07:27<00:46,  7.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3402/3750 [07:27<00:45,  7.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3404/3750 [07:27<00:45,  7.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3406/3750 [07:27<00:45,  7.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3408/3750 [07:28<00:44,  7.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3410/3750 [07:28<00:44,  7.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3412/3750 [07:28<00:44,  7.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3414/3750 [07:28<00:44,  7.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3416/3750 [07:28<00:43,  7.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3418/3750 [07:28<00:43,  7.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%| | 3420/3750 [07:28<00:43,  7.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|| 3422/3750 [07:28<00:43,  7.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|| 3424/3750 [07:28<00:42,  7.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|| 3426/3750 [07:29<00:42,  7.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|| 3428/3750 [07:29<00:42,  7.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|| 3430/3750 [07:29<00:41,  7.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3432/3750 [07:29<00:41,  7.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3434/3750 [07:29<00:41,  7.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3436/3750 [07:29<00:41,  7.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3438/3750 [07:29<00:40,  7.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3440/3750 [07:29<00:40,  7.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3442/3750 [07:30<00:40,  7.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3444/3750 [07:30<00:39,  7.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3446/3750 [07:30<00:39,  7.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3448/3750 [07:30<00:39,  7.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3450/3750 [07:30<00:39,  7.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3452/3750 [07:30<00:38,  7.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3454/3750 [07:30<00:38,  7.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3456/3750 [07:30<00:38,  7.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3458/3750 [07:30<00:38,  7.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3460/3750 [07:31<00:37,  7.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3462/3750 [07:31<00:37,  7.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3464/3750 [07:31<00:37,  7.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3466/3750 [07:31<00:36,  7.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|| 3468/3750 [07:31<00:36,  7.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3470/3750 [07:31<00:36,  7.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3472/3750 [07:31<00:36,  7.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3474/3750 [07:31<00:35,  7.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3476/3750 [07:31<00:35,  7.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3478/3750 [07:32<00:35,  7.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3480/3750 [07:32<00:35,  7.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3482/3750 [07:32<00:34,  7.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3484/3750 [07:32<00:34,  7.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3486/3750 [07:32<00:34,  7.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3488/3750 [07:32<00:33,  7.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3490/3750 [07:32<00:33,  7.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3492/3750 [07:32<00:33,  7.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3494/3750 [07:32<00:33,  7.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3496/3750 [07:33<00:32,  7.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3498/3750 [07:33<00:32,  7.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3500/3750 [07:33<00:32,  7.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3502/3750 [07:33<00:32,  7.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3504/3750 [07:33<00:31,  7.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|| 3506/3750 [07:33<00:31,  7.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3508/3750 [07:33<00:31,  7.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3510/3750 [07:33<00:31,  7.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3512/3750 [07:33<00:30,  7.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3514/3750 [07:34<00:30,  7.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3516/3750 [07:34<00:30,  7.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3518/3750 [07:34<00:29,  7.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3520/3750 [07:34<00:29,  7.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3522/3750 [07:34<00:29,  7.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3524/3750 [07:34<00:29,  7.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3526/3750 [07:34<00:28,  7.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3528/3750 [07:34<00:28,  7.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3530/3750 [07:34<00:28,  7.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3532/3750 [07:35<00:28,  7.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3534/3750 [07:35<00:27,  7.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3536/3750 [07:35<00:27,  7.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3538/3750 [07:35<00:27,  7.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3540/3750 [07:35<00:27,  7.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|| 3542/3750 [07:35<00:26,  7.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3544/3750 [07:35<00:26,  7.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3546/3750 [07:35<00:26,  7.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3548/3750 [07:35<00:25,  7.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3550/3750 [07:36<00:25,  7.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3552/3750 [07:36<00:25,  7.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3554/3750 [07:36<00:25,  7.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3556/3750 [07:36<00:24,  7.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3558/3750 [07:36<00:24,  7.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3560/3750 [07:36<00:24,  7.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3562/3750 [07:36<00:24,  7.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3564/3750 [07:36<00:23,  7.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3566/3750 [07:37<00:23,  7.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3568/3750 [07:37<00:23,  7.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3570/3750 [07:37<00:23,  7.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3572/3750 [07:37<00:22,  7.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3574/3750 [07:37<00:22,  7.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3576/3750 [07:37<00:22,  7.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3578/3750 [07:37<00:22,  7.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|| 3580/3750 [07:37<00:21,  7.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3582/3750 [07:37<00:21,  7.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3584/3750 [07:38<00:21,  7.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3586/3750 [07:38<00:20,  7.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3588/3750 [07:38<00:20,  7.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3590/3750 [07:38<00:20,  7.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3592/3750 [07:38<00:20,  7.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3594/3750 [07:38<00:19,  7.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3596/3750 [07:38<00:19,  7.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3598/3750 [07:38<00:19,  7.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3600/3750 [07:38<00:19,  7.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3602/3750 [07:39<00:18,  7.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3604/3750 [07:39<00:18,  7.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3606/3750 [07:39<00:18,  7.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3608/3750 [07:39<00:18,  7.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3610/3750 [07:39<00:17,  7.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3612/3750 [07:39<00:17,  7.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3614/3750 [07:39<00:17,  7.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3616/3750 [07:39<00:17,  7.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|| 3618/3750 [07:39<00:16,  7.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3620/3750 [07:40<00:16,  7.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3622/3750 [07:40<00:16,  7.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3624/3750 [07:40<00:16,  7.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3626/3750 [07:40<00:15,  7.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3628/3750 [07:40<00:15,  7.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3630/3750 [07:40<00:15,  7.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3632/3750 [07:40<00:14,  7.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3634/3750 [07:40<00:14,  7.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3636/3750 [07:40<00:14,  7.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3638/3750 [07:41<00:14,  7.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3640/3750 [07:41<00:13,  7.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3642/3750 [07:41<00:13,  7.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3644/3750 [07:41<00:13,  7.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3646/3750 [07:41<00:13,  7.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3648/3750 [07:41<00:12,  7.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3650/3750 [07:41<00:12,  7.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3652/3750 [07:41<00:12,  7.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3654/3750 [07:41<00:12,  7.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|| 3656/3750 [07:42<00:11,  7.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3658/3750 [07:42<00:11,  7.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3660/3750 [07:42<00:11,  7.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3662/3750 [07:42<00:11,  7.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3664/3750 [07:42<00:10,  7.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3666/3750 [07:42<00:10,  7.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3668/3750 [07:42<00:10,  7.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3670/3750 [07:42<00:10,  7.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3672/3750 [07:42<00:09,  7.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3674/3750 [07:43<00:09,  7.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3676/3750 [07:43<00:09,  7.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3678/3750 [07:43<00:09,  7.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3680/3750 [07:43<00:08,  7.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3682/3750 [07:43<00:08,  7.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3684/3750 [07:43<00:08,  7.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3686/3750 [07:43<00:08,  7.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3688/3750 [07:43<00:07,  7.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3690/3750 [07:43<00:07,  7.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|| 3692/3750 [07:44<00:07,  7.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3694/3750 [07:44<00:07,  7.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3696/3750 [07:44<00:06,  7.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3698/3750 [07:44<00:06,  7.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3700/3750 [07:44<00:06,  7.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3702/3750 [07:44<00:06,  7.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3704/3750 [07:44<00:05,  7.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3706/3750 [07:44<00:05,  7.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3708/3750 [07:45<00:05,  7.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3710/3750 [07:45<00:05,  7.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3712/3750 [07:45<00:04,  7.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3714/3750 [07:45<00:04,  7.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3716/3750 [07:45<00:04,  7.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3718/3750 [07:45<00:04,  7.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3720/3750 [07:45<00:03,  7.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3722/3750 [07:45<00:03,  7.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3724/3750 [07:45<00:03,  7.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3726/3750 [07:46<00:03,  8.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3728/3750 [07:46<00:02,  8.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|| 3730/3750 [07:46<00:02,  8.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|| 3732/3750 [07:46<00:02,  8.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|| 3734/3750 [07:46<00:01,  8.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|| 3736/3750 [07:46<00:01,  8.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|| 3738/3750 [07:46<00:01,  8.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|| 3740/3750 [07:46<00:01,  8.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|| 3742/3750 [07:46<00:00,  8.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|| 3744/3750 [07:47<00:00,  8.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|| 3746/3750 [07:47<00:00,  8.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|| 3748/3750 [07:47<00:00,  8.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|| 3750/3750 [07:47<00:00,  8.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 1:   0%|          | 0/3750 [00:00<?, ?it/s, loss=0.138, v_num=0]           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  67%|   | 2500/3750 [06:38<03:19,  6.28it/s, loss=0.125, v_num=0] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1250 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:  67%|   | 2502/3750 [06:38<03:18,  6.28it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|   | 2504/3750 [06:38<03:18,  6.28it/s, loss=0.125, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:  67%|   | 2506/3750 [06:38<03:17,  6.29it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|   | 2508/3750 [06:38<03:17,  6.29it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|   | 2510/3750 [06:38<03:17,  6.29it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|   | 2512/3750 [06:38<03:16,  6.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|   | 2514/3750 [06:39<03:16,  6.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|   | 2516/3750 [06:39<03:15,  6.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|   | 2518/3750 [06:39<03:15,  6.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|   | 2520/3750 [06:39<03:14,  6.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|   | 2522/3750 [06:39<03:14,  6.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|   | 2524/3750 [06:39<03:14,  6.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|   | 2526/3750 [06:39<03:13,  6.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|   | 2528/3750 [06:39<03:13,  6.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|   | 2530/3750 [06:39<03:12,  6.33it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2532/3750 [06:40<03:12,  6.33it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2534/3750 [06:40<03:12,  6.33it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2536/3750 [06:40<03:11,  6.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2538/3750 [06:40<03:11,  6.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2540/3750 [06:40<03:10,  6.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2542/3750 [06:40<03:10,  6.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2544/3750 [06:40<03:09,  6.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2546/3750 [06:40<03:09,  6.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2548/3750 [06:40<03:09,  6.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2550/3750 [06:41<03:08,  6.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2552/3750 [06:41<03:08,  6.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2554/3750 [06:41<03:07,  6.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2556/3750 [06:41<03:07,  6.37it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2558/3750 [06:41<03:07,  6.37it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2560/3750 [06:41<03:06,  6.37it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2562/3750 [06:41<03:06,  6.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2564/3750 [06:41<03:05,  6.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2566/3750 [06:42<03:05,  6.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|   | 2568/3750 [06:42<03:05,  6.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2570/3750 [06:42<03:04,  6.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2572/3750 [06:42<03:04,  6.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2574/3750 [06:42<03:03,  6.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2576/3750 [06:42<03:03,  6.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2578/3750 [06:42<03:03,  6.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2580/3750 [06:42<03:02,  6.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2582/3750 [06:42<03:02,  6.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2584/3750 [06:43<03:01,  6.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2586/3750 [06:43<03:01,  6.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2588/3750 [06:43<03:01,  6.42it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2590/3750 [06:43<03:00,  6.42it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2592/3750 [06:43<03:00,  6.42it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2594/3750 [06:43<02:59,  6.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2596/3750 [06:43<02:59,  6.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2598/3750 [06:43<02:59,  6.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2600/3750 [06:43<02:58,  6.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2602/3750 [06:44<02:58,  6.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2604/3750 [06:44<02:57,  6.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|   | 2606/3750 [06:44<02:57,  6.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2608/3750 [06:44<02:57,  6.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2610/3750 [06:44<02:56,  6.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2612/3750 [06:44<02:56,  6.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2614/3750 [06:44<02:55,  6.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2616/3750 [06:44<02:55,  6.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2618/3750 [06:44<02:55,  6.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2620/3750 [06:45<02:54,  6.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2622/3750 [06:45<02:54,  6.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2624/3750 [06:45<02:53,  6.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2626/3750 [06:45<02:53,  6.48it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2628/3750 [06:45<02:53,  6.48it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2630/3750 [06:45<02:52,  6.48it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2632/3750 [06:45<02:52,  6.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2634/3750 [06:45<02:51,  6.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2636/3750 [06:45<02:51,  6.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2638/3750 [06:46<02:51,  6.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2640/3750 [06:46<02:50,  6.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|   | 2642/3750 [06:46<02:50,  6.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2644/3750 [06:46<02:50,  6.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2646/3750 [06:46<02:49,  6.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2648/3750 [06:46<02:49,  6.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2650/3750 [06:46<02:48,  6.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2652/3750 [06:46<02:48,  6.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2654/3750 [06:46<02:48,  6.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2656/3750 [06:47<02:47,  6.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2658/3750 [06:47<02:47,  6.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2660/3750 [06:47<02:46,  6.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2662/3750 [06:47<02:46,  6.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2664/3750 [06:47<02:46,  6.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2666/3750 [06:47<02:45,  6.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2668/3750 [06:47<02:45,  6.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|   | 2670/3750 [06:47<02:44,  6.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|  | 2672/3750 [06:47<02:44,  6.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|  | 2674/3750 [06:48<02:44,  6.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|  | 2676/3750 [06:48<02:43,  6.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|  | 2678/3750 [06:48<02:43,  6.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|  | 2680/3750 [06:48<02:43,  6.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2682/3750 [06:48<02:42,  6.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2684/3750 [06:48<02:42,  6.57it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2686/3750 [06:48<02:41,  6.57it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2688/3750 [06:48<02:41,  6.57it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2690/3750 [06:49<02:41,  6.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2692/3750 [06:49<02:40,  6.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2694/3750 [06:49<02:40,  6.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2696/3750 [06:49<02:40,  6.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2698/3750 [06:49<02:39,  6.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2700/3750 [06:49<02:39,  6.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2702/3750 [06:49<02:38,  6.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2704/3750 [06:49<02:38,  6.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2706/3750 [06:49<02:38,  6.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2708/3750 [06:50<02:37,  6.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2710/3750 [06:50<02:37,  6.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2712/3750 [06:50<02:37,  6.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2714/3750 [06:50<02:36,  6.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2716/3750 [06:50<02:36,  6.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|  | 2718/3750 [06:50<02:35,  6.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2720/3750 [06:50<02:35,  6.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2722/3750 [06:50<02:35,  6.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2724/3750 [06:50<02:34,  6.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2726/3750 [06:51<02:34,  6.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2728/3750 [06:51<02:34,  6.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2730/3750 [06:51<02:33,  6.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2732/3750 [06:51<02:33,  6.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2734/3750 [06:51<02:32,  6.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2736/3750 [06:51<02:32,  6.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2738/3750 [06:51<02:32,  6.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2740/3750 [06:51<02:31,  6.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2742/3750 [06:51<02:31,  6.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2744/3750 [06:52<02:31,  6.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2746/3750 [06:52<02:30,  6.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2748/3750 [06:52<02:30,  6.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2750/3750 [06:52<02:29,  6.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2752/3750 [06:52<02:29,  6.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2754/3750 [06:52<02:29,  6.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|  | 2756/3750 [06:52<02:28,  6.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2758/3750 [06:52<02:28,  6.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2760/3750 [06:52<02:28,  6.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2762/3750 [06:53<02:27,  6.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2764/3750 [06:53<02:27,  6.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2766/3750 [06:53<02:27,  6.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2768/3750 [06:53<02:26,  6.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2770/3750 [06:53<02:26,  6.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2772/3750 [06:53<02:25,  6.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2774/3750 [06:53<02:25,  6.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2776/3750 [06:53<02:25,  6.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2778/3750 [06:53<02:24,  6.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2780/3750 [06:54<02:24,  6.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2782/3750 [06:54<02:24,  6.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2784/3750 [06:54<02:23,  6.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2786/3750 [06:54<02:23,  6.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2788/3750 [06:54<02:23,  6.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2790/3750 [06:54<02:22,  6.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|  | 2792/3750 [06:54<02:22,  6.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2794/3750 [06:54<02:21,  6.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2796/3750 [06:55<02:21,  6.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2798/3750 [06:55<02:21,  6.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2800/3750 [06:55<02:20,  6.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2802/3750 [06:55<02:20,  6.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2804/3750 [06:55<02:20,  6.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2806/3750 [06:55<02:19,  6.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2808/3750 [06:55<02:19,  6.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2810/3750 [06:55<02:19,  6.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2812/3750 [06:55<02:18,  6.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2814/3750 [06:56<02:18,  6.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2816/3750 [06:56<02:18,  6.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2818/3750 [06:56<02:17,  6.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2820/3750 [06:56<02:17,  6.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2822/3750 [06:56<02:16,  6.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2824/3750 [06:56<02:16,  6.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2826/3750 [06:56<02:16,  6.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2828/3750 [06:56<02:15,  6.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|  | 2830/3750 [06:56<02:15,  6.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2832/3750 [06:57<02:15,  6.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2834/3750 [06:57<02:14,  6.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2836/3750 [06:57<02:14,  6.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2838/3750 [06:57<02:14,  6.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2840/3750 [06:57<02:13,  6.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2842/3750 [06:57<02:13,  6.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2844/3750 [06:57<02:13,  6.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2846/3750 [06:57<02:12,  6.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2848/3750 [06:57<02:12,  6.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2850/3750 [06:58<02:12,  6.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2852/3750 [06:58<02:11,  6.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2854/3750 [06:58<02:11,  6.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2856/3750 [06:58<02:10,  6.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2858/3750 [06:58<02:10,  6.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2860/3750 [06:58<02:10,  6.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2862/3750 [06:58<02:09,  6.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2864/3750 [06:58<02:09,  6.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2866/3750 [06:58<02:09,  6.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|  | 2868/3750 [06:59<02:08,  6.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2870/3750 [06:59<02:08,  6.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2872/3750 [06:59<02:08,  6.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2874/3750 [06:59<02:07,  6.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2876/3750 [06:59<02:07,  6.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2878/3750 [06:59<02:07,  6.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2880/3750 [06:59<02:06,  6.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2882/3750 [06:59<02:06,  6.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2884/3750 [06:59<02:06,  6.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2886/3750 [07:00<02:05,  6.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2888/3750 [07:00<02:05,  6.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2890/3750 [07:00<02:05,  6.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2892/3750 [07:00<02:04,  6.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2894/3750 [07:00<02:04,  6.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2896/3750 [07:00<02:04,  6.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2898/3750 [07:00<02:03,  6.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2900/3750 [07:00<02:03,  6.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2902/3750 [07:00<02:03,  6.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2904/3750 [07:01<02:02,  6.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|  | 2906/3750 [07:01<02:02,  6.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2908/3750 [07:01<02:01,  6.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2910/3750 [07:01<02:01,  6.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2912/3750 [07:01<02:01,  6.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2914/3750 [07:01<02:00,  6.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2916/3750 [07:01<02:00,  6.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2918/3750 [07:01<02:00,  6.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2920/3750 [07:02<01:59,  6.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2922/3750 [07:02<01:59,  6.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2924/3750 [07:02<01:59,  6.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2926/3750 [07:02<01:58,  6.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2928/3750 [07:02<01:58,  6.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2930/3750 [07:02<01:58,  6.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2932/3750 [07:02<01:57,  6.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2934/3750 [07:02<01:57,  6.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2936/3750 [07:02<01:57,  6.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2938/3750 [07:03<01:56,  6.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2940/3750 [07:03<01:56,  6.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|  | 2942/3750 [07:03<01:56,  6.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2944/3750 [07:03<01:55,  6.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2946/3750 [07:03<01:55,  6.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2948/3750 [07:03<01:55,  6.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2950/3750 [07:03<01:54,  6.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2952/3750 [07:03<01:54,  6.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2954/3750 [07:03<01:54,  6.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2956/3750 [07:04<01:53,  6.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2958/3750 [07:04<01:53,  6.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2960/3750 [07:04<01:53,  6.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2962/3750 [07:04<01:52,  6.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2964/3750 [07:04<01:52,  6.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2966/3750 [07:04<01:52,  6.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2968/3750 [07:04<01:51,  6.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2970/3750 [07:04<01:51,  6.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2972/3750 [07:04<01:51,  6.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2974/3750 [07:05<01:50,  7.00it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2976/3750 [07:05<01:50,  7.00it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2978/3750 [07:05<01:50,  7.00it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|  | 2980/3750 [07:05<01:49,  7.01it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 2982/3750 [07:05<01:49,  7.01it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 2984/3750 [07:05<01:49,  7.01it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 2986/3750 [07:05<01:48,  7.01it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 2988/3750 [07:05<01:48,  7.02it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 2990/3750 [07:05<01:48,  7.02it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 2992/3750 [07:06<01:47,  7.02it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 2994/3750 [07:06<01:47,  7.02it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 2996/3750 [07:06<01:47,  7.03it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 2998/3750 [07:06<01:46,  7.03it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 3000/3750 [07:06<01:46,  7.03it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 3002/3750 [07:06<01:46,  7.04it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 3004/3750 [07:06<01:45,  7.04it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 3006/3750 [07:06<01:45,  7.04it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 3008/3750 [07:06<01:45,  7.04it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 3010/3750 [07:07<01:45,  7.05it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 3012/3750 [07:07<01:44,  7.05it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 3014/3750 [07:07<01:44,  7.05it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 3016/3750 [07:07<01:44,  7.06it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|  | 3018/3750 [07:07<01:43,  7.06it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3020/3750 [07:07<01:43,  7.06it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3022/3750 [07:07<01:43,  7.06it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3024/3750 [07:07<01:42,  7.07it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3026/3750 [07:08<01:42,  7.07it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3028/3750 [07:08<01:42,  7.07it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3030/3750 [07:08<01:41,  7.08it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3032/3750 [07:08<01:41,  7.08it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3034/3750 [07:08<01:41,  7.08it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3036/3750 [07:08<01:40,  7.08it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3038/3750 [07:08<01:40,  7.09it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3040/3750 [07:08<01:40,  7.09it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3042/3750 [07:08<01:39,  7.09it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3044/3750 [07:09<01:39,  7.10it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|  | 3046/3750 [07:09<01:39,  7.10it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%| | 3048/3750 [07:09<01:38,  7.10it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%| | 3050/3750 [07:09<01:38,  7.10it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%| | 3052/3750 [07:09<01:38,  7.11it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%| | 3054/3750 [07:09<01:37,  7.11it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%| | 3056/3750 [07:09<01:37,  7.11it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3058/3750 [07:09<01:37,  7.11it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3060/3750 [07:09<01:36,  7.12it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3062/3750 [07:10<01:36,  7.12it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3064/3750 [07:10<01:36,  7.12it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3066/3750 [07:10<01:35,  7.13it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3068/3750 [07:10<01:35,  7.13it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3070/3750 [07:10<01:35,  7.13it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3072/3750 [07:10<01:35,  7.13it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3074/3750 [07:10<01:34,  7.14it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3076/3750 [07:10<01:34,  7.14it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3078/3750 [07:10<01:34,  7.14it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3080/3750 [07:11<01:33,  7.15it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3082/3750 [07:11<01:33,  7.15it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3084/3750 [07:11<01:33,  7.15it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3086/3750 [07:11<01:32,  7.15it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3088/3750 [07:11<01:32,  7.16it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3090/3750 [07:11<01:32,  7.16it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%| | 3092/3750 [07:11<01:31,  7.16it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3094/3750 [07:11<01:31,  7.16it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3096/3750 [07:11<01:31,  7.17it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3098/3750 [07:12<01:30,  7.17it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3100/3750 [07:12<01:30,  7.17it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3102/3750 [07:12<01:30,  7.18it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3104/3750 [07:12<01:29,  7.18it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3106/3750 [07:12<01:29,  7.18it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3108/3750 [07:12<01:29,  7.18it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3110/3750 [07:12<01:29,  7.19it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3112/3750 [07:12<01:28,  7.19it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3114/3750 [07:12<01:28,  7.19it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3116/3750 [07:13<01:28,  7.19it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3118/3750 [07:13<01:27,  7.20it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3120/3750 [07:13<01:27,  7.20it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3122/3750 [07:13<01:27,  7.20it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3124/3750 [07:13<01:26,  7.21it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3126/3750 [07:13<01:26,  7.21it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3128/3750 [07:13<01:26,  7.21it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%| | 3130/3750 [07:13<01:25,  7.21it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3132/3750 [07:13<01:25,  7.22it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3134/3750 [07:14<01:25,  7.22it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3136/3750 [07:14<01:25,  7.22it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3138/3750 [07:14<01:24,  7.22it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3140/3750 [07:14<01:24,  7.23it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3142/3750 [07:14<01:24,  7.23it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3144/3750 [07:14<01:23,  7.23it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3146/3750 [07:14<01:23,  7.24it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3148/3750 [07:14<01:23,  7.24it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3150/3750 [07:15<01:22,  7.24it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3152/3750 [07:15<01:22,  7.24it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3154/3750 [07:15<01:22,  7.25it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3156/3750 [07:15<01:21,  7.25it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3158/3750 [07:15<01:21,  7.25it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3160/3750 [07:15<01:21,  7.25it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3162/3750 [07:15<01:21,  7.26it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3164/3750 [07:15<01:20,  7.26it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3166/3750 [07:15<01:20,  7.26it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%| | 3168/3750 [07:16<01:20,  7.27it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3170/3750 [07:16<01:19,  7.27it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3172/3750 [07:16<01:19,  7.27it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3174/3750 [07:16<01:19,  7.27it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3176/3750 [07:16<01:18,  7.28it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3178/3750 [07:16<01:18,  7.28it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3180/3750 [07:16<01:18,  7.28it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3182/3750 [07:16<01:17,  7.28it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3184/3750 [07:16<01:17,  7.29it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3186/3750 [07:17<01:17,  7.29it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3188/3750 [07:17<01:17,  7.29it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3190/3750 [07:17<01:16,  7.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3192/3750 [07:17<01:16,  7.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3194/3750 [07:17<01:16,  7.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3196/3750 [07:17<01:15,  7.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3198/3750 [07:17<01:15,  7.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3200/3750 [07:17<01:15,  7.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3202/3750 [07:17<01:14,  7.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3204/3750 [07:18<01:14,  7.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%| | 3206/3750 [07:18<01:14,  7.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3208/3750 [07:18<01:14,  7.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3210/3750 [07:18<01:13,  7.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3212/3750 [07:18<01:13,  7.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3214/3750 [07:18<01:13,  7.33it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3216/3750 [07:18<01:12,  7.33it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3218/3750 [07:18<01:12,  7.33it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3220/3750 [07:18<01:12,  7.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3222/3750 [07:19<01:11,  7.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3224/3750 [07:19<01:11,  7.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3226/3750 [07:19<01:11,  7.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3228/3750 [07:19<01:11,  7.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3230/3750 [07:19<01:10,  7.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3232/3750 [07:19<01:10,  7.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3234/3750 [07:19<01:10,  7.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3236/3750 [07:19<01:09,  7.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3238/3750 [07:19<01:09,  7.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3240/3750 [07:20<01:09,  7.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%| | 3242/3750 [07:20<01:08,  7.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3244/3750 [07:20<01:08,  7.37it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3246/3750 [07:20<01:08,  7.37it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3248/3750 [07:20<01:08,  7.37it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3250/3750 [07:20<01:07,  7.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3252/3750 [07:20<01:07,  7.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3254/3750 [07:20<01:07,  7.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3256/3750 [07:21<01:06,  7.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3258/3750 [07:21<01:06,  7.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3260/3750 [07:21<01:06,  7.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3262/3750 [07:21<01:06,  7.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3264/3750 [07:21<01:05,  7.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3266/3750 [07:21<01:05,  7.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3268/3750 [07:21<01:05,  7.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3270/3750 [07:21<01:04,  7.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3272/3750 [07:21<01:04,  7.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3274/3750 [07:22<01:04,  7.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3276/3750 [07:22<01:03,  7.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3278/3750 [07:22<01:03,  7.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%| | 3280/3750 [07:22<01:03,  7.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3282/3750 [07:22<01:03,  7.42it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3284/3750 [07:22<01:02,  7.42it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3286/3750 [07:22<01:02,  7.42it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3288/3750 [07:22<01:02,  7.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3290/3750 [07:22<01:01,  7.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3292/3750 [07:23<01:01,  7.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3294/3750 [07:23<01:01,  7.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3296/3750 [07:23<01:01,  7.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3298/3750 [07:23<01:00,  7.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3300/3750 [07:23<01:00,  7.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3302/3750 [07:23<01:00,  7.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3304/3750 [07:23<00:59,  7.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3306/3750 [07:23<00:59,  7.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3308/3750 [07:23<00:59,  7.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3310/3750 [07:24<00:59,  7.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3312/3750 [07:24<00:58,  7.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3314/3750 [07:24<00:58,  7.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3316/3750 [07:24<00:58,  7.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%| | 3318/3750 [07:24<00:57,  7.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3320/3750 [07:24<00:57,  7.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3322/3750 [07:24<00:57,  7.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3324/3750 [07:24<00:57,  7.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3326/3750 [07:24<00:56,  7.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3328/3750 [07:25<00:56,  7.48it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3330/3750 [07:25<00:56,  7.48it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3332/3750 [07:25<00:55,  7.48it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3334/3750 [07:25<00:55,  7.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3336/3750 [07:25<00:55,  7.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3338/3750 [07:25<00:55,  7.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3340/3750 [07:25<00:54,  7.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3342/3750 [07:25<00:54,  7.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3344/3750 [07:25<00:54,  7.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3346/3750 [07:26<00:53,  7.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3348/3750 [07:26<00:53,  7.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3350/3750 [07:26<00:53,  7.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3352/3750 [07:26<00:53,  7.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3354/3750 [07:26<00:52,  7.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%| | 3356/3750 [07:26<00:52,  7.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3358/3750 [07:26<00:52,  7.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3360/3750 [07:26<00:51,  7.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3362/3750 [07:26<00:51,  7.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3364/3750 [07:27<00:51,  7.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3366/3750 [07:27<00:51,  7.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3368/3750 [07:27<00:50,  7.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3370/3750 [07:27<00:50,  7.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3372/3750 [07:27<00:50,  7.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3374/3750 [07:27<00:49,  7.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3376/3750 [07:27<00:49,  7.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3378/3750 [07:27<00:49,  7.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3380/3750 [07:28<00:49,  7.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3382/3750 [07:28<00:48,  7.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3384/3750 [07:28<00:48,  7.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3386/3750 [07:28<00:48,  7.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3388/3750 [07:28<00:47,  7.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3390/3750 [07:28<00:47,  7.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%| | 3392/3750 [07:28<00:47,  7.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3394/3750 [07:28<00:47,  7.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3396/3750 [07:28<00:46,  7.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3398/3750 [07:29<00:46,  7.57it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3400/3750 [07:29<00:46,  7.57it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3402/3750 [07:29<00:45,  7.57it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3404/3750 [07:29<00:45,  7.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3406/3750 [07:29<00:45,  7.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3408/3750 [07:29<00:45,  7.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3410/3750 [07:29<00:44,  7.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3412/3750 [07:29<00:44,  7.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3414/3750 [07:29<00:44,  7.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3416/3750 [07:30<00:44,  7.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3418/3750 [07:30<00:43,  7.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%| | 3420/3750 [07:30<00:43,  7.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|| 3422/3750 [07:30<00:43,  7.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|| 3424/3750 [07:30<00:42,  7.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|| 3426/3750 [07:30<00:42,  7.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|| 3428/3750 [07:30<00:42,  7.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|| 3430/3750 [07:30<00:42,  7.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3432/3750 [07:30<00:41,  7.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3434/3750 [07:31<00:41,  7.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3436/3750 [07:31<00:41,  7.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3438/3750 [07:31<00:40,  7.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3440/3750 [07:31<00:40,  7.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3442/3750 [07:31<00:40,  7.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3444/3750 [07:31<00:40,  7.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3446/3750 [07:31<00:39,  7.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3448/3750 [07:31<00:39,  7.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3450/3750 [07:31<00:39,  7.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3452/3750 [07:32<00:39,  7.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3454/3750 [07:32<00:38,  7.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3456/3750 [07:32<00:38,  7.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3458/3750 [07:32<00:38,  7.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3460/3750 [07:32<00:37,  7.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3462/3750 [07:32<00:37,  7.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3464/3750 [07:32<00:37,  7.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3466/3750 [07:32<00:37,  7.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|| 3468/3750 [07:32<00:36,  7.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3470/3750 [07:33<00:36,  7.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3472/3750 [07:33<00:36,  7.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3474/3750 [07:33<00:36,  7.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3476/3750 [07:33<00:35,  7.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3478/3750 [07:33<00:35,  7.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3480/3750 [07:33<00:35,  7.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3482/3750 [07:33<00:34,  7.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3484/3750 [07:33<00:34,  7.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3486/3750 [07:33<00:34,  7.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3488/3750 [07:34<00:34,  7.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3490/3750 [07:34<00:33,  7.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3492/3750 [07:34<00:33,  7.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3494/3750 [07:34<00:33,  7.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3496/3750 [07:34<00:33,  7.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3498/3750 [07:34<00:32,  7.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3500/3750 [07:34<00:32,  7.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3502/3750 [07:34<00:32,  7.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3504/3750 [07:35<00:31,  7.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|| 3506/3750 [07:35<00:31,  7.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3508/3750 [07:35<00:31,  7.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3510/3750 [07:35<00:31,  7.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3512/3750 [07:35<00:30,  7.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3514/3750 [07:35<00:30,  7.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3516/3750 [07:35<00:30,  7.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3518/3750 [07:35<00:30,  7.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3520/3750 [07:35<00:29,  7.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3522/3750 [07:36<00:29,  7.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3524/3750 [07:36<00:29,  7.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3526/3750 [07:36<00:28,  7.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3528/3750 [07:36<00:28,  7.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3530/3750 [07:36<00:28,  7.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3532/3750 [07:36<00:28,  7.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3534/3750 [07:36<00:27,  7.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3536/3750 [07:36<00:27,  7.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3538/3750 [07:36<00:27,  7.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3540/3750 [07:37<00:27,  7.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|| 3542/3750 [07:37<00:26,  7.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3544/3750 [07:37<00:26,  7.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3546/3750 [07:37<00:26,  7.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3548/3750 [07:37<00:26,  7.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3550/3750 [07:37<00:25,  7.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3552/3750 [07:37<00:25,  7.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3554/3750 [07:37<00:25,  7.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3556/3750 [07:37<00:24,  7.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3558/3750 [07:38<00:24,  7.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3560/3750 [07:38<00:24,  7.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3562/3750 [07:38<00:24,  7.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3564/3750 [07:38<00:23,  7.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3566/3750 [07:38<00:23,  7.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3568/3750 [07:38<00:23,  7.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3570/3750 [07:38<00:23,  7.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3572/3750 [07:38<00:22,  7.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3574/3750 [07:38<00:22,  7.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3576/3750 [07:39<00:22,  7.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3578/3750 [07:39<00:22,  7.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|| 3580/3750 [07:39<00:21,  7.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3582/3750 [07:39<00:21,  7.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3584/3750 [07:39<00:21,  7.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3586/3750 [07:39<00:21,  7.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3588/3750 [07:39<00:20,  7.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3590/3750 [07:39<00:20,  7.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3592/3750 [07:39<00:20,  7.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3594/3750 [07:40<00:19,  7.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3596/3750 [07:40<00:19,  7.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3598/3750 [07:40<00:19,  7.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3600/3750 [07:40<00:19,  7.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3602/3750 [07:40<00:18,  7.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3604/3750 [07:40<00:18,  7.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3606/3750 [07:40<00:18,  7.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3608/3750 [07:40<00:18,  7.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3610/3750 [07:40<00:17,  7.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3612/3750 [07:41<00:17,  7.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3614/3750 [07:41<00:17,  7.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3616/3750 [07:41<00:17,  7.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|| 3618/3750 [07:41<00:16,  7.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3620/3750 [07:41<00:16,  7.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3622/3750 [07:41<00:16,  7.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3624/3750 [07:41<00:16,  7.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3626/3750 [07:41<00:15,  7.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3628/3750 [07:42<00:15,  7.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3630/3750 [07:42<00:15,  7.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3632/3750 [07:42<00:15,  7.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3634/3750 [07:42<00:14,  7.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3636/3750 [07:42<00:14,  7.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3638/3750 [07:42<00:14,  7.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3640/3750 [07:42<00:13,  7.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3642/3750 [07:42<00:13,  7.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3644/3750 [07:42<00:13,  7.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3646/3750 [07:43<00:13,  7.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3648/3750 [07:43<00:12,  7.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3650/3750 [07:43<00:12,  7.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3652/3750 [07:43<00:12,  7.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3654/3750 [07:43<00:12,  7.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|| 3656/3750 [07:43<00:11,  7.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3658/3750 [07:43<00:11,  7.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3660/3750 [07:43<00:11,  7.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3662/3750 [07:43<00:11,  7.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3664/3750 [07:44<00:10,  7.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3666/3750 [07:44<00:10,  7.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3668/3750 [07:44<00:10,  7.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3670/3750 [07:44<00:10,  7.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3672/3750 [07:44<00:09,  7.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3674/3750 [07:44<00:09,  7.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3676/3750 [07:44<00:09,  7.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3678/3750 [07:44<00:09,  7.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3680/3750 [07:44<00:08,  7.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3682/3750 [07:45<00:08,  7.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3684/3750 [07:45<00:08,  7.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3686/3750 [07:45<00:08,  7.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3688/3750 [07:45<00:07,  7.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3690/3750 [07:45<00:07,  7.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|| 3692/3750 [07:45<00:07,  7.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3694/3750 [07:45<00:07,  7.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3696/3750 [07:45<00:06,  7.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3698/3750 [07:45<00:06,  7.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3700/3750 [07:46<00:06,  7.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3702/3750 [07:46<00:06,  7.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3704/3750 [07:46<00:05,  7.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3706/3750 [07:46<00:05,  7.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3708/3750 [07:46<00:05,  7.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3710/3750 [07:46<00:05,  7.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3712/3750 [07:46<00:04,  7.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3714/3750 [07:46<00:04,  7.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3716/3750 [07:46<00:04,  7.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3718/3750 [07:47<00:04,  7.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3720/3750 [07:47<00:03,  7.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3722/3750 [07:47<00:03,  7.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3724/3750 [07:47<00:03,  7.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3726/3750 [07:47<00:03,  7.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3728/3750 [07:47<00:02,  7.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|| 3730/3750 [07:47<00:02,  7.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|| 3732/3750 [07:47<00:02,  7.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|| 3734/3750 [07:48<00:02,  7.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|| 3736/3750 [07:48<00:01,  7.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|| 3738/3750 [07:48<00:01,  7.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|| 3740/3750 [07:48<00:01,  7.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|| 3742/3750 [07:48<00:01,  7.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|| 3744/3750 [07:48<00:00,  7.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|| 3746/3750 [07:48<00:00,  7.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|| 3748/3750 [07:48<00:00,  7.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|| 3750/3750 [07:49<00:00,  7.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 2:   0%|          | 0/3750 [00:00<?, ?it/s, loss=0.125, v_num=0]           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  67%|   | 2500/3750 [06:38<03:19,  6.28it/s, loss=0.0849, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1250 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2:  67%|   | 2502/3750 [06:38<03:18,  6.28it/s, loss=0.0849, v_num=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  67%|   | 2504/3750 [06:38<03:18,  6.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|   | 2506/3750 [06:38<03:17,  6.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|   | 2508/3750 [06:38<03:17,  6.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|   | 2510/3750 [06:38<03:16,  6.30it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|   | 2512/3750 [06:38<03:16,  6.30it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|   | 2514/3750 [06:38<03:16,  6.30it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|   | 2516/3750 [06:39<03:15,  6.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|   | 2518/3750 [06:39<03:15,  6.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|   | 2520/3750 [06:39<03:14,  6.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|   | 2522/3750 [06:39<03:14,  6.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|   | 2524/3750 [06:39<03:14,  6.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|   | 2526/3750 [06:39<03:13,  6.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|   | 2528/3750 [06:39<03:13,  6.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|   | 2530/3750 [06:39<03:12,  6.33it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2532/3750 [06:39<03:12,  6.33it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2534/3750 [06:40<03:11,  6.33it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2536/3750 [06:40<03:11,  6.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2538/3750 [06:40<03:11,  6.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2540/3750 [06:40<03:10,  6.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2542/3750 [06:40<03:10,  6.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2544/3750 [06:40<03:09,  6.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2546/3750 [06:40<03:09,  6.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2548/3750 [06:40<03:09,  6.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2550/3750 [06:40<03:08,  6.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2552/3750 [06:41<03:08,  6.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2554/3750 [06:41<03:07,  6.37it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2556/3750 [06:41<03:07,  6.37it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2558/3750 [06:41<03:07,  6.37it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2560/3750 [06:41<03:06,  6.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2562/3750 [06:41<03:06,  6.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2564/3750 [06:41<03:05,  6.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2566/3750 [06:41<03:05,  6.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|   | 2568/3750 [06:41<03:05,  6.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2570/3750 [06:42<03:04,  6.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2572/3750 [06:42<03:04,  6.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2574/3750 [06:42<03:03,  6.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2576/3750 [06:42<03:03,  6.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2578/3750 [06:42<03:03,  6.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2580/3750 [06:42<03:02,  6.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2582/3750 [06:42<03:02,  6.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2584/3750 [06:42<03:01,  6.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2586/3750 [06:42<03:01,  6.42it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2588/3750 [06:43<03:00,  6.42it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2590/3750 [06:43<03:00,  6.42it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2592/3750 [06:43<03:00,  6.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2594/3750 [06:43<02:59,  6.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2596/3750 [06:43<02:59,  6.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2598/3750 [06:43<02:58,  6.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2600/3750 [06:43<02:58,  6.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2602/3750 [06:43<02:58,  6.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2604/3750 [06:44<02:57,  6.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|   | 2606/3750 [06:44<02:57,  6.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2608/3750 [06:44<02:57,  6.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2610/3750 [06:44<02:56,  6.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2612/3750 [06:44<02:56,  6.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2614/3750 [06:44<02:55,  6.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2616/3750 [06:44<02:55,  6.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2618/3750 [06:44<02:55,  6.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2620/3750 [06:44<02:54,  6.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2622/3750 [06:45<02:54,  6.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2624/3750 [06:45<02:53,  6.48it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2626/3750 [06:45<02:53,  6.48it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2628/3750 [06:45<02:53,  6.48it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2630/3750 [06:45<02:52,  6.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2632/3750 [06:45<02:52,  6.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2634/3750 [06:45<02:51,  6.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2636/3750 [06:45<02:51,  6.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2638/3750 [06:45<02:51,  6.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2640/3750 [06:46<02:50,  6.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|   | 2642/3750 [06:46<02:50,  6.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2644/3750 [06:46<02:49,  6.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2646/3750 [06:46<02:49,  6.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2648/3750 [06:46<02:49,  6.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2650/3750 [06:46<02:48,  6.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2652/3750 [06:46<02:48,  6.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2654/3750 [06:46<02:48,  6.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2656/3750 [06:46<02:47,  6.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2658/3750 [06:47<02:47,  6.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2660/3750 [06:47<02:46,  6.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2662/3750 [06:47<02:46,  6.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2664/3750 [06:47<02:46,  6.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2666/3750 [06:47<02:45,  6.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2668/3750 [06:47<02:45,  6.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|   | 2670/3750 [06:47<02:44,  6.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|  | 2672/3750 [06:47<02:44,  6.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|  | 2674/3750 [06:47<02:44,  6.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|  | 2676/3750 [06:48<02:43,  6.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|  | 2678/3750 [06:48<02:43,  6.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|  | 2680/3750 [06:48<02:43,  6.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2682/3750 [06:48<02:42,  6.57it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2684/3750 [06:48<02:42,  6.57it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2686/3750 [06:48<02:41,  6.57it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2688/3750 [06:48<02:41,  6.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2690/3750 [06:48<02:41,  6.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2692/3750 [06:48<02:40,  6.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2694/3750 [06:49<02:40,  6.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2696/3750 [06:49<02:39,  6.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2698/3750 [06:49<02:39,  6.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2700/3750 [06:49<02:39,  6.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2702/3750 [06:49<02:38,  6.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2704/3750 [06:49<02:38,  6.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2706/3750 [06:49<02:38,  6.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2708/3750 [06:49<02:37,  6.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2710/3750 [06:50<02:37,  6.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2712/3750 [06:50<02:36,  6.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2714/3750 [06:50<02:36,  6.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2716/3750 [06:50<02:36,  6.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|  | 2718/3750 [06:50<02:35,  6.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2720/3750 [06:50<02:35,  6.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2722/3750 [06:50<02:35,  6.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2724/3750 [06:50<02:34,  6.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2726/3750 [06:50<02:34,  6.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2728/3750 [06:51<02:33,  6.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2730/3750 [06:51<02:33,  6.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2732/3750 [06:51<02:33,  6.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2734/3750 [06:51<02:32,  6.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2736/3750 [06:51<02:32,  6.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2738/3750 [06:51<02:32,  6.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2740/3750 [06:51<02:31,  6.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2742/3750 [06:51<02:31,  6.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2744/3750 [06:51<02:31,  6.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2746/3750 [06:52<02:30,  6.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2748/3750 [06:52<02:30,  6.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2750/3750 [06:52<02:29,  6.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2752/3750 [06:52<02:29,  6.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2754/3750 [06:52<02:29,  6.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|  | 2756/3750 [06:52<02:28,  6.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2758/3750 [06:52<02:28,  6.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2760/3750 [06:52<02:28,  6.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2762/3750 [06:52<02:27,  6.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2764/3750 [06:53<02:27,  6.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2766/3750 [06:53<02:26,  6.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2768/3750 [06:53<02:26,  6.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2770/3750 [06:53<02:26,  6.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2772/3750 [06:53<02:25,  6.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2774/3750 [06:53<02:25,  6.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2776/3750 [06:53<02:25,  6.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2778/3750 [06:53<02:24,  6.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2780/3750 [06:53<02:24,  6.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2782/3750 [06:54<02:24,  6.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2784/3750 [06:54<02:23,  6.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2786/3750 [06:54<02:23,  6.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2788/3750 [06:54<02:22,  6.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2790/3750 [06:54<02:22,  6.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|  | 2792/3750 [06:54<02:22,  6.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2794/3750 [06:54<02:21,  6.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2796/3750 [06:54<02:21,  6.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2798/3750 [06:54<02:21,  6.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2800/3750 [06:55<02:20,  6.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2802/3750 [06:55<02:20,  6.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2804/3750 [06:55<02:20,  6.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2806/3750 [06:55<02:19,  6.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2808/3750 [06:55<02:19,  6.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2810/3750 [06:55<02:19,  6.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2812/3750 [06:55<02:18,  6.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2814/3750 [06:55<02:18,  6.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2816/3750 [06:55<02:17,  6.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2818/3750 [06:56<02:17,  6.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2820/3750 [06:56<02:17,  6.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2822/3750 [06:56<02:16,  6.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2824/3750 [06:56<02:16,  6.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2826/3750 [06:56<02:16,  6.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2828/3750 [06:56<02:15,  6.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|  | 2830/3750 [06:56<02:15,  6.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2832/3750 [06:56<02:15,  6.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2834/3750 [06:57<02:14,  6.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2836/3750 [06:57<02:14,  6.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2838/3750 [06:57<02:14,  6.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2840/3750 [06:57<02:13,  6.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2842/3750 [06:57<02:13,  6.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2844/3750 [06:57<02:13,  6.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2846/3750 [06:57<02:12,  6.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2848/3750 [06:57<02:12,  6.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2850/3750 [06:57<02:11,  6.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2852/3750 [06:58<02:11,  6.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2854/3750 [06:58<02:11,  6.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2856/3750 [06:58<02:10,  6.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2858/3750 [06:58<02:10,  6.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2860/3750 [06:58<02:10,  6.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2862/3750 [06:58<02:09,  6.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2864/3750 [06:58<02:09,  6.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2866/3750 [06:58<02:09,  6.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|  | 2868/3750 [06:58<02:08,  6.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2870/3750 [06:59<02:08,  6.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2872/3750 [06:59<02:08,  6.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2874/3750 [06:59<02:07,  6.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2876/3750 [06:59<02:07,  6.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2878/3750 [06:59<02:07,  6.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2880/3750 [06:59<02:06,  6.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2882/3750 [06:59<02:06,  6.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2884/3750 [06:59<02:06,  6.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2886/3750 [06:59<02:05,  6.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2888/3750 [07:00<02:05,  6.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2890/3750 [07:00<02:05,  6.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2892/3750 [07:00<02:04,  6.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2894/3750 [07:00<02:04,  6.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2896/3750 [07:00<02:04,  6.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2898/3750 [07:00<02:03,  6.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2900/3750 [07:00<02:03,  6.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2902/3750 [07:00<02:02,  6.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2904/3750 [07:00<02:02,  6.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|  | 2906/3750 [07:01<02:02,  6.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2908/3750 [07:01<02:01,  6.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2910/3750 [07:01<02:01,  6.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2912/3750 [07:01<02:01,  6.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2914/3750 [07:01<02:00,  6.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2916/3750 [07:01<02:00,  6.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2918/3750 [07:01<02:00,  6.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2920/3750 [07:01<01:59,  6.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2922/3750 [07:01<01:59,  6.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2924/3750 [07:02<01:59,  6.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2926/3750 [07:02<01:58,  6.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2928/3750 [07:02<01:58,  6.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2930/3750 [07:02<01:58,  6.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2932/3750 [07:02<01:57,  6.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2934/3750 [07:02<01:57,  6.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2936/3750 [07:02<01:57,  6.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2938/3750 [07:02<01:56,  6.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2940/3750 [07:02<01:56,  6.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|  | 2942/3750 [07:03<01:56,  6.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2944/3750 [07:03<01:55,  6.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2946/3750 [07:03<01:55,  6.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2948/3750 [07:03<01:55,  6.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2950/3750 [07:03<01:54,  6.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2952/3750 [07:03<01:54,  6.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2954/3750 [07:03<01:54,  6.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2956/3750 [07:03<01:53,  6.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2958/3750 [07:04<01:53,  6.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2960/3750 [07:04<01:53,  6.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2962/3750 [07:04<01:52,  6.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2964/3750 [07:04<01:52,  6.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2966/3750 [07:04<01:52,  6.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2968/3750 [07:04<01:51,  6.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2970/3750 [07:04<01:51,  6.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2972/3750 [07:04<01:51,  7.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2974/3750 [07:04<01:50,  7.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2976/3750 [07:05<01:50,  7.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2978/3750 [07:05<01:50,  7.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|  | 2980/3750 [07:05<01:49,  7.01it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 2982/3750 [07:05<01:49,  7.01it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 2984/3750 [07:05<01:49,  7.01it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 2986/3750 [07:05<01:48,  7.02it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 2988/3750 [07:05<01:48,  7.02it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 2990/3750 [07:05<01:48,  7.02it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 2992/3750 [07:05<01:47,  7.02it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 2994/3750 [07:06<01:47,  7.03it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 2996/3750 [07:06<01:47,  7.03it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 2998/3750 [07:06<01:46,  7.03it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 3000/3750 [07:06<01:46,  7.04it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 3002/3750 [07:06<01:46,  7.04it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 3004/3750 [07:06<01:45,  7.04it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 3006/3750 [07:06<01:45,  7.04it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 3008/3750 [07:06<01:45,  7.05it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 3010/3750 [07:06<01:44,  7.05it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 3012/3750 [07:07<01:44,  7.05it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 3014/3750 [07:07<01:44,  7.06it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 3016/3750 [07:07<01:43,  7.06it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|  | 3018/3750 [07:07<01:43,  7.06it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3020/3750 [07:07<01:43,  7.06it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3022/3750 [07:07<01:43,  7.07it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3024/3750 [07:07<01:42,  7.07it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3026/3750 [07:07<01:42,  7.07it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3028/3750 [07:07<01:42,  7.08it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3030/3750 [07:08<01:41,  7.08it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3032/3750 [07:08<01:41,  7.08it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3034/3750 [07:08<01:41,  7.08it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3036/3750 [07:08<01:40,  7.09it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3038/3750 [07:08<01:40,  7.09it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3040/3750 [07:08<01:40,  7.09it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3042/3750 [07:08<01:39,  7.09it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3044/3750 [07:08<01:39,  7.10it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|  | 3046/3750 [07:08<01:39,  7.10it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%| | 3048/3750 [07:09<01:38,  7.10it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%| | 3050/3750 [07:09<01:38,  7.11it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%| | 3052/3750 [07:09<01:38,  7.11it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%| | 3054/3750 [07:09<01:37,  7.11it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%| | 3056/3750 [07:09<01:37,  7.11it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3058/3750 [07:09<01:37,  7.12it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3060/3750 [07:09<01:36,  7.12it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3062/3750 [07:09<01:36,  7.12it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3064/3750 [07:10<01:36,  7.13it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3066/3750 [07:10<01:35,  7.13it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3068/3750 [07:10<01:35,  7.13it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3070/3750 [07:10<01:35,  7.13it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3072/3750 [07:10<01:35,  7.14it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3074/3750 [07:10<01:34,  7.14it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3076/3750 [07:10<01:34,  7.14it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3078/3750 [07:10<01:34,  7.14it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3080/3750 [07:10<01:33,  7.15it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3082/3750 [07:11<01:33,  7.15it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3084/3750 [07:11<01:33,  7.15it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3086/3750 [07:11<01:32,  7.16it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3088/3750 [07:11<01:32,  7.16it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3090/3750 [07:11<01:32,  7.16it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%| | 3092/3750 [07:11<01:31,  7.16it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3094/3750 [07:11<01:31,  7.17it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3096/3750 [07:11<01:31,  7.17it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3098/3750 [07:11<01:30,  7.17it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3100/3750 [07:12<01:30,  7.18it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3102/3750 [07:12<01:30,  7.18it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3104/3750 [07:12<01:29,  7.18it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3106/3750 [07:12<01:29,  7.18it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3108/3750 [07:12<01:29,  7.19it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3110/3750 [07:12<01:29,  7.19it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3112/3750 [07:12<01:28,  7.19it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3114/3750 [07:12<01:28,  7.19it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3116/3750 [07:12<01:28,  7.20it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3118/3750 [07:13<01:27,  7.20it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3120/3750 [07:13<01:27,  7.20it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3122/3750 [07:13<01:27,  7.21it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3124/3750 [07:13<01:26,  7.21it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3126/3750 [07:13<01:26,  7.21it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3128/3750 [07:13<01:26,  7.21it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%| | 3130/3750 [07:13<01:25,  7.22it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3132/3750 [07:13<01:25,  7.22it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3134/3750 [07:13<01:25,  7.22it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3136/3750 [07:14<01:24,  7.22it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3138/3750 [07:14<01:24,  7.23it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3140/3750 [07:14<01:24,  7.23it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3142/3750 [07:14<01:24,  7.23it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3144/3750 [07:14<01:23,  7.24it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3146/3750 [07:14<01:23,  7.24it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3148/3750 [07:14<01:23,  7.24it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3150/3750 [07:14<01:22,  7.24it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3152/3750 [07:14<01:22,  7.25it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3154/3750 [07:15<01:22,  7.25it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3156/3750 [07:15<01:21,  7.25it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3158/3750 [07:15<01:21,  7.25it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3160/3750 [07:15<01:21,  7.26it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3162/3750 [07:15<01:20,  7.26it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3164/3750 [07:15<01:20,  7.26it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3166/3750 [07:15<01:20,  7.27it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%| | 3168/3750 [07:15<01:20,  7.27it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3170/3750 [07:15<01:19,  7.27it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3172/3750 [07:16<01:19,  7.27it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3174/3750 [07:16<01:19,  7.28it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3176/3750 [07:16<01:18,  7.28it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3178/3750 [07:16<01:18,  7.28it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3180/3750 [07:16<01:18,  7.28it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3182/3750 [07:16<01:17,  7.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3184/3750 [07:16<01:17,  7.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3186/3750 [07:16<01:17,  7.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3188/3750 [07:17<01:17,  7.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3190/3750 [07:17<01:16,  7.30it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3192/3750 [07:17<01:16,  7.30it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3194/3750 [07:17<01:16,  7.30it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3196/3750 [07:17<01:15,  7.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3198/3750 [07:17<01:15,  7.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3200/3750 [07:17<01:15,  7.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3202/3750 [07:17<01:14,  7.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3204/3750 [07:17<01:14,  7.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%| | 3206/3750 [07:18<01:14,  7.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3208/3750 [07:18<01:14,  7.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3210/3750 [07:18<01:13,  7.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3212/3750 [07:18<01:13,  7.33it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3214/3750 [07:18<01:13,  7.33it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3216/3750 [07:18<01:12,  7.33it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3218/3750 [07:18<01:12,  7.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3220/3750 [07:18<01:12,  7.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3222/3750 [07:18<01:11,  7.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3224/3750 [07:19<01:11,  7.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3226/3750 [07:19<01:11,  7.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3228/3750 [07:19<01:11,  7.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3230/3750 [07:19<01:10,  7.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3232/3750 [07:19<01:10,  7.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3234/3750 [07:19<01:10,  7.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3236/3750 [07:19<01:09,  7.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3238/3750 [07:19<01:09,  7.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3240/3750 [07:19<01:09,  7.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%| | 3242/3750 [07:20<01:08,  7.37it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3244/3750 [07:20<01:08,  7.37it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3246/3750 [07:20<01:08,  7.37it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3248/3750 [07:20<01:08,  7.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3250/3750 [07:20<01:07,  7.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3252/3750 [07:20<01:07,  7.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3254/3750 [07:20<01:07,  7.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3256/3750 [07:20<01:06,  7.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3258/3750 [07:20<01:06,  7.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3260/3750 [07:21<01:06,  7.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3262/3750 [07:21<01:06,  7.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3264/3750 [07:21<01:05,  7.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3266/3750 [07:21<01:05,  7.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3268/3750 [07:21<01:05,  7.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3270/3750 [07:21<01:04,  7.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3272/3750 [07:21<01:04,  7.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3274/3750 [07:21<01:04,  7.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3276/3750 [07:21<01:03,  7.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3278/3750 [07:22<01:03,  7.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%| | 3280/3750 [07:22<01:03,  7.42it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3282/3750 [07:22<01:03,  7.42it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3284/3750 [07:22<01:02,  7.42it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3286/3750 [07:22<01:02,  7.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3288/3750 [07:22<01:02,  7.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3290/3750 [07:22<01:01,  7.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3292/3750 [07:22<01:01,  7.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3294/3750 [07:22<01:01,  7.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3296/3750 [07:23<01:01,  7.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3298/3750 [07:23<01:00,  7.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3300/3750 [07:23<01:00,  7.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3302/3750 [07:23<01:00,  7.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3304/3750 [07:23<00:59,  7.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3306/3750 [07:23<00:59,  7.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3308/3750 [07:23<00:59,  7.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3310/3750 [07:23<00:59,  7.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3312/3750 [07:24<00:58,  7.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3314/3750 [07:24<00:58,  7.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3316/3750 [07:24<00:58,  7.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%| | 3318/3750 [07:24<00:57,  7.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3320/3750 [07:24<00:57,  7.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3322/3750 [07:24<00:57,  7.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3324/3750 [07:24<00:56,  7.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3326/3750 [07:24<00:56,  7.48it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3328/3750 [07:24<00:56,  7.48it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3330/3750 [07:25<00:56,  7.48it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3332/3750 [07:25<00:55,  7.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3334/3750 [07:25<00:55,  7.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3336/3750 [07:25<00:55,  7.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3338/3750 [07:25<00:54,  7.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3340/3750 [07:25<00:54,  7.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3342/3750 [07:25<00:54,  7.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3344/3750 [07:25<00:54,  7.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3346/3750 [07:25<00:53,  7.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3348/3750 [07:26<00:53,  7.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3350/3750 [07:26<00:53,  7.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3352/3750 [07:26<00:52,  7.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3354/3750 [07:26<00:52,  7.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%| | 3356/3750 [07:26<00:52,  7.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3358/3750 [07:26<00:52,  7.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3360/3750 [07:26<00:51,  7.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3362/3750 [07:26<00:51,  7.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3364/3750 [07:26<00:51,  7.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3366/3750 [07:27<00:51,  7.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3368/3750 [07:27<00:50,  7.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3370/3750 [07:27<00:50,  7.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3372/3750 [07:27<00:50,  7.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3374/3750 [07:27<00:49,  7.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3376/3750 [07:27<00:49,  7.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3378/3750 [07:27<00:49,  7.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3380/3750 [07:27<00:49,  7.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3382/3750 [07:27<00:48,  7.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3384/3750 [07:28<00:48,  7.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3386/3750 [07:28<00:48,  7.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3388/3750 [07:28<00:47,  7.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3390/3750 [07:28<00:47,  7.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%| | 3392/3750 [07:28<00:47,  7.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3394/3750 [07:28<00:47,  7.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3396/3750 [07:28<00:46,  7.57it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3398/3750 [07:28<00:46,  7.57it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3400/3750 [07:28<00:46,  7.57it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3402/3750 [07:29<00:45,  7.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3404/3750 [07:29<00:45,  7.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3406/3750 [07:29<00:45,  7.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3408/3750 [07:29<00:45,  7.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3410/3750 [07:29<00:44,  7.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3412/3750 [07:29<00:44,  7.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3414/3750 [07:29<00:44,  7.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3416/3750 [07:29<00:43,  7.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3418/3750 [07:30<00:43,  7.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%| | 3420/3750 [07:30<00:43,  7.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|| 3422/3750 [07:30<00:43,  7.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|| 3424/3750 [07:30<00:42,  7.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|| 3426/3750 [07:30<00:42,  7.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|| 3428/3750 [07:30<00:42,  7.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|| 3430/3750 [07:30<00:42,  7.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3432/3750 [07:30<00:41,  7.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3434/3750 [07:30<00:41,  7.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3436/3750 [07:31<00:41,  7.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3438/3750 [07:31<00:40,  7.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3440/3750 [07:31<00:40,  7.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3442/3750 [07:31<00:40,  7.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3444/3750 [07:31<00:40,  7.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3446/3750 [07:31<00:39,  7.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3448/3750 [07:31<00:39,  7.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3450/3750 [07:31<00:39,  7.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3452/3750 [07:31<00:39,  7.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3454/3750 [07:32<00:38,  7.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3456/3750 [07:32<00:38,  7.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3458/3750 [07:32<00:38,  7.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3460/3750 [07:32<00:37,  7.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3462/3750 [07:32<00:37,  7.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3464/3750 [07:32<00:37,  7.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3466/3750 [07:32<00:37,  7.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|| 3468/3750 [07:32<00:36,  7.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3470/3750 [07:32<00:36,  7.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3472/3750 [07:33<00:36,  7.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3474/3750 [07:33<00:36,  7.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3476/3750 [07:33<00:35,  7.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3478/3750 [07:33<00:35,  7.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3480/3750 [07:33<00:35,  7.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3482/3750 [07:33<00:34,  7.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3484/3750 [07:33<00:34,  7.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3486/3750 [07:33<00:34,  7.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3488/3750 [07:33<00:34,  7.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3490/3750 [07:34<00:33,  7.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3492/3750 [07:34<00:33,  7.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3494/3750 [07:34<00:33,  7.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3496/3750 [07:34<00:33,  7.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3498/3750 [07:34<00:32,  7.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3500/3750 [07:34<00:32,  7.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3502/3750 [07:34<00:32,  7.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3504/3750 [07:34<00:31,  7.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|| 3506/3750 [07:34<00:31,  7.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3508/3750 [07:35<00:31,  7.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3510/3750 [07:35<00:31,  7.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3512/3750 [07:35<00:30,  7.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3514/3750 [07:35<00:30,  7.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3516/3750 [07:35<00:30,  7.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3518/3750 [07:35<00:30,  7.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3520/3750 [07:35<00:29,  7.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3522/3750 [07:35<00:29,  7.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3524/3750 [07:35<00:29,  7.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3526/3750 [07:36<00:28,  7.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3528/3750 [07:36<00:28,  7.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3530/3750 [07:36<00:28,  7.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3532/3750 [07:36<00:28,  7.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3534/3750 [07:36<00:27,  7.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3536/3750 [07:36<00:27,  7.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3538/3750 [07:36<00:27,  7.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3540/3750 [07:36<00:27,  7.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|| 3542/3750 [07:37<00:26,  7.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3544/3750 [07:37<00:26,  7.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3546/3750 [07:37<00:26,  7.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3548/3750 [07:37<00:26,  7.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3550/3750 [07:37<00:25,  7.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3552/3750 [07:37<00:25,  7.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3554/3750 [07:37<00:25,  7.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3556/3750 [07:37<00:24,  7.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3558/3750 [07:37<00:24,  7.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3560/3750 [07:38<00:24,  7.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3562/3750 [07:38<00:24,  7.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3564/3750 [07:38<00:23,  7.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3566/3750 [07:38<00:23,  7.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3568/3750 [07:38<00:23,  7.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3570/3750 [07:38<00:23,  7.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3572/3750 [07:38<00:22,  7.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3574/3750 [07:38<00:22,  7.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3576/3750 [07:38<00:22,  7.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3578/3750 [07:39<00:22,  7.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|| 3580/3750 [07:39<00:21,  7.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3582/3750 [07:39<00:21,  7.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3584/3750 [07:39<00:21,  7.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3586/3750 [07:39<00:21,  7.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3588/3750 [07:39<00:20,  7.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3590/3750 [07:39<00:20,  7.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3592/3750 [07:39<00:20,  7.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3594/3750 [07:39<00:19,  7.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3596/3750 [07:40<00:19,  7.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3598/3750 [07:40<00:19,  7.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3600/3750 [07:40<00:19,  7.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3602/3750 [07:40<00:18,  7.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3604/3750 [07:40<00:18,  7.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3606/3750 [07:40<00:18,  7.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3608/3750 [07:40<00:18,  7.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3610/3750 [07:40<00:17,  7.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3612/3750 [07:40<00:17,  7.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3614/3750 [07:41<00:17,  7.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3616/3750 [07:41<00:17,  7.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|| 3618/3750 [07:41<00:16,  7.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3620/3750 [07:41<00:16,  7.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3622/3750 [07:41<00:16,  7.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3624/3750 [07:41<00:16,  7.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3626/3750 [07:41<00:15,  7.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3628/3750 [07:41<00:15,  7.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3630/3750 [07:41<00:15,  7.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3632/3750 [07:42<00:15,  7.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3634/3750 [07:42<00:14,  7.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3636/3750 [07:42<00:14,  7.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3638/3750 [07:42<00:14,  7.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3640/3750 [07:42<00:13,  7.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3642/3750 [07:42<00:13,  7.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3644/3750 [07:42<00:13,  7.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3646/3750 [07:42<00:13,  7.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3648/3750 [07:43<00:12,  7.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3650/3750 [07:43<00:12,  7.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3652/3750 [07:43<00:12,  7.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3654/3750 [07:43<00:12,  7.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|| 3656/3750 [07:43<00:11,  7.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3658/3750 [07:43<00:11,  7.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3660/3750 [07:43<00:11,  7.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3662/3750 [07:43<00:11,  7.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3664/3750 [07:43<00:10,  7.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3666/3750 [07:44<00:10,  7.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3668/3750 [07:44<00:10,  7.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3670/3750 [07:44<00:10,  7.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3672/3750 [07:44<00:09,  7.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3674/3750 [07:44<00:09,  7.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3676/3750 [07:44<00:09,  7.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3678/3750 [07:44<00:09,  7.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3680/3750 [07:44<00:08,  7.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3682/3750 [07:44<00:08,  7.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3684/3750 [07:45<00:08,  7.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3686/3750 [07:45<00:08,  7.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3688/3750 [07:45<00:07,  7.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3690/3750 [07:45<00:07,  7.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|| 3692/3750 [07:45<00:07,  7.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3694/3750 [07:45<00:07,  7.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3696/3750 [07:45<00:06,  7.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3698/3750 [07:45<00:06,  7.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3700/3750 [07:45<00:06,  7.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3702/3750 [07:46<00:06,  7.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3704/3750 [07:46<00:05,  7.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3706/3750 [07:46<00:05,  7.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3708/3750 [07:46<00:05,  7.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3710/3750 [07:46<00:05,  7.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3712/3750 [07:46<00:04,  7.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3714/3750 [07:46<00:04,  7.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3716/3750 [07:46<00:04,  7.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3718/3750 [07:46<00:04,  7.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3720/3750 [07:47<00:03,  7.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3722/3750 [07:47<00:03,  7.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3724/3750 [07:47<00:03,  7.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3726/3750 [07:47<00:03,  7.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3728/3750 [07:47<00:02,  7.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|| 3730/3750 [07:47<00:02,  7.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|| 3732/3750 [07:47<00:02,  7.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|| 3734/3750 [07:47<00:02,  7.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|| 3736/3750 [07:47<00:01,  7.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|| 3738/3750 [07:48<00:01,  7.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|| 3740/3750 [07:48<00:01,  7.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|| 3742/3750 [07:48<00:01,  7.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|| 3744/3750 [07:48<00:00,  7.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|| 3746/3750 [07:48<00:00,  8.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|| 3748/3750 [07:48<00:00,  8.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|| 3750/3750 [07:48<00:00,  8.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|| 3750/3750 [07:50<00:00,  7.98it/s, loss=0.0849, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nan0hu-nj5Zm"
   },
   "source": [
    "## Load the Stored Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T13:03:06.550253Z",
     "iopub.status.busy": "2024-02-27T13:03:06.549917Z",
     "iopub.status.idle": "2024-02-27T13:03:08.694709Z",
     "shell.execute_reply": "2024-02-27T13:03:08.694174Z",
     "shell.execute_reply.started": "2024-02-27T13:03:06.550225Z"
    },
    "id": "27yNiUp_W1pn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.load_from_checkpoint(\"/mnt/workspace/ORL/lightning_logs/version_0/checkpoints/epoch=2-step=470.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T13:03:16.977947Z",
     "iopub.status.busy": "2024-02-27T13:03:16.977623Z",
     "iopub.status.idle": "2024-02-27T13:03:24.844373Z",
     "shell.execute_reply": "2024-02-27T13:03:24.843720Z",
     "shell.execute_reply.started": "2024-02-27T13:03:16.977926Z"
    },
    "id": "-yVoc97oPged",
    "outputId": "06ddd83e-dae5-43f4-b585-fd1056192d07",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: calhoun city , mississippi\n",
      "\n",
      "Actual Entities: loc: calhoun city , mississippi\n",
      "Predicted Entities: loc: calhoun city , mississippi\n",
      "=====================================================================\n",
      "\n",
      "text: honorary fellow of the american institute of architects ( 1993 ) and of the royal institute of\n",
      "british architects ( 1995 ) .\n",
      "\n",
      "Actual Entities: org: american institute of architects; org: royal institute of british architects\n",
      "Predicted Entities: org: american institute of architects; org: royal institute of british architects\n",
      "=====================================================================\n",
      "\n",
      "text: museo di storia naturale di venezia , venice\n",
      "\n",
      "Actual Entities: org: museo di storia naturale di venezia; loc: venice\n",
      "Predicted Entities: loc: museo di storia naturale di venezia\n",
      "=====================================================================\n",
      "\n",
      "text: edgar allan poe in popular culture\n",
      "\n",
      "Actual Entities: org: edgar allan poe in popular culture\n",
      "Predicted Entities: per: edgar allan poe in popular culture\n",
      "=====================================================================\n",
      "\n",
      "text: '' shine my shoes ''\n",
      "\n",
      "Actual Entities: org: shine my shoes\n",
      "Predicted Entities: org: shine my shoes\n",
      "=====================================================================\n",
      "\n",
      "text: vrmlands ln , seat no .\n",
      "\n",
      "Actual Entities: org: vrmlands ln\n",
      "Predicted Entities: loc: vrmlands ln\n",
      "=====================================================================\n",
      "\n",
      "text: their first retail store was set up at shaw house and centre on scotts road .\n",
      "\n",
      "Actual Entities: org: shaw house and centre; loc: scotts road\n",
      "Predicted Entities: org: shaw house and centre; loc: scotts road\n",
      "=====================================================================\n",
      "\n",
      "text: on 28 july 2006 , it was sold to air greenland .\n",
      "\n",
      "Actual Entities: org: air greenland\n",
      "Predicted Entities: org: air greenland\n",
      "=====================================================================\n",
      "\n",
      "text: buchanan 's birthplace state park ( franklin county )\n",
      "\n",
      "Actual Entities: org: buchanan 's birthplace state park; loc: franklin county\n",
      "Predicted Entities: loc: buchanan 's birthplace state park; loc: frankli\n",
      "=====================================================================\n",
      "\n",
      "text: *american singer-guitarist glen campbell covered the song on his 12th album wichita lineman ''\n",
      ", released in 1968 by capitol records .\n",
      "\n",
      "Actual Entities: per: glen campbell; org: wichita lineman; org: capitol records\n",
      "Predicted Entities: per: glen campbell; org: wichita lineman;\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "dataloader = DataLoader(input_dataset, batch_size=32, num_workers=2, shuffle=True)\n",
    "model.model.eval()\n",
    "model = model.to(\"cpu\")\n",
    "outputs = []\n",
    "targets = []\n",
    "texts = []\n",
    "for batch in dataloader:\n",
    "\n",
    "    outs = model.model.generate(input_ids=batch['source_ids'],\n",
    "                                attention_mask=batch['source_mask'])\n",
    "    dec = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip() for ids in outs]\n",
    "    target = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"target_ids\"]]\n",
    "    text = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"source_ids\"]]\n",
    "    texts.extend(text)\n",
    "    outputs.extend(dec)\n",
    "    targets.extend(target)\n",
    "    break\n",
    "\n",
    "for i in range(10):\n",
    "    c = texts[i]\n",
    "    lines = textwrap.wrap(\"text:\\n%s\\n\" % c, width=100)\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nActual Entities: %s\" % target[i])\n",
    "    print(\"Predicted Entities: %s\" % outputs[i])\n",
    "    print(\"=====================================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T13:04:07.805434Z",
     "iopub.status.busy": "2024-02-27T13:04:07.805085Z",
     "iopub.status.idle": "2024-02-27T13:04:07.811701Z",
     "shell.execute_reply": "2024-02-27T13:04:07.811208Z",
     "shell.execute_reply.started": "2024-02-27T13:04:07.805408Z"
    },
    "id": "Q358Ph_JUeSA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_sub_list(sl, l):\n",
    "    results = []\n",
    "    sll = len(sl)\n",
    "    for ind in (i for i, e in enumerate(l) if e == sl[0]):\n",
    "        if l[ind:ind+sll] == sl:\n",
    "            results.append((ind, ind+sll-1))\n",
    "    return results\n",
    "\n",
    "def generate_label(input: str, target: str):\n",
    "    mapper = {'O': 0, 'B-DATE': 1, 'I-DATE': 2, 'B-PER': 3,\n",
    "              'I-PER': 4, 'B-ORG': 5, 'I-ORG': 6, 'B-LOC': 7, 'I-LOC': 8}\n",
    "    inv_mapper = {v: k for k, v in mapper.items()}\n",
    "\n",
    "    input = input.split(\" \")\n",
    "    target = target.split(\"; \")\n",
    "\n",
    "    init_target_label = [mapper['O']]*len(input)\n",
    "\n",
    "    for ent in target:\n",
    "        ent = ent.split(\": \")\n",
    "        try:\n",
    "            sent_end = ent[1].split(\" \")\n",
    "            index = find_sub_list(sent_end, input)\n",
    "        except:\n",
    "            continue\n",
    "        # print(index)\n",
    "        try:\n",
    "            init_target_label[index[0][0]] = mapper[f\"B-{ent[0].upper()}\"]\n",
    "            for i in range(index[0][0]+1, index[0][1]+1):\n",
    "                init_target_label[i] = mapper[f\"I-{ent[0].upper()}\"]\n",
    "        except:\n",
    "            continue\n",
    "    init_target_label = [inv_mapper[j] for j in init_target_label]\n",
    "    return init_target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T13:04:11.030985Z",
     "iopub.status.busy": "2024-02-27T13:04:11.030664Z",
     "iopub.status.idle": "2024-02-27T13:05:34.504615Z",
     "shell.execute_reply": "2024-02-27T13:05:34.504054Z",
     "shell.execute_reply.started": "2024-02-27T13:04:11.030962Z"
    },
    "id": "s8b7-Y07T5qV",
    "outputId": "6ff28c77-103b-4a3a-f50b-0b3c1dbee16c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|| 313/313 [01:18<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "test_dataset = WikiAnnDataset(tokenizer=tokenizer, dataset=dataset, type_path='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=32,\n",
    "                             num_workers=2, shuffle=True)\n",
    "model.model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "outputs = []\n",
    "targets = []\n",
    "all_text = []\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "for batch in tqdm(test_loader):\n",
    "    input_ids = batch['source_ids'].to(\"cuda\")\n",
    "    attention_mask = batch['source_mask'].to(\"cuda\")\n",
    "    outs = model.model.generate(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "    dec = [tokenizer.decode(ids, skip_special_tokens=True,\n",
    "                            clean_up_tokenization_spaces=False).strip() for ids in outs]\n",
    "    target = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"target_ids\"]]\n",
    "    texts = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"source_ids\"]]\n",
    "    true_label = [generate_label(texts[i].strip(), target[i].strip()) if target[i].strip() != 'none' else [\n",
    "        \"O\"]*len(texts[i].strip().split()) for i in range(len(texts))]\n",
    "    pred_label = [generate_label(texts[i].strip(), dec[i].strip()) if dec[i].strip() != 'none' else [\n",
    "        \"O\"]*len(texts[i].strip().split()) for i in range(len(texts))]\n",
    "\n",
    "    outputs.extend(dec)\n",
    "    targets.extend(target)\n",
    "    true_labels.extend(true_label)\n",
    "    pred_labels.extend(pred_label)\n",
    "    all_text.extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T13:05:43.154403Z",
     "iopub.status.busy": "2024-02-27T13:05:43.154049Z",
     "iopub.status.idle": "2024-02-27T13:05:43.159246Z",
     "shell.execute_reply": "2024-02-27T13:05:43.158785Z",
     "shell.execute_reply.started": "2024-02-27T13:05:43.154377Z"
    },
    "id": "MTDdTHwdadFx",
    "outputId": "845d8b90-cd00-490e-f0a9-96d71eff167e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"orguss '' - additional voices\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T13:06:23.049881Z",
     "iopub.status.busy": "2024-02-27T13:06:23.049554Z",
     "iopub.status.idle": "2024-02-27T13:06:28.187486Z",
     "shell.execute_reply": "2024-02-27T13:06:28.186898Z",
     "shell.execute_reply.started": "2024-02-27T13:06:23.049861Z"
    },
    "id": "ZrFA-BSHerhf",
    "outputId": "3df4f246-e26e-46ff-dd92-cf5a6da5cc4f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/datasets/load.py:753: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.1/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  reginald beckwith as kenniston .\n",
      "Predicted Token Class:  ['B-PER', 'I-PER', 'O', 'B-PER', 'O']\n",
      "True Token Class:  ['B-PER', 'I-PER', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  orguss '' - additional voices\n",
      "Predicted Token Class:  ['B-ORG', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['B-ORG', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  dihedral symmetry groups with even-orders have a number of subgroups .\n",
      "Predicted Token Class:  ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  council of southern africa football associations\n",
      "Predicted Token Class:  ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']\n",
      "True Token Class:  ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']\n",
      "=====================================================================\n",
      "\n",
      "Text:  he died in 1924 and was buried in the htel des invalides .\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  paul warren rieger .\n",
      "Predicted Token Class:  ['B-PER', 'I-PER', 'I-PER', 'O']\n",
      "True Token Class:  ['B-PER', 'I-PER', 'I-PER', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  diggy liggy lo '' ( j. d. miller )  2:16\n",
      "Predicted Token Class:  ['B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  '' pereza '' '\n",
      "Predicted Token Class:  ['O', 'B-LOC', 'O', 'O']\n",
      "True Token Class:  ['O', 'B-ORG', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  atkinson , new hampshire\n",
      "Predicted Token Class:  ['B-LOC', 'I-LOC', 'I-LOC', 'I-LOC']\n",
      "True Token Class:  ['B-LOC', 'I-LOC', 'I-LOC', 'I-LOC']\n",
      "=====================================================================\n",
      "\n",
      "Text:  san diego county , california\n",
      "Predicted Token Class:  ['B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC']\n",
      "True Token Class:  ['B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC']\n",
      "=====================================================================\n",
      "\n",
      "{'LOC': {'precision': 0.7034047919293821, 'recall': 0.6028966709900562, 'f1': 0.6492841345594227, 'number': 4626}, 'ORG': {'precision': 0.6855995410212278, 'recall': 0.5156418554476807, 'f1': 0.5885974633665805, 'number': 4635}, 'PER': {'precision': 0.7557732680195941, 'recall': 0.7139709122961657, 'f1': 0.7342776203966006, 'number': 4538}, 'overall_precision': 0.7172431419321861, 'overall_recall': 0.6101166751213856, 'overall_f1': 0.6593570113952305, 'overall_accuracy': 0.8310771188661119}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Text:  {all_text[i]}\")\n",
    "    print(f\"Predicted Token Class:  {pred_labels[i]}\")\n",
    "    print(f\"True Token Class:  {true_labels[i]}\")\n",
    "    print(\"=====================================================================\\n\")\n",
    "\n",
    "print(metric.compute(predictions=pred_labels, references=true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sF7loiUFVbQM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "T5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "005a930db3d242a4be28a9c5923eed76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0305993a3c1a4f8296faeb1aba61fa38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0573bd35717d4189ab4d74fdc489653b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bd7b7a9f5f80492997ec2cbd4bf22627",
       "IPY_MODEL_1b08c691a8db4cb79e6f7837a08ac799",
       "IPY_MODEL_b904bbebe38943728a23a0d630f86a88"
      ],
      "layout": "IPY_MODEL_06e6627b73a24e4291f316a281a20aea"
     }
    },
    "06e6627b73a24e4291f316a281a20aea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "0e46dd857d504def992f555a9e9c9c5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "127c67d7658d4bf392408e7d5600a09c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b08c691a8db4cb79e6f7837a08ac799": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f69895f136a14e629614a45f2e7d8557",
      "max": 1250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cfcb95376da04ce884ab18c57c2d63ed",
      "value": 1250
     }
    },
    "1fac6af61b4d411a94f3916061731428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20d7306a9b474da3b0c8e80a3d7abe09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_264fdba12e854d54b3ed2510458c7a1b",
      "placeholder": "",
      "style": "IPY_MODEL_95d7c71216094ea0b466a79efc95341d",
      "value": " 1250/1250 [02:30&lt;00:00,  8.20it/s]"
     }
    },
    "21b88aca18f048759fb25ce63540c992": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25b71debb82040a2960eb8348df2a4ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "264fdba12e854d54b3ed2510458c7a1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285649e2ae134f87bd2f8dcf40a7758d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3e24f0b77884455868b103ab69ddd5d",
      "placeholder": "",
      "style": "IPY_MODEL_c3c43f7938044239b4eca004d07874ae",
      "value": "100%"
     }
    },
    "304c605d63584a298e8cefd4ffcf4ead": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfdd904fb4924ad8948793222255cc3b",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d88a23982ac46b3b8077264a6998b9a",
      "value": 3
     }
    },
    "347f2c97cd4f46aa8bd1d30f79041b29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37a7f3f9244a4fd991fe9e8847268ec1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fce9ba2896164d4391fea7f32dc3d811",
      "placeholder": "",
      "style": "IPY_MODEL_0305993a3c1a4f8296faeb1aba61fa38",
      "value": " 1250/1250 [02:30&lt;00:00,  8.20it/s]"
     }
    },
    "388d8e1e34a143c3afe9e4082be44ebb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3898654592194daca51999f513192a24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39ceb75a4fa14f6e9a8a5f4ae1324cbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4bba40ddade644b79cce613925a4f47e",
       "IPY_MODEL_aa38ae45e85545bebec6c8b43db7abbf",
       "IPY_MODEL_37a7f3f9244a4fd991fe9e8847268ec1"
      ],
      "layout": "IPY_MODEL_49901550f7c14e439505f80faaaa8357"
     }
    },
    "3b924323276f4f92a66a64d295ba6c78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ddd6cf350fb4378ad6cf2698f67d68f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21b88aca18f048759fb25ce63540c992",
      "placeholder": "",
      "style": "IPY_MODEL_3b924323276f4f92a66a64d295ba6c78",
      "value": "Validating: 100%"
     }
    },
    "429fbc36c65446d09d32298cfc4b606e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43278de125c54c1e8b55baa0370c4cc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45340f3b0bf4413182060f27c7458334": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f16174670d2c4182ace507dda7812328",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_966b77941ef046babfb1e9ed597a6aee",
      "value": 3
     }
    },
    "47144694b20f49f0aa54ee1d83119fda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48bb2d6d069e411a9e969187d5ddf17d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81211b58e69b4973a9e1b500e621656b",
      "placeholder": "",
      "style": "IPY_MODEL_347f2c97cd4f46aa8bd1d30f79041b29",
      "value": "Epoch 2: 100%"
     }
    },
    "49901550f7c14e439505f80faaaa8357": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "4b15ff3c6b044b40a15b21f051bf53c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "4bba40ddade644b79cce613925a4f47e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce10ff94a3454674a5deb511394387ff",
      "placeholder": "",
      "style": "IPY_MODEL_b537afbec50e4567885220cf27a5b761",
      "value": "Validating: 100%"
     }
    },
    "4fb2b190729943cb8c1f1fd2b84d6935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fffbd7c89314024a7b8c128ad1ba248": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d4e33c5404f49caa4811bfd55b0bee5",
      "max": 3750,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce97e8d1d6b54e17a16ec75e1b3abf7f",
      "value": 3750
     }
    },
    "5587ced0255640dd9bec68478cd973fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "56496f0e8cef4b5cb989f289af418f9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d4e33c5404f49caa4811bfd55b0bee5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d88a23982ac46b3b8077264a6998b9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5fd2178313d34631a030d79934dcffe0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4dc2a989d794b44b8000ca88cf095fa",
      "placeholder": "",
      "style": "IPY_MODEL_b449b3c3b1b944a38293f2f13d517860",
      "value": " 3/3 [00:00&lt;00:00, 64.65it/s]"
     }
    },
    "6bf0078bd11d4ed980f1b7a9b612a091": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbcd62725c684fcc897583042ca44888",
      "placeholder": "",
      "style": "IPY_MODEL_e61579f72d51414782f8fe3c28e12e86",
      "value": " 3/3 [00:00&lt;00:00, 73.09it/s]"
     }
    },
    "79385887dd0f479d993b251748f8cb2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ca93c1fe9a9415e9c7d6f22a58b90d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa0489927bdd4bf4809c9fcc92d9d7b4",
      "placeholder": "",
      "style": "IPY_MODEL_43278de125c54c1e8b55baa0370c4cc1",
      "value": " 3/3 [00:00&lt;00:00, 48.52it/s]"
     }
    },
    "81211b58e69b4973a9e1b500e621656b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83ec7a9ea11e410bb3fcad13c082d664": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_429fbc36c65446d09d32298cfc4b606e",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79385887dd0f479d993b251748f8cb2f",
      "value": 3
     }
    },
    "84ab2eb4f0b74ac3a334eb7ecd7c4d63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "84c7612e3ed740958159eec4ee147476": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93c2ea7279794b88b6264f832400e3c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5a571c48de54900b2b696f2c6817a2e",
      "placeholder": "",
      "style": "IPY_MODEL_4fb2b190729943cb8c1f1fd2b84d6935",
      "value": "100%"
     }
    },
    "9428191170994f0aa7fd400caf0d1d07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95d7c71216094ea0b466a79efc95341d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "966b77941ef046babfb1e9ed597a6aee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "97e269fbcb954d629b2314d30c41c57b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_93c2ea7279794b88b6264f832400e3c7",
       "IPY_MODEL_45340f3b0bf4413182060f27c7458334",
       "IPY_MODEL_6bf0078bd11d4ed980f1b7a9b612a091"
      ],
      "layout": "IPY_MODEL_84c7612e3ed740958159eec4ee147476"
     }
    },
    "9cd468cf60c643db96d0cd35923c8258": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0a3db286a1843b293b1d3b944a3d33a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9428191170994f0aa7fd400caf0d1d07",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_25b71debb82040a2960eb8348df2a4ca",
      "value": 2
     }
    },
    "a5a571c48de54900b2b696f2c6817a2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa38ae45e85545bebec6c8b43db7abbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d26f30f1432e4f2ab1c53484b44989ee",
      "max": 1250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be10758757c1426c8779c6706a445ecd",
      "value": 1250
     }
    },
    "b112c9a8184d4b479fc0e59698789b43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebcc288979ff4cd5901e9223063751d1",
       "IPY_MODEL_304c605d63584a298e8cefd4ffcf4ead",
       "IPY_MODEL_7ca93c1fe9a9415e9c7d6f22a58b90d1"
      ],
      "layout": "IPY_MODEL_e550224ab580420cb4973b805c2393af"
     }
    },
    "b3e24f0b77884455868b103ab69ddd5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b449b3c3b1b944a38293f2f13d517860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b537afbec50e4567885220cf27a5b761": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b58e5e54e53e46d7a4f196a93812373c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b849b43f5c4649deb018fb959191edc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b904bbebe38943728a23a0d630f86a88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3898654592194daca51999f513192a24",
      "placeholder": "",
      "style": "IPY_MODEL_47144694b20f49f0aa54ee1d83119fda",
      "value": " 1250/1250 [02:30&lt;00:00,  8.22it/s]"
     }
    },
    "ba1298c2f3db42c48b7e3e3ee83d5000": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_285649e2ae134f87bd2f8dcf40a7758d",
       "IPY_MODEL_83ec7a9ea11e410bb3fcad13c082d664",
       "IPY_MODEL_5fd2178313d34631a030d79934dcffe0"
      ],
      "layout": "IPY_MODEL_0e46dd857d504def992f555a9e9c9c5f"
     }
    },
    "ba6f4922558c41fea4a4b171a021b871": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48bb2d6d069e411a9e969187d5ddf17d",
       "IPY_MODEL_4fffbd7c89314024a7b8c128ad1ba248",
       "IPY_MODEL_dea06faaa22b41b6bbfd7ff6d8ee39f6"
      ],
      "layout": "IPY_MODEL_5587ced0255640dd9bec68478cd973fb"
     }
    },
    "bd7b7a9f5f80492997ec2cbd4bf22627": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cddc7d98bbb740a9a81bf8e244d4595d",
      "placeholder": "",
      "style": "IPY_MODEL_9cd468cf60c643db96d0cd35923c8258",
      "value": "Validating: 100%"
     }
    },
    "be10758757c1426c8779c6706a445ecd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c3c43f7938044239b4eca004d07874ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4dc2a989d794b44b8000ca88cf095fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cddc7d98bbb740a9a81bf8e244d4595d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce10ff94a3454674a5deb511394387ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce97e8d1d6b54e17a16ec75e1b3abf7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ceca8a9a02fe46d5a1a3aa093fdbcde7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b849b43f5c4649deb018fb959191edc5",
      "max": 1250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b58e5e54e53e46d7a4f196a93812373c",
      "value": 1250
     }
    },
    "cfcb95376da04ce884ab18c57c2d63ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d26f30f1432e4f2ab1c53484b44989ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2b327e2b0074354a6b889afc169a62e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f8ebf6d2f2954cbbb525e67de58a766a",
       "IPY_MODEL_a0a3db286a1843b293b1d3b944a3d33a",
       "IPY_MODEL_d68d5a7c97bd47719eb1e19f67d64805"
      ],
      "layout": "IPY_MODEL_84ab2eb4f0b74ac3a334eb7ecd7c4d63"
     }
    },
    "d37bf18a5e9346fcb59242e0e5288307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d68d5a7c97bd47719eb1e19f67d64805": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dffd33c1015f4bfd91fd702095c2127e",
      "placeholder": "",
      "style": "IPY_MODEL_ef4fa30c44df4726a36cfc1da100fb4f",
      "value": " 2/2 [00:00&lt;00:00,  3.48it/s]"
     }
    },
    "dbcd62725c684fcc897583042ca44888": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dea06faaa22b41b6bbfd7ff6d8ee39f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_005a930db3d242a4be28a9c5923eed76",
      "placeholder": "",
      "style": "IPY_MODEL_d37bf18a5e9346fcb59242e0e5288307",
      "value": " 3750/3750 [15:58&lt;00:00,  3.91it/s, loss=0.103, v_num=0]"
     }
    },
    "dfdd904fb4924ad8948793222255cc3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dffd33c1015f4bfd91fd702095c2127e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e550224ab580420cb4973b805c2393af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e61579f72d51414782f8fe3c28e12e86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebcc288979ff4cd5901e9223063751d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_388d8e1e34a143c3afe9e4082be44ebb",
      "placeholder": "",
      "style": "IPY_MODEL_56496f0e8cef4b5cb989f289af418f9f",
      "value": "100%"
     }
    },
    "ef4fa30c44df4726a36cfc1da100fb4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f16174670d2c4182ace507dda7812328": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f69895f136a14e629614a45f2e7d8557": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8ebf6d2f2954cbbb525e67de58a766a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_127c67d7658d4bf392408e7d5600a09c",
      "placeholder": "",
      "style": "IPY_MODEL_1fac6af61b4d411a94f3916061731428",
      "value": "Validation sanity check: 100%"
     }
    },
    "fa0489927bdd4bf4809c9fcc92d9d7b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fce9ba2896164d4391fea7f32dc3d811": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffe6027ef4bb4fd9964717116a39f1a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3ddd6cf350fb4378ad6cf2698f67d68f",
       "IPY_MODEL_ceca8a9a02fe46d5a1a3aa093fdbcde7",
       "IPY_MODEL_20d7306a9b474da3b0c8e80a3d7abe09"
      ],
      "layout": "IPY_MODEL_4b15ff3c6b044b40a15b21f051bf53c8"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
