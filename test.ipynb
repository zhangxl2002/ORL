{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zhangxl2002/ORL/blob/main/T5_Ner_Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:14:19.480171Z",
     "iopub.status.busy": "2024-02-28T14:14:19.479860Z",
     "iopub.status.idle": "2024-02-28T14:14:19.806834Z",
     "shell.execute_reply": "2024-02-28T14:14:19.806292Z",
     "shell.execute_reply.started": "2024-02-28T14:14:19.480151Z"
    },
    "id": "60Y1tlwa3Xzr",
    "outputId": "1c139d68-ea58-410c-cbe8-30a88af57671",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 28 22:14:19 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10          Off  | 00000000:00:08.0 Off |                    0 |\n",
      "|  0%   25C    P8     8W / 150W |      0MiB / 22731MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T11:46:03.615350Z",
     "iopub.status.busy": "2024-02-28T11:46:03.615160Z",
     "iopub.status.idle": "2024-02-28T11:46:03.618572Z",
     "shell.execute_reply": "2024-02-28T11:46:03.617968Z",
     "shell.execute_reply.started": "2024-02-28T11:46:03.615332Z"
    },
    "id": "4rfSWZLR6E7k",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "\n",
    "# try:\n",
    "#   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "# except ValueError:\n",
    "#   raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "# tf.config.experimental_connect_to_cluster(tpu)\n",
    "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "# tpu_strategy = tf.distribute.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T11:46:03.619198Z",
     "iopub.status.busy": "2024-02-28T11:46:03.619062Z",
     "iopub.status.idle": "2024-02-28T11:46:03.622519Z",
     "shell.execute_reply": "2024-02-28T11:46:03.621968Z",
     "shell.execute_reply.started": "2024-02-28T11:46:03.619184Z"
    },
    "id": "t9OP72ZA5jQo",
    "outputId": "e4824393-4d31-47ae-d60b-62cfda0c1189",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install pytorch_lightning\n",
    "# !pip install sentencepiece datasets seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BlIYFZKgmOU"
   },
   "source": [
    "# Named Entity Recognition with T5\n",
    "\n",
    "This notebook shows how to finetune [T5 Model](https://https://huggingface.co/docs/transformers/model_doc/t5) for token classification or named entity recognition with pytorch lighning. In this demo, I used the T5-Small and cast the entities as a text using the text to text framework used in the t5 paper. During Eval the generated tokens are then split and classifies into their specific classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:14:23.741652Z",
     "iopub.status.busy": "2024-02-28T14:14:23.741327Z",
     "iopub.status.idle": "2024-02-28T14:14:27.411717Z",
     "shell.execute_reply": "2024-02-28T14:14:27.411232Z",
     "shell.execute_reply.started": "2024-02-28T14:14:23.741632Z"
    },
    "id": "cBQiMj-p5lfz",
    "outputId": "7802de39-2c8b-4e20-c061-164dcbb6af9e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    MT5ForConditionalGeneration,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:14:29.473867Z",
     "iopub.status.busy": "2024-02-28T14:14:29.473454Z",
     "iopub.status.idle": "2024-02-28T14:14:29.527177Z",
     "shell.execute_reply": "2024-02-28T14:14:29.526681Z",
     "shell.execute_reply.started": "2024-02-28T14:14:29.473846Z"
    },
    "id": "0WqcwP916Dwq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:14:30.727929Z",
     "iopub.status.busy": "2024-02-28T14:14:30.727603Z",
     "iopub.status.idle": "2024-02-28T14:14:30.980906Z",
     "shell.execute_reply": "2024-02-28T14:14:30.980442Z",
     "shell.execute_reply.started": "2024-02-28T14:14:30.727909Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:14:36.446536Z",
     "iopub.status.busy": "2024-02-28T14:14:36.446076Z",
     "iopub.status.idle": "2024-02-28T14:15:04.104154Z",
     "shell.execute_reply": "2024-02-28T14:15:04.103481Z",
     "shell.execute_reply.started": "2024-02-28T14:14:36.446513Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 2.09M/2.09M [00:10<00:00, 200kB/s]\n",
      "Downloading data: 100%|██████████| 539k/539k [00:01<00:00, 287kB/s]\n",
      "Downloading data: 100%|██████████| 894k/894k [00:02<00:00, 309kB/s]\n",
      "Generating train split: 3549 examples [00:00, 155609.29 examples/s]\n",
      "Generating validation split: 893 examples [00:00, 169418.92 examples/s]\n",
      "Generating test split: 1509 examples [00:00, 204181.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"zhangxl2002/mpqa_ORL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:15:30.477538Z",
     "iopub.status.busy": "2024-02-28T14:15:30.476989Z",
     "iopub.status.idle": "2024-02-28T14:15:30.751473Z",
     "shell.execute_reply": "2024-02-28T14:15:30.750974Z",
     "shell.execute_reply.started": "2024-02-28T14:15:30.477514Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': ['He', 'argued', 'that', 'had', 'the', 'West', 'not', 'continued', 'to', 'keep', 'alive', 'during', 'the', 'past', 'several', 'years', 'the', 'Cold', 'War', 'stereotype', 'of', 'a', 'threat', 'from', 'the', 'East', ',', 'but', 'would', 'have', 'concentrated', 'instead', 'on', 'terrorism', ',', 'the', 'common', 'enemy', ',', 'the', 'twin', 'towers', 'of', 'New', 'York', 'may', 'not', 'have', 'collapsed', '.'], 'label_ids': [1, 3, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0], 'labels': ['B-AGENT', 'B-DSE', 'O', 'O', 'B-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O'], 'spans': ['AGENT: He', 'TARGET: the West', 'TARGET: terrorism', 'TARGET: the twin towers of New York may not have collapsed'], 'dse': 'argued'}\n",
      "{'words': ['They', 'think', 'she', 'is', 'traveling', 'too', 'much', ',', 'while', 'internal', 'problems', 'sap', 'the', 'country', \"'s\", 'energy', ',', 'and', 'that', 'she', 'has', 'misplaced', 'strategic', 'priorities', 'in', 'her', 'overseas', 'visits', '.'], 'label_ids': [1, 3, 5, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': ['B-AGENT', 'B-DSE', 'B-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'spans': ['AGENT: They', 'TARGET: she', 'TARGET: internal problems', 'TARGET: she'], 'dse': 'think'}\n",
      "{'words': ['He', 'claims', 'that', 'he', 'belongs', 'to', 'the', 'good', 'side', 'and', 'whoever', 'is', 'on', 'the', 'other', 'side', 'is', 'the', 'evil', 'that', 'must', 'be', 'destroyed', 'or', 'at', 'least', 'deserves', 'condemnation', '.'], 'label_ids': [1, 3, 0, 5, 0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 6, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': ['B-AGENT', 'B-DSE', 'O', 'B-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'B-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'spans': ['AGENT: He', 'TARGET: he', 'TARGET: whoever is on the other side', 'TARGET: the evil'], 'dse': 'claims'}\n",
      "{'words': ['``', 'The', 'situation', 'we', 'see', 'now', 'is', 'what', 'I', 'call', 'the', 'Last', 'Supper', '--', 'it', 'is', 'ZANU-PF', \"'s\", 'final', 'feast', ',', \"''\", 'Mr.', 'Tsvangirai', 'said', '.'], 'label_ids': [0, 5, 6, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': ['O', 'B-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'B-DSE', 'O', 'O', 'O', 'O', 'B-TARGET', 'O', 'B-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'spans': ['TARGET: The situation', 'AGENT: I', 'TARGET: it', 'TARGET: ZANU-PF'], 'dse': 'call'}\n",
      "{'words': ['Protesters', 'carried', 'banners', 'reading', ',', '``', 'Ratify', 'the', 'Kyoto', 'Protocol', ',', \"''\", 'and', '``', 'Koizumi', 'say', '`', 'No', \"'\", 'to', 'Bush', ':', 'Stick', 'to', 'Kyoto', 'Protocol', '.', \"''\"], 'label_ids': [1, 3, 4, 4, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 6, 0, 0], 'labels': ['B-AGENT', 'B-DSE', 'I-DSE', 'I-DSE', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'O', 'O'], 'spans': ['AGENT: Protesters', 'TARGET: the Kyoto Protocol', 'TARGET: Bush', 'TARGET: Kyoto Protocol'], 'dse': 'carried banners reading'}\n",
      "{'words': ['Carl', 'Pope', ',', 'the', 'director', 'of', 'the', 'Sierra', 'Club', ',', 'considers', 'for', 'his', 'part', 'that', 'the', 'Bush', 'Administration', '``', 'is', 'sticking', 'to', 'the', 'polluting', 'policies', 'that', 'the', 'energy', 'industry', 'asked', 'for', 'rather', 'than', 'taking', 'the', 'sensible', 'steps', 'that', 'can', 'protect', 'our', 'health', '.', \"''\"], 'label_ids': [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 0, 0, 0], 'labels': ['B-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DSE', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'spans': ['AGENT: Carl Pope', 'TARGET: the Bush Administration', 'TARGET: the polluting policies', 'TARGET: the sensible steps'], 'dse': 'considers'}\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(len(dataset['train'])):\n",
    "    if len(dataset['train'][i]['spans']) > 3:\n",
    "        print(dataset['train'][i])\n",
    "        cnt+=1\n",
    "        if cnt>5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:15:42.085306Z",
     "iopub.status.busy": "2024-02-28T14:15:42.084743Z",
     "iopub.status.idle": "2024-02-28T14:15:42.088099Z",
     "shell.execute_reply": "2024-02-28T14:15:42.087634Z",
     "shell.execute_reply.started": "2024-02-28T14:15:42.085282Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['words', 'label_ids', 'labels', 'spans', 'dse'],\n",
      "        num_rows: 3549\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['words', 'label_ids', 'labels', 'spans', 'dse'],\n",
      "        num_rows: 893\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['words', 'label_ids', 'labels', 'spans', 'dse'],\n",
      "        num_rows: 1509\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:15:57.416351Z",
     "iopub.status.busy": "2024-02-28T14:15:57.415778Z",
     "iopub.status.idle": "2024-02-28T14:15:57.421671Z",
     "shell.execute_reply": "2024-02-28T14:15:57.421212Z",
     "shell.execute_reply.started": "2024-02-28T14:15:57.416327Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Kimberley Provincial Hospital said it would probably know by Tuesday whether one of its patients had Congo Fever .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(dataset['train'][0]['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:15:59.815006Z",
     "iopub.status.busy": "2024-02-28T14:15:59.814680Z",
     "iopub.status.idle": "2024-02-28T14:15:59.819500Z",
     "shell.execute_reply": "2024-02-28T14:15:59.819045Z",
     "shell.execute_reply.started": "2024-02-28T14:15:59.814986Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': ['The',\n",
       "  'Kimberley',\n",
       "  'Provincial',\n",
       "  'Hospital',\n",
       "  'said',\n",
       "  'it',\n",
       "  'would',\n",
       "  'probably',\n",
       "  'know',\n",
       "  'by',\n",
       "  'Tuesday',\n",
       "  'whether',\n",
       "  'one',\n",
       "  'of',\n",
       "  'its',\n",
       "  'patients',\n",
       "  'had',\n",
       "  'Congo',\n",
       "  'Fever',\n",
       "  '.'],\n",
       " 'label_ids': [1, 2, 2, 2, 0, 0, 3, 4, 4, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 0],\n",
       " 'labels': ['B-AGENT',\n",
       "  'I-AGENT',\n",
       "  'I-AGENT',\n",
       "  'I-AGENT',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-DSE',\n",
       "  'I-DSE',\n",
       "  'I-DSE',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-TARGET',\n",
       "  'I-TARGET',\n",
       "  'I-TARGET',\n",
       "  'I-TARGET',\n",
       "  'I-TARGET',\n",
       "  'I-TARGET',\n",
       "  'I-TARGET',\n",
       "  'I-TARGET',\n",
       "  'O'],\n",
       " 'spans': ['AGENT: The Kimberley Provincial Hospital',\n",
       "  'TARGET: whether one of its patients had Congo Fever'],\n",
       " 'dse': 'would probably know'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:03.808350Z",
     "iopub.status.busy": "2024-02-28T14:16:03.808004Z",
     "iopub.status.idle": "2024-02-28T14:16:03.814544Z",
     "shell.execute_reply": "2024-02-28T14:16:03.814024Z",
     "shell.execute_reply.started": "2024-02-28T14:16:03.808329Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MPQADataset(Dataset):\n",
    "  def __init__(self, tokenizer, dataset, type_path, max_len=512):\n",
    "\n",
    "    self.data = dataset[type_path]\n",
    "    self.max_len = max_len\n",
    "    self.tokenizer = tokenizer\n",
    "    self.tokenizer.max_length = max_len\n",
    "    self.tokenizer.model_max_length = max_len\n",
    "    self.inputs = []\n",
    "    self.targets = []\n",
    "\n",
    "    self._build()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.inputs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
    "    target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
    "\n",
    "    src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "    target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "\n",
    "    return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "\n",
    "  def _build(self):\n",
    "    for idx in range(len(self.data)):\n",
    "      input_, target = \" \".join(self.data[idx][\"words\"]), \"; \".join(self.data[idx][\"spans\"])\n",
    "      input_ = input_ + \" DSE:\" + self.data[idx][\"dse\"]\n",
    "\n",
    "      input_ = input_.lower() + ' </s>'\n",
    "      target = target.lower() + \" </s>\"\n",
    "\n",
    "       # tokenize inputs\n",
    "      tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
    "          [input_], max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "      )\n",
    "       # tokenize targets\n",
    "      tokenized_targets = self.tokenizer.batch_encode_plus(\n",
    "          [target],max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "      )\n",
    "\n",
    "      self.inputs.append(tokenized_inputs)\n",
    "      self.targets.append(tokenized_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:07.466521Z",
     "iopub.status.busy": "2024-02-28T14:16:07.466195Z",
     "iopub.status.idle": "2024-02-28T14:16:10.213091Z",
     "shell.execute_reply": "2024-02-28T14:16:10.212619Z",
     "shell.execute_reply.started": "2024-02-28T14:16:07.466502Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5TokenizerFast(name_or_path='../T5-base', vocab_size=32100, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32000: AddedToken(\"<extra_id_99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32001: AddedToken(\"<extra_id_98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32002: AddedToken(\"<extra_id_97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32003: AddedToken(\"<extra_id_96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32004: AddedToken(\"<extra_id_95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32005: AddedToken(\"<extra_id_94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32006: AddedToken(\"<extra_id_93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32007: AddedToken(\"<extra_id_92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32008: AddedToken(\"<extra_id_91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32009: AddedToken(\"<extra_id_90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32010: AddedToken(\"<extra_id_89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32011: AddedToken(\"<extra_id_88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32012: AddedToken(\"<extra_id_87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32013: AddedToken(\"<extra_id_86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32014: AddedToken(\"<extra_id_85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32015: AddedToken(\"<extra_id_84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32016: AddedToken(\"<extra_id_83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32017: AddedToken(\"<extra_id_82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32018: AddedToken(\"<extra_id_81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32019: AddedToken(\"<extra_id_80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32020: AddedToken(\"<extra_id_79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32021: AddedToken(\"<extra_id_78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32022: AddedToken(\"<extra_id_77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32023: AddedToken(\"<extra_id_76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32024: AddedToken(\"<extra_id_75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32025: AddedToken(\"<extra_id_74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32026: AddedToken(\"<extra_id_73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32027: AddedToken(\"<extra_id_72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32028: AddedToken(\"<extra_id_71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32029: AddedToken(\"<extra_id_70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32030: AddedToken(\"<extra_id_69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32031: AddedToken(\"<extra_id_68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32032: AddedToken(\"<extra_id_67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32033: AddedToken(\"<extra_id_66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32034: AddedToken(\"<extra_id_65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32035: AddedToken(\"<extra_id_64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32036: AddedToken(\"<extra_id_63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32037: AddedToken(\"<extra_id_62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32038: AddedToken(\"<extra_id_61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32039: AddedToken(\"<extra_id_60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32040: AddedToken(\"<extra_id_59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32041: AddedToken(\"<extra_id_58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32042: AddedToken(\"<extra_id_57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32043: AddedToken(\"<extra_id_56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32044: AddedToken(\"<extra_id_55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32045: AddedToken(\"<extra_id_54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32046: AddedToken(\"<extra_id_53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32047: AddedToken(\"<extra_id_52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32048: AddedToken(\"<extra_id_51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32049: AddedToken(\"<extra_id_50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32050: AddedToken(\"<extra_id_49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32051: AddedToken(\"<extra_id_48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32052: AddedToken(\"<extra_id_47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32053: AddedToken(\"<extra_id_46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32054: AddedToken(\"<extra_id_45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32055: AddedToken(\"<extra_id_44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32056: AddedToken(\"<extra_id_43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32057: AddedToken(\"<extra_id_42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32058: AddedToken(\"<extra_id_41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32059: AddedToken(\"<extra_id_40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32060: AddedToken(\"<extra_id_39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32061: AddedToken(\"<extra_id_38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32062: AddedToken(\"<extra_id_37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32063: AddedToken(\"<extra_id_36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32064: AddedToken(\"<extra_id_35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32065: AddedToken(\"<extra_id_34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32066: AddedToken(\"<extra_id_33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32067: AddedToken(\"<extra_id_32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32068: AddedToken(\"<extra_id_31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32069: AddedToken(\"<extra_id_30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32070: AddedToken(\"<extra_id_29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32071: AddedToken(\"<extra_id_28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32072: AddedToken(\"<extra_id_27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32073: AddedToken(\"<extra_id_26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32074: AddedToken(\"<extra_id_25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32075: AddedToken(\"<extra_id_24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32076: AddedToken(\"<extra_id_23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32077: AddedToken(\"<extra_id_22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32078: AddedToken(\"<extra_id_21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32079: AddedToken(\"<extra_id_20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32080: AddedToken(\"<extra_id_19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32081: AddedToken(\"<extra_id_18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32082: AddedToken(\"<extra_id_17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32083: AddedToken(\"<extra_id_16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32084: AddedToken(\"<extra_id_15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32085: AddedToken(\"<extra_id_14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32086: AddedToken(\"<extra_id_13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32087: AddedToken(\"<extra_id_12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32088: AddedToken(\"<extra_id_11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32089: AddedToken(\"<extra_id_10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32090: AddedToken(\"<extra_id_9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32091: AddedToken(\"<extra_id_8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32092: AddedToken(\"<extra_id_7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32093: AddedToken(\"<extra_id_6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32094: AddedToken(\"<extra_id_5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32095: AddedToken(\"<extra_id_4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32096: AddedToken(\"<extra_id_3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32097: AddedToken(\"<extra_id_2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32098: AddedToken(\"<extra_id_1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32099: AddedToken(\"<extra_id_0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../T5-base\")\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "input_dataset = MPQADataset(tokenizer=tokenizer, dataset=dataset, type_path='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:13.171208Z",
     "iopub.status.busy": "2024-02-28T14:16:13.170875Z",
     "iopub.status.idle": "2024-02-28T14:16:13.203985Z",
     "shell.execute_reply": "2024-02-28T14:16:13.203516Z",
     "shell.execute_reply.started": "2024-02-28T14:16:13.171189Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(input_dataset)):\n",
    "    _ = input_dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:13.859761Z",
     "iopub.status.busy": "2024-02-28T14:16:13.859213Z",
     "iopub.status.idle": "2024-02-28T14:16:13.865043Z",
     "shell.execute_reply": "2024-02-28T14:16:13.864610Z",
     "shell.execute_reply.started": "2024-02-28T14:16:13.859741Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the kimberley provincial hospital said it would probably know by tuesday whether one of its patients had congo fever. dse:would probably know</s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "agent: the kimberley provincial hospital; target: whether one of its patients had congo fever</s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "data = input_dataset[0]\n",
    "\n",
    "print(tokenizer.decode(data[\"source_ids\"], skip_special_tokens=False))\n",
    "print(tokenizer.decode(data[\"target_ids\"], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:33.181671Z",
     "iopub.status.busy": "2024-02-28T14:16:33.181353Z",
     "iopub.status.idle": "2024-02-28T14:16:33.185008Z",
     "shell.execute_reply": "2024-02-28T14:16:33.184575Z",
     "shell.execute_reply.started": "2024-02-28T14:16:33.181650Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args_dict = dict(\n",
    "    data_dir=\"zhangxl2002/mpqa_ORL\", # path for data files\n",
    "    output_dir=\"\", # path to save the checkpoints\n",
    "    model_name_or_path='t5-base',\n",
    "    tokenizer_name_or_path='t5-base',\n",
    "    max_seq_length=256,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    gradient_accumulation_steps=16,\n",
    "    n_gpu=1,\n",
    "    early_stop_callback=False,\n",
    "    fp_16=True, # if you want to enable 16-bit training then install apex and set this to true\n",
    "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
    "    max_grad_norm=1, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:34.903982Z",
     "iopub.status.busy": "2024-02-28T14:16:34.903434Z",
     "iopub.status.idle": "2024-02-28T14:16:34.906468Z",
     "shell.execute_reply": "2024-02-28T14:16:34.905943Z",
     "shell.execute_reply.started": "2024-02-28T14:16:34.903962Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:37.580505Z",
     "iopub.status.busy": "2024-02-28T14:16:37.579929Z",
     "iopub.status.idle": "2024-02-28T14:16:37.591249Z",
     "shell.execute_reply": "2024-02-28T14:16:37.590740Z",
     "shell.execute_reply.started": "2024-02-28T14:16:37.580485Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "    def __init__(self, hparam):\n",
    "        super(T5FineTuner, self).__init__()\n",
    "        self.hparam = hparam\n",
    "\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "            hparam.model_name_or_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            hparam.model_name_or_path\n",
    "        )\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def is_logger(self):\n",
    "        return True\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
    "    ):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=lm_labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            lm_labels=lm_labels,\n",
    "            decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        tensorboard_logs = {\"train_loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparam.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.hparam.learning_rate, eps=self.hparam.adam_epsilon)\n",
    "        self.opt = optimizer\n",
    "        return [optimizer]\n",
    "\n",
    "    def optimizer_step(self,\n",
    "                       epoch=None,\n",
    "                       batch_idx=None,\n",
    "                       optimizer=None,\n",
    "                       optimizer_idx=None,\n",
    "                       optimizer_closure=None,\n",
    "                       on_tpu=None,\n",
    "                       using_native_amp=None,\n",
    "                       using_lbfgs=None\n",
    "                       ):\n",
    "\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "        optimizer.zero_grad()\n",
    "        self.lr_scheduler.step()\n",
    "\n",
    "    def get_tqdm_dict(self):\n",
    "        tqdm_dict = {\"loss\": \"{:.3f}\".format(\n",
    "            self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "\n",
    "        return tqdm_dict\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = get_dataset(\n",
    "            tokenizer=self.tokenizer, type_path=\"train\", args=self.hparam)\n",
    "        dataloader = DataLoader(train_dataset, batch_size=self.hparam.train_batch_size,\n",
    "                                drop_last=True, shuffle=True, num_workers=2)\n",
    "        t_total = (\n",
    "            (len(dataloader.dataset) //\n",
    "             (self.hparam.train_batch_size * max(1, self.hparam.n_gpu)))\n",
    "            // self.hparam.gradient_accumulation_steps\n",
    "            * float(self.hparam.num_train_epochs)\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.opt, num_warmup_steps=self.hparam.warmup_steps, num_training_steps=t_total\n",
    "        )\n",
    "        self.lr_scheduler = scheduler\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = get_dataset(\n",
    "            tokenizer=self.tokenizer, type_path=\"validation\", args=self.hparam)\n",
    "        return DataLoader(val_dataset, batch_size=self.hparam.eval_batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:39.522728Z",
     "iopub.status.busy": "2024-02-28T14:16:39.522408Z",
     "iopub.status.idle": "2024-02-28T14:16:46.303899Z",
     "shell.execute_reply": "2024-02-28T14:16:46.303415Z",
     "shell.execute_reply.started": "2024-02-28T14:16:39.522708Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = T5FineTuner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:49.405585Z",
     "iopub.status.busy": "2024-02-28T14:16:49.405011Z",
     "iopub.status.idle": "2024-02-28T14:16:49.410174Z",
     "shell.execute_reply": "2024-02-28T14:16:49.409675Z",
     "shell.execute_reply.started": "2024-02-28T14:16:49.405565Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LoggingCallback(pl.Callback):\n",
    "  def on_validation_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Validation results *****\")\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "      # Log results\n",
    "      for key in sorted(metrics):\n",
    "        if key not in [\"log\", \"progress_bar\"]:\n",
    "          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "  def on_test_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Test results *****\")\n",
    "\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "\n",
    "      # Log and save results to file\n",
    "      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
    "      with open(output_test_results_file, \"w\") as writer:\n",
    "        for key in sorted(metrics):\n",
    "          if key not in [\"log\", \"progress_bar\"]:\n",
    "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:53.624799Z",
     "iopub.status.busy": "2024-02-28T14:16:53.624457Z",
     "iopub.status.idle": "2024-02-28T14:16:53.629524Z",
     "shell.execute_reply": "2024-02-28T14:16:53.629044Z",
     "shell.execute_reply.started": "2024-02-28T14:16:53.624778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    filename=args.output_dir+\"/checkpoint.pth\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    #early_stop_callback=False,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    #amp_level=args.opt_level,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    callbacks=[LoggingCallback()],\n",
    ")\n",
    "\n",
    "# train_params = dict(\n",
    "#     accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "#     ## gpus=args.n_gpu,\n",
    "#     max_epochs=args.num_train_epochs,\n",
    "#     #early_stop_callback=False,\n",
    "#     precision= 16 if args.fp_16 else 32,\n",
    "#     #amp_level=args.opt_level,\n",
    "#     gradient_clip_val=args.max_grad_norm,\n",
    "#     # callbacks=[LoggingCallback()],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T14:16:59.154405Z",
     "iopub.status.busy": "2024-02-28T14:16:59.153852Z",
     "iopub.status.idle": "2024-02-28T14:16:59.157263Z",
     "shell.execute_reply": "2024-02-28T14:16:59.156780Z",
     "shell.execute_reply.started": "2024-02-28T14:16:59.154380Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset(tokenizer, type_path, args):\n",
    "    tokenizer.max_length = args.max_seq_length\n",
    "    tokenizer.model_max_length = args.max_seq_length\n",
    "    # dataset = load_dataset(args.data_dir)\n",
    "    dataset = load_dataset(\"zhangxl2002/mpqa_ORL\")\n",
    "    return MPQADataset(tokenizer=tokenizer, dataset=dataset, type_path=type_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:17:03.095693Z",
     "iopub.status.busy": "2024-02-28T14:17:03.095368Z",
     "iopub.status.idle": "2024-02-28T14:17:03.102459Z",
     "shell.execute_reply": "2024-02-28T14:17:03.102015Z",
     "shell.execute_reply.started": "2024-02-28T14:17:03.095673Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7fb6a2a8c9d0>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7fb6a2a8c9d0>)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T14:17:04.889255Z",
     "iopub.status.busy": "2024-02-28T14:17:04.888686Z",
     "iopub.status.idle": "2024-02-28T14:54:53.783173Z",
     "shell.execute_reply": "2024-02-28T14:54:53.782617Z",
     "shell.execute_reply.started": "2024-02-28T14:17:04.889232Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:102: UserWarning: When using `Trainer(accumulate_grad_batches != 1)` and overriding `LightningModule.optimizer_{step,zero_grad}`, the hooks will not be called on every batch (rather, they are called on every optimization step).\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "445.807   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/555 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/closure.py:35: LightningDeprecationWarning: One of the returned values {'log'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  80%|███████▉  | 443/555 [03:21<00:50,  2.20it/s, loss=0.307, v_num=4]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  80%|████████  | 445/555 [03:21<00:49,  2.21it/s, loss=0.307, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating:   2%|▏         | 2/112 [00:00<00:16,  6.81it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 447/555 [03:21<00:48,  2.21it/s, loss=0.307, v_num=4]\n",
      "Validating:   4%|▎         | 4/112 [00:00<00:17,  6.22it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 449/555 [03:22<00:47,  2.22it/s, loss=0.307, v_num=4]\n",
      "Validating:   5%|▌         | 6/112 [00:00<00:17,  6.06it/s]\u001b[A\n",
      "Epoch 0:  81%|████████▏ | 451/555 [03:22<00:46,  2.23it/s, loss=0.307, v_num=4]\n",
      "Validating:   7%|▋         | 8/112 [00:01<00:17,  5.98it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 453/555 [03:22<00:45,  2.23it/s, loss=0.307, v_num=4]\n",
      "Validating:   9%|▉         | 10/112 [00:01<00:17,  5.97it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 455/555 [03:23<00:44,  2.24it/s, loss=0.307, v_num=4]\n",
      "Validating:  11%|█         | 12/112 [00:01<00:16,  5.96it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 457/555 [03:23<00:43,  2.24it/s, loss=0.307, v_num=4]\n",
      "Validating:  12%|█▎        | 14/112 [00:02<00:16,  5.94it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 459/555 [03:23<00:42,  2.25it/s, loss=0.307, v_num=4]\n",
      "Validating:  14%|█▍        | 16/112 [00:02<00:16,  5.94it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 461/555 [03:24<00:41,  2.26it/s, loss=0.307, v_num=4]\n",
      "Validating:  16%|█▌        | 18/112 [00:02<00:15,  5.95it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 463/555 [03:24<00:40,  2.26it/s, loss=0.307, v_num=4]\n",
      "Validating:  18%|█▊        | 20/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 465/555 [03:24<00:39,  2.27it/s, loss=0.307, v_num=4]\n",
      "Validating:  20%|█▉        | 22/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 467/555 [03:25<00:38,  2.27it/s, loss=0.307, v_num=4]\n",
      "Validating:  21%|██▏       | 24/112 [00:03<00:14,  5.95it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 469/555 [03:25<00:37,  2.28it/s, loss=0.307, v_num=4]\n",
      "Validating:  23%|██▎       | 26/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 471/555 [03:25<00:36,  2.29it/s, loss=0.307, v_num=4]\n",
      "Validating:  25%|██▌       | 28/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 473/555 [03:26<00:35,  2.29it/s, loss=0.307, v_num=4]\n",
      "Validating:  27%|██▋       | 30/112 [00:04<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 475/555 [03:26<00:34,  2.30it/s, loss=0.307, v_num=4]\n",
      "Validating:  29%|██▊       | 32/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 477/555 [03:26<00:33,  2.30it/s, loss=0.307, v_num=4]\n",
      "Validating:  30%|███       | 34/112 [00:05<00:13,  5.95it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▋ | 479/555 [03:27<00:32,  2.31it/s, loss=0.307, v_num=4]\n",
      "Validating:  32%|███▏      | 36/112 [00:06<00:12,  5.95it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 481/555 [03:27<00:31,  2.32it/s, loss=0.307, v_num=4]\n",
      "Validating:  34%|███▍      | 38/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 483/555 [03:27<00:31,  2.32it/s, loss=0.307, v_num=4]\n",
      "Validating:  36%|███▌      | 40/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 485/555 [03:28<00:30,  2.33it/s, loss=0.307, v_num=4]\n",
      "Validating:  38%|███▊      | 42/112 [00:07<00:11,  5.95it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 487/555 [03:28<00:29,  2.33it/s, loss=0.307, v_num=4]\n",
      "Validating:  39%|███▉      | 44/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 489/555 [03:28<00:28,  2.34it/s, loss=0.307, v_num=4]\n",
      "Validating:  41%|████      | 46/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 491/555 [03:29<00:27,  2.35it/s, loss=0.307, v_num=4]\n",
      "Validating:  43%|████▎     | 48/112 [00:08<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 493/555 [03:29<00:26,  2.35it/s, loss=0.307, v_num=4]\n",
      "Validating:  45%|████▍     | 50/112 [00:08<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 495/555 [03:30<00:25,  2.36it/s, loss=0.307, v_num=4]\n",
      "Validating:  46%|████▋     | 52/112 [00:08<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 497/555 [03:30<00:24,  2.36it/s, loss=0.307, v_num=4]\n",
      "Validating:  48%|████▊     | 54/112 [00:09<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 499/555 [03:30<00:23,  2.37it/s, loss=0.307, v_num=4]\n",
      "Validating:  50%|█████     | 56/112 [00:09<00:09,  5.95it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 501/555 [03:31<00:22,  2.37it/s, loss=0.307, v_num=4]\n",
      "Validating:  52%|█████▏    | 58/112 [00:09<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 503/555 [03:31<00:21,  2.38it/s, loss=0.307, v_num=4]\n",
      "Validating:  54%|█████▎    | 60/112 [00:10<00:08,  5.95it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 505/555 [03:31<00:20,  2.39it/s, loss=0.307, v_num=4]\n",
      "Validating:  55%|█████▌    | 62/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████▏| 507/555 [03:32<00:20,  2.39it/s, loss=0.307, v_num=4]\n",
      "Validating:  57%|█████▋    | 64/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 509/555 [03:32<00:19,  2.40it/s, loss=0.307, v_num=4]\n",
      "Validating:  59%|█████▉    | 66/112 [00:11<00:07,  5.95it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 511/555 [03:32<00:18,  2.40it/s, loss=0.307, v_num=4]\n",
      "Validating:  61%|██████    | 68/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 513/555 [03:33<00:17,  2.41it/s, loss=0.307, v_num=4]\n",
      "Validating:  62%|██████▎   | 70/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 515/555 [03:33<00:16,  2.41it/s, loss=0.307, v_num=4]\n",
      "Validating:  64%|██████▍   | 72/112 [00:12<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 517/555 [03:33<00:15,  2.42it/s, loss=0.307, v_num=4]\n",
      "Validating:  66%|██████▌   | 74/112 [00:12<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▎| 519/555 [03:34<00:14,  2.42it/s, loss=0.307, v_num=4]\n",
      "Validating:  68%|██████▊   | 76/112 [00:12<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 521/555 [03:34<00:13,  2.43it/s, loss=0.307, v_num=4]\n",
      "Validating:  70%|██████▉   | 78/112 [00:13<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 523/555 [03:34<00:13,  2.44it/s, loss=0.307, v_num=4]\n",
      "Validating:  71%|███████▏  | 80/112 [00:13<00:05,  5.95it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 525/555 [03:35<00:12,  2.44it/s, loss=0.307, v_num=4]\n",
      "Validating:  73%|███████▎  | 82/112 [00:13<00:05,  5.95it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 527/555 [03:35<00:11,  2.45it/s, loss=0.307, v_num=4]\n",
      "Validating:  75%|███████▌  | 84/112 [00:14<00:04,  5.95it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 529/555 [03:35<00:10,  2.45it/s, loss=0.307, v_num=4]\n",
      "Validating:  77%|███████▋  | 86/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 531/555 [03:36<00:09,  2.46it/s, loss=0.307, v_num=4]\n",
      "Validating:  79%|███████▊  | 88/112 [00:14<00:04,  5.95it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 533/555 [03:36<00:08,  2.46it/s, loss=0.307, v_num=4]\n",
      "Validating:  80%|████████  | 90/112 [00:15<00:03,  5.95it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 535/555 [03:36<00:08,  2.47it/s, loss=0.307, v_num=4]\n",
      "Validating:  82%|████████▏ | 92/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 537/555 [03:37<00:07,  2.47it/s, loss=0.307, v_num=4]\n",
      "Validating:  84%|████████▍ | 94/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 539/555 [03:37<00:06,  2.48it/s, loss=0.307, v_num=4]\n",
      "Validating:  86%|████████▌ | 96/112 [00:16<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 541/555 [03:37<00:05,  2.48it/s, loss=0.307, v_num=4]\n",
      "Validating:  88%|████████▊ | 98/112 [00:16<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 543/555 [03:38<00:04,  2.49it/s, loss=0.307, v_num=4]\n",
      "Validating:  89%|████████▉ | 100/112 [00:16<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 545/555 [03:38<00:04,  2.50it/s, loss=0.307, v_num=4]\n",
      "Validating:  91%|█████████ | 102/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▊| 547/555 [03:38<00:03,  2.50it/s, loss=0.307, v_num=4]\n",
      "Validating:  93%|█████████▎| 104/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 549/555 [03:39<00:02,  2.51it/s, loss=0.307, v_num=4]\n",
      "Validating:  95%|█████████▍| 106/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 551/555 [03:39<00:01,  2.51it/s, loss=0.307, v_num=4]\n",
      "Validating:  96%|█████████▋| 108/112 [00:18<00:00,  5.95it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 553/555 [03:39<00:00,  2.52it/s, loss=0.307, v_num=4]\n",
      "Validating:  98%|█████████▊| 110/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 555/555 [03:40<00:00,  2.52it/s, loss=0.307, v_num=4]\n",
      "Epoch 0: 100%|██████████| 555/555 [03:40<00:00,  2.52it/s, loss=0.307, v_num=4]\n",
      "Epoch 1:   0%|          | 0/555 [00:00<?, ?it/s, loss=0.307, v_num=4]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  80%|████████  | 444/555 [03:22<00:50,  2.20it/s, loss=0.219, v_num=4]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating:   1%|          | 1/112 [00:00<00:13,  8.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:  80%|████████  | 446/555 [03:22<00:49,  2.20it/s, loss=0.219, v_num=4]\n",
      "Validating:   3%|▎         | 3/112 [00:00<00:17,  6.39it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 448/555 [03:22<00:48,  2.21it/s, loss=0.219, v_num=4]\n",
      "Validating:   4%|▍         | 5/112 [00:00<00:17,  6.12it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 450/555 [03:23<00:47,  2.21it/s, loss=0.219, v_num=4]\n",
      "Validating:   6%|▋         | 7/112 [00:01<00:17,  5.99it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 452/555 [03:23<00:46,  2.22it/s, loss=0.219, v_num=4]\n",
      "Validating:   8%|▊         | 9/112 [00:01<00:17,  5.97it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 454/555 [03:23<00:45,  2.23it/s, loss=0.219, v_num=4]\n",
      "Validating:  10%|▉         | 11/112 [00:01<00:16,  5.96it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 456/555 [03:24<00:44,  2.23it/s, loss=0.219, v_num=4]\n",
      "Validating:  12%|█▏        | 13/112 [00:02<00:16,  5.94it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 458/555 [03:24<00:43,  2.24it/s, loss=0.219, v_num=4]\n",
      "Validating:  13%|█▎        | 15/112 [00:02<00:16,  5.93it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 460/555 [03:24<00:42,  2.25it/s, loss=0.219, v_num=4]\n",
      "Validating:  15%|█▌        | 17/112 [00:02<00:15,  5.95it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 462/555 [03:25<00:41,  2.25it/s, loss=0.219, v_num=4]\n",
      "Validating:  17%|█▋        | 19/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 464/555 [03:25<00:40,  2.26it/s, loss=0.219, v_num=4]\n",
      "Validating:  19%|█▉        | 21/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 466/555 [03:25<00:39,  2.26it/s, loss=0.219, v_num=4]\n",
      "Validating:  21%|██        | 23/112 [00:03<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 468/555 [03:26<00:38,  2.27it/s, loss=0.219, v_num=4]\n",
      "Validating:  22%|██▏       | 25/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 470/555 [03:26<00:37,  2.28it/s, loss=0.219, v_num=4]\n",
      "Validating:  24%|██▍       | 27/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 472/555 [03:26<00:36,  2.28it/s, loss=0.219, v_num=4]\n",
      "Validating:  26%|██▌       | 29/112 [00:04<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 474/555 [03:27<00:35,  2.29it/s, loss=0.219, v_num=4]\n",
      "Validating:  28%|██▊       | 31/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 476/555 [03:27<00:34,  2.29it/s, loss=0.219, v_num=4]\n",
      "Validating:  29%|██▉       | 33/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 478/555 [03:27<00:33,  2.30it/s, loss=0.219, v_num=4]\n",
      "Validating:  31%|███▏      | 35/112 [00:05<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 480/555 [03:28<00:32,  2.30it/s, loss=0.219, v_num=4]\n",
      "Validating:  33%|███▎      | 37/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 482/555 [03:28<00:31,  2.31it/s, loss=0.219, v_num=4]\n",
      "Validating:  35%|███▍      | 39/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 484/555 [03:28<00:30,  2.32it/s, loss=0.219, v_num=4]\n",
      "Validating:  37%|███▋      | 41/112 [00:06<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 486/555 [03:29<00:29,  2.32it/s, loss=0.219, v_num=4]\n",
      "Validating:  38%|███▊      | 43/112 [00:07<00:11,  5.95it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 488/555 [03:29<00:28,  2.33it/s, loss=0.219, v_num=4]\n",
      "Validating:  40%|████      | 45/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 490/555 [03:29<00:27,  2.33it/s, loss=0.219, v_num=4]\n",
      "Validating:  42%|████▏     | 47/112 [00:07<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 492/555 [03:30<00:26,  2.34it/s, loss=0.219, v_num=4]\n",
      "Validating:  44%|████▍     | 49/112 [00:08<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 494/555 [03:30<00:26,  2.35it/s, loss=0.219, v_num=4]\n",
      "Validating:  46%|████▌     | 51/112 [00:08<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 496/555 [03:30<00:25,  2.35it/s, loss=0.219, v_num=4]\n",
      "Validating:  47%|████▋     | 53/112 [00:08<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 498/555 [03:31<00:24,  2.36it/s, loss=0.219, v_num=4]\n",
      "Validating:  49%|████▉     | 55/112 [00:09<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 500/555 [03:31<00:23,  2.36it/s, loss=0.219, v_num=4]\n",
      "Validating:  51%|█████     | 57/112 [00:09<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 502/555 [03:31<00:22,  2.37it/s, loss=0.219, v_num=4]\n",
      "Validating:  53%|█████▎    | 59/112 [00:09<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 504/555 [03:32<00:21,  2.37it/s, loss=0.219, v_num=4]\n",
      "Validating:  54%|█████▍    | 61/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 506/555 [03:32<00:20,  2.38it/s, loss=0.219, v_num=4]\n",
      "Validating:  56%|█████▋    | 63/112 [00:10<00:08,  5.95it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 508/555 [03:32<00:19,  2.39it/s, loss=0.219, v_num=4]\n",
      "Validating:  58%|█████▊    | 65/112 [00:10<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 510/555 [03:33<00:18,  2.39it/s, loss=0.219, v_num=4]\n",
      "Validating:  60%|█████▉    | 67/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 512/555 [03:33<00:17,  2.40it/s, loss=0.219, v_num=4]\n",
      "Validating:  62%|██████▏   | 69/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 514/555 [03:33<00:17,  2.40it/s, loss=0.219, v_num=4]\n",
      "Validating:  63%|██████▎   | 71/112 [00:11<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 516/555 [03:34<00:16,  2.41it/s, loss=0.219, v_num=4]\n",
      "Validating:  65%|██████▌   | 73/112 [00:12<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 518/555 [03:34<00:15,  2.41it/s, loss=0.219, v_num=4]\n",
      "Validating:  67%|██████▋   | 75/112 [00:12<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 520/555 [03:34<00:14,  2.42it/s, loss=0.219, v_num=4]\n",
      "Validating:  69%|██████▉   | 77/112 [00:12<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 522/555 [03:35<00:13,  2.42it/s, loss=0.219, v_num=4]\n",
      "Validating:  71%|███████   | 79/112 [00:13<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 524/555 [03:35<00:12,  2.43it/s, loss=0.219, v_num=4]\n",
      "Validating:  72%|███████▏  | 81/112 [00:13<00:05,  5.95it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 526/555 [03:35<00:11,  2.44it/s, loss=0.219, v_num=4]\n",
      "Validating:  74%|███████▍  | 83/112 [00:13<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 528/555 [03:36<00:11,  2.44it/s, loss=0.219, v_num=4]\n",
      "Validating:  76%|███████▌  | 85/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 530/555 [03:36<00:10,  2.45it/s, loss=0.219, v_num=4]\n",
      "Validating:  78%|███████▊  | 87/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 532/555 [03:37<00:09,  2.45it/s, loss=0.219, v_num=4]\n",
      "Validating:  79%|███████▉  | 89/112 [00:14<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 534/555 [03:37<00:08,  2.46it/s, loss=0.219, v_num=4]\n",
      "Validating:  81%|████████▏ | 91/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 536/555 [03:37<00:07,  2.46it/s, loss=0.219, v_num=4]\n",
      "Validating:  83%|████████▎ | 93/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 538/555 [03:38<00:06,  2.47it/s, loss=0.219, v_num=4]\n",
      "Validating:  85%|████████▍ | 95/112 [00:15<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 540/555 [03:38<00:06,  2.47it/s, loss=0.219, v_num=4]\n",
      "Validating:  87%|████████▋ | 97/112 [00:16<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 542/555 [03:38<00:05,  2.48it/s, loss=0.219, v_num=4]\n",
      "Validating:  88%|████████▊ | 99/112 [00:16<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 544/555 [03:39<00:04,  2.48it/s, loss=0.219, v_num=4]\n",
      "Validating:  90%|█████████ | 101/112 [00:16<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 546/555 [03:39<00:03,  2.49it/s, loss=0.219, v_num=4]\n",
      "Validating:  92%|█████████▏| 103/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 548/555 [03:39<00:02,  2.49it/s, loss=0.219, v_num=4]\n",
      "Validating:  94%|█████████▍| 105/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 550/555 [03:40<00:02,  2.50it/s, loss=0.219, v_num=4]\n",
      "Validating:  96%|█████████▌| 107/112 [00:17<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 552/555 [03:40<00:01,  2.50it/s, loss=0.219, v_num=4]\n",
      "Validating:  97%|█████████▋| 109/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 554/555 [03:40<00:00,  2.51it/s, loss=0.219, v_num=4]\n",
      "Validating:  99%|█████████▉| 111/112 [00:18<00:00,  5.95it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 555/555 [03:41<00:00,  2.51it/s, loss=0.219, v_num=4]\n",
      "Epoch 2:   0%|          | 0/555 [00:00<?, ?it/s, loss=0.219, v_num=4]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  80%|████████  | 444/555 [03:22<00:50,  2.20it/s, loss=0.198, v_num=4]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating:   1%|          | 1/112 [00:00<00:12,  8.96it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2:  80%|████████  | 446/555 [03:22<00:49,  2.20it/s, loss=0.198, v_num=4]\n",
      "Validating:   3%|▎         | 3/112 [00:00<00:16,  6.45it/s]\u001b[A\n",
      "Epoch 2:  81%|████████  | 448/555 [03:22<00:48,  2.21it/s, loss=0.198, v_num=4]\n",
      "Validating:   4%|▍         | 5/112 [00:00<00:17,  6.14it/s]\u001b[A\n",
      "Epoch 2:  81%|████████  | 450/555 [03:23<00:47,  2.22it/s, loss=0.198, v_num=4]\n",
      "Validating:   6%|▋         | 7/112 [00:01<00:17,  6.00it/s]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 452/555 [03:23<00:46,  2.22it/s, loss=0.198, v_num=4]\n",
      "Validating:   8%|▊         | 9/112 [00:01<00:17,  5.97it/s]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 454/555 [03:23<00:45,  2.23it/s, loss=0.198, v_num=4]\n",
      "Validating:  10%|▉         | 11/112 [00:01<00:16,  5.96it/s]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 456/555 [03:24<00:44,  2.23it/s, loss=0.198, v_num=4]\n",
      "Validating:  12%|█▏        | 13/112 [00:02<00:16,  5.95it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 458/555 [03:24<00:43,  2.24it/s, loss=0.198, v_num=4]\n",
      "Validating:  13%|█▎        | 15/112 [00:02<00:16,  5.94it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 460/555 [03:24<00:42,  2.25it/s, loss=0.198, v_num=4]\n",
      "Validating:  15%|█▌        | 17/112 [00:02<00:15,  5.95it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 462/555 [03:25<00:41,  2.25it/s, loss=0.198, v_num=4]\n",
      "Validating:  17%|█▋        | 19/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 464/555 [03:25<00:40,  2.26it/s, loss=0.198, v_num=4]\n",
      "Validating:  19%|█▉        | 21/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 466/555 [03:25<00:39,  2.26it/s, loss=0.198, v_num=4]\n",
      "Validating:  21%|██        | 23/112 [00:03<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 468/555 [03:26<00:38,  2.27it/s, loss=0.198, v_num=4]\n",
      "Validating:  22%|██▏       | 25/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 470/555 [03:26<00:37,  2.28it/s, loss=0.198, v_num=4]\n",
      "Validating:  24%|██▍       | 27/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 472/555 [03:26<00:36,  2.28it/s, loss=0.198, v_num=4]\n",
      "Validating:  26%|██▌       | 29/112 [00:04<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 474/555 [03:27<00:35,  2.29it/s, loss=0.198, v_num=4]\n",
      "Validating:  28%|██▊       | 31/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 476/555 [03:27<00:34,  2.29it/s, loss=0.198, v_num=4]\n",
      "Validating:  29%|██▉       | 33/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 478/555 [03:27<00:33,  2.30it/s, loss=0.198, v_num=4]\n",
      "Validating:  31%|███▏      | 35/112 [00:05<00:12,  5.95it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 480/555 [03:28<00:32,  2.31it/s, loss=0.198, v_num=4]\n",
      "Validating:  33%|███▎      | 37/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 482/555 [03:28<00:31,  2.31it/s, loss=0.198, v_num=4]\n",
      "Validating:  35%|███▍      | 39/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 484/555 [03:28<00:30,  2.32it/s, loss=0.198, v_num=4]\n",
      "Validating:  37%|███▋      | 41/112 [00:06<00:11,  5.95it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 486/555 [03:29<00:29,  2.32it/s, loss=0.198, v_num=4]\n",
      "Validating:  38%|███▊      | 43/112 [00:07<00:11,  5.95it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 488/555 [03:29<00:28,  2.33it/s, loss=0.198, v_num=4]\n",
      "Validating:  40%|████      | 45/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 490/555 [03:29<00:27,  2.33it/s, loss=0.198, v_num=4]\n",
      "Validating:  42%|████▏     | 47/112 [00:07<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 492/555 [03:30<00:26,  2.34it/s, loss=0.198, v_num=4]\n",
      "Validating:  44%|████▍     | 49/112 [00:08<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 494/555 [03:30<00:25,  2.35it/s, loss=0.198, v_num=4]\n",
      "Validating:  46%|████▌     | 51/112 [00:08<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 496/555 [03:30<00:25,  2.35it/s, loss=0.198, v_num=4]\n",
      "Validating:  47%|████▋     | 53/112 [00:08<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 498/555 [03:31<00:24,  2.36it/s, loss=0.198, v_num=4]\n",
      "Validating:  49%|████▉     | 55/112 [00:09<00:09,  5.95it/s]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 500/555 [03:31<00:23,  2.36it/s, loss=0.198, v_num=4]\n",
      "Validating:  51%|█████     | 57/112 [00:09<00:09,  5.95it/s]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 502/555 [03:31<00:22,  2.37it/s, loss=0.198, v_num=4]\n",
      "Validating:  53%|█████▎    | 59/112 [00:09<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 504/555 [03:32<00:21,  2.37it/s, loss=0.198, v_num=4]\n",
      "Validating:  54%|█████▍    | 61/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 506/555 [03:32<00:20,  2.38it/s, loss=0.198, v_num=4]\n",
      "Validating:  56%|█████▋    | 63/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 508/555 [03:32<00:19,  2.39it/s, loss=0.198, v_num=4]\n",
      "Validating:  58%|█████▊    | 65/112 [00:10<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 510/555 [03:33<00:18,  2.39it/s, loss=0.198, v_num=4]\n",
      "Validating:  60%|█████▉    | 67/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 512/555 [03:33<00:17,  2.40it/s, loss=0.198, v_num=4]\n",
      "Validating:  62%|██████▏   | 69/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 514/555 [03:33<00:17,  2.40it/s, loss=0.198, v_num=4]\n",
      "Validating:  63%|██████▎   | 71/112 [00:11<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 516/555 [03:34<00:16,  2.41it/s, loss=0.198, v_num=4]\n",
      "Validating:  65%|██████▌   | 73/112 [00:12<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 518/555 [03:34<00:15,  2.41it/s, loss=0.198, v_num=4]\n",
      "Validating:  67%|██████▋   | 75/112 [00:12<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 520/555 [03:34<00:14,  2.42it/s, loss=0.198, v_num=4]\n",
      "Validating:  69%|██████▉   | 77/112 [00:12<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 522/555 [03:35<00:13,  2.42it/s, loss=0.198, v_num=4]\n",
      "Validating:  71%|███████   | 79/112 [00:13<00:05,  5.95it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 524/555 [03:35<00:12,  2.43it/s, loss=0.198, v_num=4]\n",
      "Validating:  72%|███████▏  | 81/112 [00:13<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 526/555 [03:35<00:11,  2.44it/s, loss=0.198, v_num=4]\n",
      "Validating:  74%|███████▍  | 83/112 [00:13<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 528/555 [03:36<00:11,  2.44it/s, loss=0.198, v_num=4]\n",
      "Validating:  76%|███████▌  | 85/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 530/555 [03:36<00:10,  2.45it/s, loss=0.198, v_num=4]\n",
      "Validating:  78%|███████▊  | 87/112 [00:14<00:04,  5.95it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 532/555 [03:36<00:09,  2.45it/s, loss=0.198, v_num=4]\n",
      "Validating:  79%|███████▉  | 89/112 [00:14<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 534/555 [03:37<00:08,  2.46it/s, loss=0.198, v_num=4]\n",
      "Validating:  81%|████████▏ | 91/112 [00:15<00:03,  5.95it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 536/555 [03:37<00:07,  2.46it/s, loss=0.198, v_num=4]\n",
      "Validating:  83%|████████▎ | 93/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 538/555 [03:37<00:06,  2.47it/s, loss=0.198, v_num=4]\n",
      "Validating:  85%|████████▍ | 95/112 [00:15<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 540/555 [03:38<00:06,  2.47it/s, loss=0.198, v_num=4]\n",
      "Validating:  87%|████████▋ | 97/112 [00:16<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 542/555 [03:38<00:05,  2.48it/s, loss=0.198, v_num=4]\n",
      "Validating:  88%|████████▊ | 99/112 [00:16<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 544/555 [03:38<00:04,  2.48it/s, loss=0.198, v_num=4]\n",
      "Validating:  90%|█████████ | 101/112 [00:16<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 546/555 [03:39<00:03,  2.49it/s, loss=0.198, v_num=4]\n",
      "Validating:  92%|█████████▏| 103/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 548/555 [03:39<00:02,  2.50it/s, loss=0.198, v_num=4]\n",
      "Validating:  94%|█████████▍| 105/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 550/555 [03:39<00:01,  2.50it/s, loss=0.198, v_num=4]\n",
      "Validating:  96%|█████████▌| 107/112 [00:17<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 552/555 [03:40<00:01,  2.51it/s, loss=0.198, v_num=4]\n",
      "Validating:  97%|█████████▋| 109/112 [00:18<00:00,  5.95it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 554/555 [03:40<00:00,  2.51it/s, loss=0.198, v_num=4]\n",
      "Validating:  99%|█████████▉| 111/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 555/555 [03:41<00:00,  2.51it/s, loss=0.198, v_num=4]\n",
      "Epoch 3:   0%|          | 0/555 [00:00<?, ?it/s, loss=0.198, v_num=4]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  80%|████████  | 444/555 [03:22<00:50,  2.20it/s, loss=0.134, v_num=4]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating:   1%|          | 1/112 [00:00<00:13,  8.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3:  80%|████████  | 446/555 [03:22<00:49,  2.20it/s, loss=0.134, v_num=4]\n",
      "Validating:   3%|▎         | 3/112 [00:00<00:17,  6.36it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 448/555 [03:22<00:48,  2.21it/s, loss=0.134, v_num=4]\n",
      "Validating:   4%|▍         | 5/112 [00:00<00:17,  6.11it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 450/555 [03:23<00:47,  2.21it/s, loss=0.134, v_num=4]\n",
      "Validating:   6%|▋         | 7/112 [00:01<00:17,  5.99it/s]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 452/555 [03:23<00:46,  2.22it/s, loss=0.134, v_num=4]\n",
      "Validating:   8%|▊         | 9/112 [00:01<00:17,  5.97it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 454/555 [03:23<00:45,  2.23it/s, loss=0.134, v_num=4]\n",
      "Validating:  10%|▉         | 11/112 [00:01<00:16,  5.96it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 456/555 [03:24<00:44,  2.23it/s, loss=0.134, v_num=4]\n",
      "Validating:  12%|█▏        | 13/112 [00:02<00:16,  5.94it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 458/555 [03:24<00:43,  2.24it/s, loss=0.134, v_num=4]\n",
      "Validating:  13%|█▎        | 15/112 [00:02<00:16,  5.94it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 460/555 [03:24<00:42,  2.24it/s, loss=0.134, v_num=4]\n",
      "Validating:  15%|█▌        | 17/112 [00:02<00:15,  5.95it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 462/555 [03:25<00:41,  2.25it/s, loss=0.134, v_num=4]\n",
      "Validating:  17%|█▋        | 19/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 464/555 [03:25<00:40,  2.26it/s, loss=0.134, v_num=4]\n",
      "Validating:  19%|█▉        | 21/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 466/555 [03:25<00:39,  2.26it/s, loss=0.134, v_num=4]\n",
      "Validating:  21%|██        | 23/112 [00:03<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 468/555 [03:26<00:38,  2.27it/s, loss=0.134, v_num=4]\n",
      "Validating:  22%|██▏       | 25/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 470/555 [03:26<00:37,  2.28it/s, loss=0.134, v_num=4]\n",
      "Validating:  24%|██▍       | 27/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 472/555 [03:26<00:36,  2.28it/s, loss=0.134, v_num=4]\n",
      "Validating:  26%|██▌       | 29/112 [00:04<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 474/555 [03:27<00:35,  2.29it/s, loss=0.134, v_num=4]\n",
      "Validating:  28%|██▊       | 31/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 476/555 [03:27<00:34,  2.29it/s, loss=0.134, v_num=4]\n",
      "Validating:  29%|██▉       | 33/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 478/555 [03:27<00:33,  2.30it/s, loss=0.134, v_num=4]\n",
      "Validating:  31%|███▏      | 35/112 [00:05<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 480/555 [03:28<00:32,  2.30it/s, loss=0.134, v_num=4]\n",
      "Validating:  33%|███▎      | 37/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 482/555 [03:28<00:31,  2.31it/s, loss=0.134, v_num=4]\n",
      "Validating:  35%|███▍      | 39/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 484/555 [03:28<00:30,  2.32it/s, loss=0.134, v_num=4]\n",
      "Validating:  37%|███▋      | 41/112 [00:06<00:11,  5.95it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 486/555 [03:29<00:29,  2.32it/s, loss=0.134, v_num=4]\n",
      "Validating:  38%|███▊      | 43/112 [00:07<00:11,  5.95it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 488/555 [03:29<00:28,  2.33it/s, loss=0.134, v_num=4]\n",
      "Validating:  40%|████      | 45/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 490/555 [03:29<00:27,  2.33it/s, loss=0.134, v_num=4]\n",
      "Validating:  42%|████▏     | 47/112 [00:07<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 492/555 [03:30<00:26,  2.34it/s, loss=0.134, v_num=4]\n",
      "Validating:  44%|████▍     | 49/112 [00:08<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 494/555 [03:30<00:26,  2.35it/s, loss=0.134, v_num=4]\n",
      "Validating:  46%|████▌     | 51/112 [00:08<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 496/555 [03:30<00:25,  2.35it/s, loss=0.134, v_num=4]\n",
      "Validating:  47%|████▋     | 53/112 [00:08<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 498/555 [03:31<00:24,  2.36it/s, loss=0.134, v_num=4]\n",
      "Validating:  49%|████▉     | 55/112 [00:09<00:09,  5.95it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 500/555 [03:31<00:23,  2.36it/s, loss=0.134, v_num=4]\n",
      "Validating:  51%|█████     | 57/112 [00:09<00:09,  5.95it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 502/555 [03:31<00:22,  2.37it/s, loss=0.134, v_num=4]\n",
      "Validating:  53%|█████▎    | 59/112 [00:09<00:08,  5.95it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 504/555 [03:32<00:21,  2.37it/s, loss=0.134, v_num=4]\n",
      "Validating:  54%|█████▍    | 61/112 [00:10<00:08,  5.95it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 506/555 [03:32<00:20,  2.38it/s, loss=0.134, v_num=4]\n",
      "Validating:  56%|█████▋    | 63/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 508/555 [03:32<00:19,  2.39it/s, loss=0.134, v_num=4]\n",
      "Validating:  58%|█████▊    | 65/112 [00:10<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 510/555 [03:33<00:18,  2.39it/s, loss=0.134, v_num=4]\n",
      "Validating:  60%|█████▉    | 67/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 512/555 [03:33<00:17,  2.40it/s, loss=0.134, v_num=4]\n",
      "Validating:  62%|██████▏   | 69/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 514/555 [03:33<00:17,  2.40it/s, loss=0.134, v_num=4]\n",
      "Validating:  63%|██████▎   | 71/112 [00:11<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 516/555 [03:34<00:16,  2.41it/s, loss=0.134, v_num=4]\n",
      "Validating:  65%|██████▌   | 73/112 [00:12<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 518/555 [03:34<00:15,  2.41it/s, loss=0.134, v_num=4]\n",
      "Validating:  67%|██████▋   | 75/112 [00:12<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 520/555 [03:35<00:14,  2.42it/s, loss=0.134, v_num=4]\n",
      "Validating:  69%|██████▉   | 77/112 [00:12<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 522/555 [03:35<00:13,  2.42it/s, loss=0.134, v_num=4]\n",
      "Validating:  71%|███████   | 79/112 [00:13<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 524/555 [03:35<00:12,  2.43it/s, loss=0.134, v_num=4]\n",
      "Validating:  72%|███████▏  | 81/112 [00:13<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 526/555 [03:36<00:11,  2.44it/s, loss=0.134, v_num=4]\n",
      "Validating:  74%|███████▍  | 83/112 [00:13<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 528/555 [03:36<00:11,  2.44it/s, loss=0.134, v_num=4]\n",
      "Validating:  76%|███████▌  | 85/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 530/555 [03:36<00:10,  2.45it/s, loss=0.134, v_num=4]\n",
      "Validating:  78%|███████▊  | 87/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 532/555 [03:37<00:09,  2.45it/s, loss=0.134, v_num=4]\n",
      "Validating:  79%|███████▉  | 89/112 [00:14<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 534/555 [03:37<00:08,  2.46it/s, loss=0.134, v_num=4]\n",
      "Validating:  81%|████████▏ | 91/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 536/555 [03:37<00:07,  2.46it/s, loss=0.134, v_num=4]\n",
      "Validating:  83%|████████▎ | 93/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 538/555 [03:38<00:06,  2.47it/s, loss=0.134, v_num=4]\n",
      "Validating:  85%|████████▍ | 95/112 [00:15<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 540/555 [03:38<00:06,  2.47it/s, loss=0.134, v_num=4]\n",
      "Validating:  87%|████████▋ | 97/112 [00:16<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 542/555 [03:38<00:05,  2.48it/s, loss=0.134, v_num=4]\n",
      "Validating:  88%|████████▊ | 99/112 [00:16<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 544/555 [03:39<00:04,  2.48it/s, loss=0.134, v_num=4]\n",
      "Validating:  90%|█████████ | 101/112 [00:16<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 546/555 [03:39<00:03,  2.49it/s, loss=0.134, v_num=4]\n",
      "Validating:  92%|█████████▏| 103/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 548/555 [03:39<00:02,  2.49it/s, loss=0.134, v_num=4]\n",
      "Validating:  94%|█████████▍| 105/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 550/555 [03:40<00:02,  2.50it/s, loss=0.134, v_num=4]\n",
      "Validating:  96%|█████████▌| 107/112 [00:17<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 552/555 [03:40<00:01,  2.50it/s, loss=0.134, v_num=4]\n",
      "Validating:  97%|█████████▋| 109/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 554/555 [03:40<00:00,  2.51it/s, loss=0.134, v_num=4]\n",
      "Validating:  99%|█████████▉| 111/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 555/555 [03:41<00:00,  2.51it/s, loss=0.134, v_num=4]\n",
      "Epoch 4:   0%|          | 0/555 [00:00<?, ?it/s, loss=0.134, v_num=4]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  80%|████████  | 444/555 [03:22<00:50,  2.20it/s, loss=0.127, v_num=4]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating:   1%|          | 1/112 [00:00<00:13,  8.27it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4:  80%|████████  | 446/555 [03:22<00:49,  2.20it/s, loss=0.127, v_num=4]\n",
      "Validating:   3%|▎         | 3/112 [00:00<00:17,  6.36it/s]\u001b[A\n",
      "Epoch 4:  81%|████████  | 448/555 [03:22<00:48,  2.21it/s, loss=0.127, v_num=4]\n",
      "Validating:   4%|▍         | 5/112 [00:00<00:17,  6.11it/s]\u001b[A\n",
      "Epoch 4:  81%|████████  | 450/555 [03:23<00:47,  2.21it/s, loss=0.127, v_num=4]\n",
      "Validating:   6%|▋         | 7/112 [00:01<00:17,  5.99it/s]\u001b[A\n",
      "Epoch 4:  81%|████████▏ | 452/555 [03:23<00:46,  2.22it/s, loss=0.127, v_num=4]\n",
      "Validating:   8%|▊         | 9/112 [00:01<00:17,  5.97it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 454/555 [03:23<00:45,  2.23it/s, loss=0.127, v_num=4]\n",
      "Validating:  10%|▉         | 11/112 [00:01<00:16,  5.96it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 456/555 [03:24<00:44,  2.23it/s, loss=0.127, v_num=4]\n",
      "Validating:  12%|█▏        | 13/112 [00:02<00:16,  5.94it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 458/555 [03:24<00:43,  2.24it/s, loss=0.127, v_num=4]\n",
      "Validating:  13%|█▎        | 15/112 [00:02<00:16,  5.94it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 460/555 [03:24<00:42,  2.25it/s, loss=0.127, v_num=4]\n",
      "Validating:  15%|█▌        | 17/112 [00:02<00:15,  5.95it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 462/555 [03:25<00:41,  2.25it/s, loss=0.127, v_num=4]\n",
      "Validating:  17%|█▋        | 19/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▎ | 464/555 [03:25<00:40,  2.26it/s, loss=0.127, v_num=4]\n",
      "Validating:  19%|█▉        | 21/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 466/555 [03:25<00:39,  2.26it/s, loss=0.127, v_num=4]\n",
      "Validating:  21%|██        | 23/112 [00:03<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 468/555 [03:26<00:38,  2.27it/s, loss=0.127, v_num=4]\n",
      "Validating:  22%|██▏       | 25/112 [00:04<00:14,  5.95it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▍ | 470/555 [03:26<00:37,  2.28it/s, loss=0.127, v_num=4]\n",
      "Validating:  24%|██▍       | 27/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 472/555 [03:26<00:36,  2.28it/s, loss=0.127, v_num=4]\n",
      "Validating:  26%|██▌       | 29/112 [00:04<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 474/555 [03:27<00:35,  2.29it/s, loss=0.127, v_num=4]\n",
      "Validating:  28%|██▊       | 31/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 476/555 [03:27<00:34,  2.29it/s, loss=0.127, v_num=4]\n",
      "Validating:  29%|██▉       | 33/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 478/555 [03:27<00:33,  2.30it/s, loss=0.127, v_num=4]\n",
      "Validating:  31%|███▏      | 35/112 [00:05<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▋ | 480/555 [03:28<00:32,  2.31it/s, loss=0.127, v_num=4]\n",
      "Validating:  33%|███▎      | 37/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 482/555 [03:28<00:31,  2.31it/s, loss=0.127, v_num=4]\n",
      "Validating:  35%|███▍      | 39/112 [00:06<00:12,  5.95it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 484/555 [03:28<00:30,  2.32it/s, loss=0.127, v_num=4]\n",
      "Validating:  37%|███▋      | 41/112 [00:06<00:11,  5.95it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 486/555 [03:29<00:29,  2.32it/s, loss=0.127, v_num=4]\n",
      "Validating:  38%|███▊      | 43/112 [00:07<00:11,  5.95it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 488/555 [03:29<00:28,  2.33it/s, loss=0.127, v_num=4]\n",
      "Validating:  40%|████      | 45/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 490/555 [03:29<00:27,  2.33it/s, loss=0.127, v_num=4]\n",
      "Validating:  42%|████▏     | 47/112 [00:07<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▊ | 492/555 [03:30<00:26,  2.34it/s, loss=0.127, v_num=4]\n",
      "Validating:  44%|████▍     | 49/112 [00:08<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 494/555 [03:30<00:26,  2.35it/s, loss=0.127, v_num=4]\n",
      "Validating:  46%|████▌     | 51/112 [00:08<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 496/555 [03:30<00:25,  2.35it/s, loss=0.127, v_num=4]\n",
      "Validating:  47%|████▋     | 53/112 [00:08<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 498/555 [03:31<00:24,  2.36it/s, loss=0.127, v_num=4]\n",
      "Validating:  49%|████▉     | 55/112 [00:09<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 4:  90%|█████████ | 500/555 [03:31<00:23,  2.36it/s, loss=0.127, v_num=4]\n",
      "Validating:  51%|█████     | 57/112 [00:09<00:09,  5.95it/s]\u001b[A\n",
      "Epoch 4:  90%|█████████ | 502/555 [03:31<00:22,  2.37it/s, loss=0.127, v_num=4]\n",
      "Validating:  53%|█████▎    | 59/112 [00:09<00:08,  5.95it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 504/555 [03:32<00:21,  2.37it/s, loss=0.127, v_num=4]\n",
      "Validating:  54%|█████▍    | 61/112 [00:10<00:08,  5.95it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 506/555 [03:32<00:20,  2.38it/s, loss=0.127, v_num=4]\n",
      "Validating:  56%|█████▋    | 63/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 508/555 [03:32<00:19,  2.39it/s, loss=0.127, v_num=4]\n",
      "Validating:  58%|█████▊    | 65/112 [00:10<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 510/555 [03:33<00:18,  2.39it/s, loss=0.127, v_num=4]\n",
      "Validating:  60%|█████▉    | 67/112 [00:11<00:07,  5.95it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 512/555 [03:33<00:17,  2.40it/s, loss=0.127, v_num=4]\n",
      "Validating:  62%|██████▏   | 69/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 514/555 [03:33<00:17,  2.40it/s, loss=0.127, v_num=4]\n",
      "Validating:  63%|██████▎   | 71/112 [00:11<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 516/555 [03:34<00:16,  2.41it/s, loss=0.127, v_num=4]\n",
      "Validating:  65%|██████▌   | 73/112 [00:12<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 518/555 [03:34<00:15,  2.41it/s, loss=0.127, v_num=4]\n",
      "Validating:  67%|██████▋   | 75/112 [00:12<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▎| 520/555 [03:34<00:14,  2.42it/s, loss=0.127, v_num=4]\n",
      "Validating:  69%|██████▉   | 77/112 [00:12<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 522/555 [03:35<00:13,  2.42it/s, loss=0.127, v_num=4]\n",
      "Validating:  71%|███████   | 79/112 [00:13<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 524/555 [03:35<00:12,  2.43it/s, loss=0.127, v_num=4]\n",
      "Validating:  72%|███████▏  | 81/112 [00:13<00:05,  5.95it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 526/555 [03:35<00:11,  2.44it/s, loss=0.127, v_num=4]\n",
      "Validating:  74%|███████▍  | 83/112 [00:13<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 528/555 [03:36<00:11,  2.44it/s, loss=0.127, v_num=4]\n",
      "Validating:  76%|███████▌  | 85/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 530/555 [03:36<00:10,  2.45it/s, loss=0.127, v_num=4]\n",
      "Validating:  78%|███████▊  | 87/112 [00:14<00:04,  5.95it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 532/555 [03:36<00:09,  2.45it/s, loss=0.127, v_num=4]\n",
      "Validating:  79%|███████▉  | 89/112 [00:14<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 534/555 [03:37<00:08,  2.46it/s, loss=0.127, v_num=4]\n",
      "Validating:  81%|████████▏ | 91/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 536/555 [03:37<00:07,  2.46it/s, loss=0.127, v_num=4]\n",
      "Validating:  83%|████████▎ | 93/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 538/555 [03:37<00:06,  2.47it/s, loss=0.127, v_num=4]\n",
      "Validating:  85%|████████▍ | 95/112 [00:15<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 540/555 [03:38<00:06,  2.47it/s, loss=0.127, v_num=4]\n",
      "Validating:  87%|████████▋ | 97/112 [00:16<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 542/555 [03:38<00:05,  2.48it/s, loss=0.127, v_num=4]\n",
      "Validating:  88%|████████▊ | 99/112 [00:16<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 544/555 [03:39<00:04,  2.48it/s, loss=0.127, v_num=4]\n",
      "Validating:  90%|█████████ | 101/112 [00:16<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 546/555 [03:39<00:03,  2.49it/s, loss=0.127, v_num=4]\n",
      "Validating:  92%|█████████▏| 103/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 548/555 [03:39<00:02,  2.49it/s, loss=0.127, v_num=4]\n",
      "Validating:  94%|█████████▍| 105/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 550/555 [03:40<00:02,  2.50it/s, loss=0.127, v_num=4]\n",
      "Validating:  96%|█████████▌| 107/112 [00:17<00:00,  5.95it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 552/555 [03:40<00:01,  2.51it/s, loss=0.127, v_num=4]\n",
      "Validating:  97%|█████████▋| 109/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 554/555 [03:40<00:00,  2.51it/s, loss=0.127, v_num=4]\n",
      "Validating:  99%|█████████▉| 111/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 555/555 [03:41<00:00,  2.51it/s, loss=0.127, v_num=4]\n",
      "Epoch 5:   0%|          | 0/555 [00:00<?, ?it/s, loss=0.127, v_num=4]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  80%|████████  | 444/555 [03:22<00:50,  2.20it/s, loss=0.119, v_num=4] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating:   1%|          | 1/112 [00:00<00:13,  8.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5:  80%|████████  | 446/555 [03:22<00:49,  2.20it/s, loss=0.119, v_num=4]\n",
      "Validating:   3%|▎         | 3/112 [00:00<00:17,  6.38it/s]\u001b[A\n",
      "Epoch 5:  81%|████████  | 448/555 [03:22<00:48,  2.21it/s, loss=0.119, v_num=4]\n",
      "Validating:   4%|▍         | 5/112 [00:00<00:17,  6.11it/s]\u001b[A\n",
      "Epoch 5:  81%|████████  | 450/555 [03:23<00:47,  2.21it/s, loss=0.119, v_num=4]\n",
      "Validating:   6%|▋         | 7/112 [00:01<00:17,  6.00it/s]\u001b[A\n",
      "Epoch 5:  81%|████████▏ | 452/555 [03:23<00:46,  2.22it/s, loss=0.119, v_num=4]\n",
      "Validating:   8%|▊         | 9/112 [00:01<00:17,  5.97it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 454/555 [03:23<00:45,  2.23it/s, loss=0.119, v_num=4]\n",
      "Validating:  10%|▉         | 11/112 [00:01<00:16,  5.96it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 456/555 [03:24<00:44,  2.23it/s, loss=0.119, v_num=4]\n",
      "Validating:  12%|█▏        | 13/112 [00:02<00:16,  5.94it/s]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 458/555 [03:24<00:43,  2.24it/s, loss=0.119, v_num=4]\n",
      "Validating:  13%|█▎        | 15/112 [00:02<00:16,  5.95it/s]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 460/555 [03:24<00:42,  2.25it/s, loss=0.119, v_num=4]\n",
      "Validating:  15%|█▌        | 17/112 [00:02<00:15,  5.95it/s]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 462/555 [03:25<00:41,  2.25it/s, loss=0.119, v_num=4]\n",
      "Validating:  17%|█▋        | 19/112 [00:03<00:15,  5.93it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▎ | 464/555 [03:25<00:40,  2.26it/s, loss=0.119, v_num=4]\n",
      "Validating:  19%|█▉        | 21/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 466/555 [03:25<00:39,  2.26it/s, loss=0.119, v_num=4]\n",
      "Validating:  21%|██        | 23/112 [00:03<00:14,  5.95it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 468/555 [03:26<00:38,  2.27it/s, loss=0.119, v_num=4]\n",
      "Validating:  22%|██▏       | 25/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▍ | 470/555 [03:26<00:37,  2.28it/s, loss=0.119, v_num=4]\n",
      "Validating:  24%|██▍       | 27/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▌ | 472/555 [03:26<00:36,  2.28it/s, loss=0.119, v_num=4]\n",
      "Validating:  26%|██▌       | 29/112 [00:04<00:13,  5.95it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▌ | 474/555 [03:27<00:35,  2.29it/s, loss=0.119, v_num=4]\n",
      "Validating:  28%|██▊       | 31/112 [00:05<00:13,  5.95it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 476/555 [03:27<00:34,  2.29it/s, loss=0.119, v_num=4]\n",
      "Validating:  29%|██▉       | 33/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 478/555 [03:27<00:33,  2.30it/s, loss=0.119, v_num=4]\n",
      "Validating:  31%|███▏      | 35/112 [00:05<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▋ | 480/555 [03:28<00:32,  2.30it/s, loss=0.119, v_num=4]\n",
      "Validating:  33%|███▎      | 37/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 482/555 [03:28<00:31,  2.31it/s, loss=0.119, v_num=4]\n",
      "Validating:  35%|███▍      | 39/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 484/555 [03:28<00:30,  2.32it/s, loss=0.119, v_num=4]\n",
      "Validating:  37%|███▋      | 41/112 [00:06<00:11,  5.95it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 486/555 [03:29<00:29,  2.32it/s, loss=0.119, v_num=4]\n",
      "Validating:  38%|███▊      | 43/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 488/555 [03:29<00:28,  2.33it/s, loss=0.119, v_num=4]\n",
      "Validating:  40%|████      | 45/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 490/555 [03:29<00:27,  2.33it/s, loss=0.119, v_num=4]\n",
      "Validating:  42%|████▏     | 47/112 [00:07<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▊ | 492/555 [03:30<00:26,  2.34it/s, loss=0.119, v_num=4]\n",
      "Validating:  44%|████▍     | 49/112 [00:08<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 494/555 [03:30<00:26,  2.35it/s, loss=0.119, v_num=4]\n",
      "Validating:  46%|████▌     | 51/112 [00:08<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 496/555 [03:30<00:25,  2.35it/s, loss=0.119, v_num=4]\n",
      "Validating:  47%|████▋     | 53/112 [00:08<00:09,  5.95it/s]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 498/555 [03:31<00:24,  2.36it/s, loss=0.119, v_num=4]\n",
      "Validating:  49%|████▉     | 55/112 [00:09<00:09,  5.95it/s]\u001b[A\n",
      "Epoch 5:  90%|█████████ | 500/555 [03:31<00:23,  2.36it/s, loss=0.119, v_num=4]\n",
      "Validating:  51%|█████     | 57/112 [00:09<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 5:  90%|█████████ | 502/555 [03:31<00:22,  2.37it/s, loss=0.119, v_num=4]\n",
      "Validating:  53%|█████▎    | 59/112 [00:09<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 504/555 [03:32<00:21,  2.37it/s, loss=0.119, v_num=4]\n",
      "Validating:  54%|█████▍    | 61/112 [00:10<00:08,  5.95it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 506/555 [03:32<00:20,  2.38it/s, loss=0.119, v_num=4]\n",
      "Validating:  56%|█████▋    | 63/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 508/555 [03:32<00:19,  2.39it/s, loss=0.119, v_num=4]\n",
      "Validating:  58%|█████▊    | 65/112 [00:10<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 510/555 [03:33<00:18,  2.39it/s, loss=0.119, v_num=4]\n",
      "Validating:  60%|█████▉    | 67/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 512/555 [03:33<00:17,  2.40it/s, loss=0.119, v_num=4]\n",
      "Validating:  62%|██████▏   | 69/112 [00:11<00:07,  5.95it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 514/555 [03:33<00:17,  2.40it/s, loss=0.119, v_num=4]\n",
      "Validating:  63%|██████▎   | 71/112 [00:11<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 516/555 [03:34<00:16,  2.41it/s, loss=0.119, v_num=4]\n",
      "Validating:  65%|██████▌   | 73/112 [00:12<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 518/555 [03:34<00:15,  2.41it/s, loss=0.119, v_num=4]\n",
      "Validating:  67%|██████▋   | 75/112 [00:12<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▎| 520/555 [03:34<00:14,  2.42it/s, loss=0.119, v_num=4]\n",
      "Validating:  69%|██████▉   | 77/112 [00:12<00:05,  5.95it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 522/555 [03:35<00:13,  2.42it/s, loss=0.119, v_num=4]\n",
      "Validating:  71%|███████   | 79/112 [00:13<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 524/555 [03:35<00:12,  2.43it/s, loss=0.119, v_num=4]\n",
      "Validating:  72%|███████▏  | 81/112 [00:13<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 526/555 [03:35<00:11,  2.44it/s, loss=0.119, v_num=4]\n",
      "Validating:  74%|███████▍  | 83/112 [00:13<00:04,  5.95it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 528/555 [03:36<00:11,  2.44it/s, loss=0.119, v_num=4]\n",
      "Validating:  76%|███████▌  | 85/112 [00:14<00:04,  5.95it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 530/555 [03:36<00:10,  2.45it/s, loss=0.119, v_num=4]\n",
      "Validating:  78%|███████▊  | 87/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 532/555 [03:36<00:09,  2.45it/s, loss=0.119, v_num=4]\n",
      "Validating:  79%|███████▉  | 89/112 [00:14<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 534/555 [03:37<00:08,  2.46it/s, loss=0.119, v_num=4]\n",
      "Validating:  81%|████████▏ | 91/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 536/555 [03:37<00:07,  2.46it/s, loss=0.119, v_num=4]\n",
      "Validating:  83%|████████▎ | 93/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 538/555 [03:38<00:06,  2.47it/s, loss=0.119, v_num=4]\n",
      "Validating:  85%|████████▍ | 95/112 [00:15<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 540/555 [03:38<00:06,  2.47it/s, loss=0.119, v_num=4]\n",
      "Validating:  87%|████████▋ | 97/112 [00:16<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 542/555 [03:38<00:05,  2.48it/s, loss=0.119, v_num=4]\n",
      "Validating:  88%|████████▊ | 99/112 [00:16<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 544/555 [03:39<00:04,  2.48it/s, loss=0.119, v_num=4]\n",
      "Validating:  90%|█████████ | 101/112 [00:16<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 546/555 [03:39<00:03,  2.49it/s, loss=0.119, v_num=4]\n",
      "Validating:  92%|█████████▏| 103/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 548/555 [03:39<00:02,  2.49it/s, loss=0.119, v_num=4]\n",
      "Validating:  94%|█████████▍| 105/112 [00:17<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 550/555 [03:40<00:02,  2.50it/s, loss=0.119, v_num=4]\n",
      "Validating:  96%|█████████▌| 107/112 [00:17<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 552/555 [03:40<00:01,  2.50it/s, loss=0.119, v_num=4]\n",
      "Validating:  97%|█████████▋| 109/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 554/555 [03:40<00:00,  2.51it/s, loss=0.119, v_num=4]\n",
      "Validating:  99%|█████████▉| 111/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 555/555 [03:41<00:00,  2.51it/s, loss=0.119, v_num=4]\n",
      "Epoch 6:   0%|          | 0/555 [00:00<?, ?it/s, loss=0.119, v_num=4]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  80%|████████  | 444/555 [03:22<00:50,  2.20it/s, loss=0.115, v_num=4] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating:   1%|          | 1/112 [00:00<00:12,  8.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6:  80%|████████  | 446/555 [03:22<00:49,  2.20it/s, loss=0.115, v_num=4]\n",
      "Validating:   3%|▎         | 3/112 [00:00<00:17,  6.40it/s]\u001b[A\n",
      "Epoch 6:  81%|████████  | 448/555 [03:22<00:48,  2.21it/s, loss=0.115, v_num=4]\n",
      "Validating:   4%|▍         | 5/112 [00:00<00:17,  6.12it/s]\u001b[A\n",
      "Epoch 6:  81%|████████  | 450/555 [03:23<00:47,  2.22it/s, loss=0.115, v_num=4]\n",
      "Validating:   6%|▋         | 7/112 [00:01<00:17,  6.01it/s]\u001b[A\n",
      "Epoch 6:  81%|████████▏ | 452/555 [03:23<00:46,  2.22it/s, loss=0.115, v_num=4]\n",
      "Validating:   8%|▊         | 9/112 [00:01<00:17,  5.97it/s]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 454/555 [03:23<00:45,  2.23it/s, loss=0.115, v_num=4]\n",
      "Validating:  10%|▉         | 11/112 [00:01<00:16,  5.96it/s]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 456/555 [03:24<00:44,  2.23it/s, loss=0.115, v_num=4]\n",
      "Validating:  12%|█▏        | 13/112 [00:02<00:16,  5.94it/s]\u001b[A\n",
      "Epoch 6:  83%|████████▎ | 458/555 [03:24<00:43,  2.24it/s, loss=0.115, v_num=4]\n",
      "Validating:  13%|█▎        | 15/112 [00:02<00:16,  5.95it/s]\u001b[A\n",
      "Epoch 6:  83%|████████▎ | 460/555 [03:24<00:42,  2.25it/s, loss=0.115, v_num=4]\n",
      "Validating:  15%|█▌        | 17/112 [00:02<00:15,  5.95it/s]\u001b[A\n",
      "Epoch 6:  83%|████████▎ | 462/555 [03:25<00:41,  2.25it/s, loss=0.115, v_num=4]\n",
      "Validating:  17%|█▋        | 19/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 6:  84%|████████▎ | 464/555 [03:25<00:40,  2.26it/s, loss=0.115, v_num=4]\n",
      "Validating:  19%|█▉        | 21/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 466/555 [03:25<00:39,  2.26it/s, loss=0.115, v_num=4]\n",
      "Validating:  21%|██        | 23/112 [00:03<00:14,  5.95it/s]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 468/555 [03:26<00:38,  2.27it/s, loss=0.115, v_num=4]\n",
      "Validating:  22%|██▏       | 25/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 6:  85%|████████▍ | 470/555 [03:26<00:37,  2.28it/s, loss=0.115, v_num=4]\n",
      "Validating:  24%|██▍       | 27/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 6:  85%|████████▌ | 472/555 [03:26<00:36,  2.28it/s, loss=0.115, v_num=4]\n",
      "Validating:  26%|██▌       | 29/112 [00:04<00:13,  5.95it/s]\u001b[A\n",
      "Epoch 6:  85%|████████▌ | 474/555 [03:27<00:35,  2.29it/s, loss=0.115, v_num=4]\n",
      "Validating:  28%|██▊       | 31/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 476/555 [03:27<00:34,  2.29it/s, loss=0.115, v_num=4]\n",
      "Validating:  29%|██▉       | 33/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 478/555 [03:27<00:33,  2.30it/s, loss=0.115, v_num=4]\n",
      "Validating:  31%|███▏      | 35/112 [00:05<00:12,  5.95it/s]\u001b[A\n",
      "Epoch 6:  86%|████████▋ | 480/555 [03:28<00:32,  2.31it/s, loss=0.115, v_num=4]\n",
      "Validating:  33%|███▎      | 37/112 [00:06<00:12,  5.95it/s]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 482/555 [03:28<00:31,  2.31it/s, loss=0.115, v_num=4]\n",
      "Validating:  35%|███▍      | 39/112 [00:06<00:12,  5.95it/s]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 484/555 [03:28<00:30,  2.32it/s, loss=0.115, v_num=4]\n",
      "Validating:  37%|███▋      | 41/112 [00:06<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 486/555 [03:29<00:29,  2.32it/s, loss=0.115, v_num=4]\n",
      "Validating:  38%|███▊      | 43/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 488/555 [03:29<00:28,  2.33it/s, loss=0.115, v_num=4]\n",
      "Validating:  40%|████      | 45/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 490/555 [03:29<00:27,  2.34it/s, loss=0.115, v_num=4]\n",
      "Validating:  42%|████▏     | 47/112 [00:07<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▊ | 492/555 [03:30<00:26,  2.34it/s, loss=0.115, v_num=4]\n",
      "Validating:  44%|████▍     | 49/112 [00:08<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 494/555 [03:30<00:25,  2.35it/s, loss=0.115, v_num=4]\n",
      "Validating:  46%|████▌     | 51/112 [00:08<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 496/555 [03:30<00:25,  2.35it/s, loss=0.115, v_num=4]\n",
      "Validating:  47%|████▋     | 53/112 [00:08<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 6:  90%|████████▉ | 498/555 [03:31<00:24,  2.36it/s, loss=0.115, v_num=4]\n",
      "Validating:  49%|████▉     | 55/112 [00:09<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 6:  90%|█████████ | 500/555 [03:31<00:23,  2.36it/s, loss=0.115, v_num=4]\n",
      "Validating:  51%|█████     | 57/112 [00:09<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 6:  90%|█████████ | 502/555 [03:31<00:22,  2.37it/s, loss=0.115, v_num=4]\n",
      "Validating:  53%|█████▎    | 59/112 [00:09<00:08,  5.95it/s]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 504/555 [03:32<00:21,  2.38it/s, loss=0.115, v_num=4]\n",
      "Validating:  54%|█████▍    | 61/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 506/555 [03:32<00:20,  2.38it/s, loss=0.115, v_num=4]\n",
      "Validating:  56%|█████▋    | 63/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 508/555 [03:32<00:19,  2.39it/s, loss=0.115, v_num=4]\n",
      "Validating:  58%|█████▊    | 65/112 [00:10<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 510/555 [03:33<00:18,  2.39it/s, loss=0.115, v_num=4]\n",
      "Validating:  60%|█████▉    | 67/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 512/555 [03:33<00:17,  2.40it/s, loss=0.115, v_num=4]\n",
      "Validating:  62%|██████▏   | 69/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 514/555 [03:33<00:17,  2.40it/s, loss=0.115, v_num=4]\n",
      "Validating:  63%|██████▎   | 71/112 [00:11<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 516/555 [03:34<00:16,  2.41it/s, loss=0.115, v_num=4]\n",
      "Validating:  65%|██████▌   | 73/112 [00:12<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 518/555 [03:34<00:15,  2.41it/s, loss=0.115, v_num=4]\n",
      "Validating:  67%|██████▋   | 75/112 [00:12<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 6:  94%|█████████▎| 520/555 [03:34<00:14,  2.42it/s, loss=0.115, v_num=4]\n",
      "Validating:  69%|██████▉   | 77/112 [00:12<00:05,  5.95it/s]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 522/555 [03:35<00:13,  2.43it/s, loss=0.115, v_num=4]\n",
      "Validating:  71%|███████   | 79/112 [00:13<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 524/555 [03:35<00:12,  2.43it/s, loss=0.115, v_num=4]\n",
      "Validating:  72%|███████▏  | 81/112 [00:13<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 526/555 [03:35<00:11,  2.44it/s, loss=0.115, v_num=4]\n",
      "Validating:  74%|███████▍  | 83/112 [00:13<00:04,  5.95it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 528/555 [03:36<00:11,  2.44it/s, loss=0.115, v_num=4]\n",
      "Validating:  76%|███████▌  | 85/112 [00:14<00:04,  5.95it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 530/555 [03:36<00:10,  2.45it/s, loss=0.115, v_num=4]\n",
      "Validating:  78%|███████▊  | 87/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 532/555 [03:36<00:09,  2.45it/s, loss=0.115, v_num=4]\n",
      "Validating:  79%|███████▉  | 89/112 [00:14<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 534/555 [03:37<00:08,  2.46it/s, loss=0.115, v_num=4]\n",
      "Validating:  81%|████████▏ | 91/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 536/555 [03:37<00:07,  2.46it/s, loss=0.115, v_num=4]\n",
      "Validating:  83%|████████▎ | 93/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 538/555 [03:37<00:06,  2.47it/s, loss=0.115, v_num=4]\n",
      "Validating:  85%|████████▍ | 95/112 [00:15<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 540/555 [03:38<00:06,  2.47it/s, loss=0.115, v_num=4]\n",
      "Validating:  87%|████████▋ | 97/112 [00:16<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 542/555 [03:38<00:05,  2.48it/s, loss=0.115, v_num=4]\n",
      "Validating:  88%|████████▊ | 99/112 [00:16<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 544/555 [03:38<00:04,  2.49it/s, loss=0.115, v_num=4]\n",
      "Validating:  90%|█████████ | 101/112 [00:16<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 546/555 [03:39<00:03,  2.49it/s, loss=0.115, v_num=4]\n",
      "Validating:  92%|█████████▏| 103/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▊| 548/555 [03:39<00:02,  2.50it/s, loss=0.115, v_num=4]\n",
      "Validating:  94%|█████████▍| 105/112 [00:17<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 550/555 [03:39<00:01,  2.50it/s, loss=0.115, v_num=4]\n",
      "Validating:  96%|█████████▌| 107/112 [00:17<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 552/555 [03:40<00:01,  2.51it/s, loss=0.115, v_num=4]\n",
      "Validating:  97%|█████████▋| 109/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 6: 100%|█████████▉| 554/555 [03:40<00:00,  2.51it/s, loss=0.115, v_num=4]\n",
      "Validating:  99%|█████████▉| 111/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 555/555 [03:40<00:00,  2.51it/s, loss=0.115, v_num=4]\n",
      "Epoch 7:   0%|          | 0/555 [00:00<?, ?it/s, loss=0.115, v_num=4]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  80%|████████  | 444/555 [03:21<00:50,  2.20it/s, loss=0.0963, v_num=4]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating:   1%|          | 1/112 [00:00<00:12,  8.94it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7:  80%|████████  | 446/555 [03:22<00:49,  2.21it/s, loss=0.0963, v_num=4]\n",
      "Validating:   3%|▎         | 3/112 [00:00<00:16,  6.44it/s]\u001b[A\n",
      "Epoch 7:  81%|████████  | 448/555 [03:22<00:48,  2.21it/s, loss=0.0963, v_num=4]\n",
      "Validating:   4%|▍         | 5/112 [00:00<00:17,  6.14it/s]\u001b[A\n",
      "Epoch 7:  81%|████████  | 450/555 [03:22<00:47,  2.22it/s, loss=0.0963, v_num=4]\n",
      "Validating:   6%|▋         | 7/112 [00:01<00:17,  6.01it/s]\u001b[A\n",
      "Epoch 7:  81%|████████▏ | 452/555 [03:23<00:46,  2.22it/s, loss=0.0963, v_num=4]\n",
      "Validating:   8%|▊         | 9/112 [00:01<00:17,  5.98it/s]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 454/555 [03:23<00:45,  2.23it/s, loss=0.0963, v_num=4]\n",
      "Validating:  10%|▉         | 11/112 [00:01<00:16,  5.97it/s]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 456/555 [03:23<00:44,  2.24it/s, loss=0.0963, v_num=4]\n",
      "Validating:  12%|█▏        | 13/112 [00:02<00:16,  5.95it/s]\u001b[A\n",
      "Epoch 7:  83%|████████▎ | 458/555 [03:24<00:43,  2.24it/s, loss=0.0963, v_num=4]\n",
      "Validating:  13%|█▎        | 15/112 [00:02<00:16,  5.95it/s]\u001b[A\n",
      "Epoch 7:  83%|████████▎ | 460/555 [03:24<00:42,  2.25it/s, loss=0.0963, v_num=4]\n",
      "Validating:  15%|█▌        | 17/112 [00:02<00:15,  5.95it/s]\u001b[A\n",
      "Epoch 7:  83%|████████▎ | 462/555 [03:24<00:41,  2.25it/s, loss=0.0963, v_num=4]\n",
      "Validating:  17%|█▋        | 19/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 7:  84%|████████▎ | 464/555 [03:25<00:40,  2.26it/s, loss=0.0963, v_num=4]\n",
      "Validating:  19%|█▉        | 21/112 [00:03<00:15,  5.95it/s]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 466/555 [03:25<00:39,  2.27it/s, loss=0.0963, v_num=4]\n",
      "Validating:  21%|██        | 23/112 [00:03<00:14,  5.95it/s]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 468/555 [03:25<00:38,  2.27it/s, loss=0.0963, v_num=4]\n",
      "Validating:  22%|██▏       | 25/112 [00:04<00:14,  5.95it/s]\u001b[A\n",
      "Epoch 7:  85%|████████▍ | 470/555 [03:26<00:37,  2.28it/s, loss=0.0963, v_num=4]\n",
      "Validating:  24%|██▍       | 27/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 7:  85%|████████▌ | 472/555 [03:26<00:36,  2.28it/s, loss=0.0963, v_num=4]\n",
      "Validating:  26%|██▌       | 29/112 [00:04<00:13,  5.95it/s]\u001b[A\n",
      "Epoch 7:  85%|████████▌ | 474/555 [03:26<00:35,  2.29it/s, loss=0.0963, v_num=4]\n",
      "Validating:  28%|██▊       | 31/112 [00:05<00:13,  5.95it/s]\u001b[A\n",
      "Epoch 7:  86%|████████▌ | 476/555 [03:27<00:34,  2.30it/s, loss=0.0963, v_num=4]\n",
      "Validating:  29%|██▉       | 33/112 [00:05<00:13,  5.95it/s]\u001b[A\n",
      "Epoch 7:  86%|████████▌ | 478/555 [03:27<00:33,  2.30it/s, loss=0.0963, v_num=4]\n",
      "Validating:  31%|███▏      | 35/112 [00:05<00:12,  5.95it/s]\u001b[A\n",
      "Epoch 7:  86%|████████▋ | 480/555 [03:27<00:32,  2.31it/s, loss=0.0963, v_num=4]\n",
      "Validating:  33%|███▎      | 37/112 [00:06<00:12,  5.95it/s]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 482/555 [03:28<00:31,  2.31it/s, loss=0.0963, v_num=4]\n",
      "Validating:  35%|███▍      | 39/112 [00:06<00:12,  5.95it/s]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 484/555 [03:28<00:30,  2.32it/s, loss=0.0963, v_num=4]\n",
      "Validating:  37%|███▋      | 41/112 [00:06<00:11,  5.95it/s]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 486/555 [03:28<00:29,  2.33it/s, loss=0.0963, v_num=4]\n",
      "Validating:  38%|███▊      | 43/112 [00:07<00:11,  5.95it/s]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 488/555 [03:29<00:28,  2.33it/s, loss=0.0963, v_num=4]\n",
      "Validating:  40%|████      | 45/112 [00:07<00:11,  5.95it/s]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 490/555 [03:29<00:27,  2.34it/s, loss=0.0963, v_num=4]\n",
      "Validating:  42%|████▏     | 47/112 [00:07<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 7:  89%|████████▊ | 492/555 [03:29<00:26,  2.34it/s, loss=0.0963, v_num=4]\n",
      "Validating:  44%|████▍     | 49/112 [00:08<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 494/555 [03:30<00:25,  2.35it/s, loss=0.0963, v_num=4]\n",
      "Validating:  46%|████▌     | 51/112 [00:08<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 496/555 [03:30<00:25,  2.35it/s, loss=0.0963, v_num=4]\n",
      "Validating:  47%|████▋     | 53/112 [00:08<00:09,  5.95it/s]\u001b[A\n",
      "Epoch 7:  90%|████████▉ | 498/555 [03:30<00:24,  2.36it/s, loss=0.0963, v_num=4]\n",
      "Validating:  49%|████▉     | 55/112 [00:09<00:09,  5.95it/s]\u001b[A\n",
      "Epoch 7:  90%|█████████ | 500/555 [03:31<00:23,  2.37it/s, loss=0.0963, v_num=4]\n",
      "Validating:  51%|█████     | 57/112 [00:09<00:09,  5.95it/s]\u001b[A\n",
      "Epoch 7:  90%|█████████ | 502/555 [03:31<00:22,  2.37it/s, loss=0.0963, v_num=4]\n",
      "Validating:  53%|█████▎    | 59/112 [00:09<00:08,  5.95it/s]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 504/555 [03:31<00:21,  2.38it/s, loss=0.0963, v_num=4]\n",
      "Validating:  54%|█████▍    | 61/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 506/555 [03:32<00:20,  2.38it/s, loss=0.0963, v_num=4]\n",
      "Validating:  56%|█████▋    | 63/112 [00:10<00:08,  5.95it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 508/555 [03:32<00:19,  2.39it/s, loss=0.0963, v_num=4]\n",
      "Validating:  58%|█████▊    | 65/112 [00:10<00:07,  5.95it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 510/555 [03:32<00:18,  2.39it/s, loss=0.0963, v_num=4]\n",
      "Validating:  60%|█████▉    | 67/112 [00:11<00:07,  5.95it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 512/555 [03:33<00:17,  2.40it/s, loss=0.0963, v_num=4]\n",
      "Validating:  62%|██████▏   | 69/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 514/555 [03:33<00:17,  2.41it/s, loss=0.0963, v_num=4]\n",
      "Validating:  63%|██████▎   | 71/112 [00:11<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 516/555 [03:33<00:16,  2.41it/s, loss=0.0963, v_num=4]\n",
      "Validating:  65%|██████▌   | 73/112 [00:12<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 518/555 [03:34<00:15,  2.42it/s, loss=0.0963, v_num=4]\n",
      "Validating:  67%|██████▋   | 75/112 [00:12<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 7:  94%|█████████▎| 520/555 [03:34<00:14,  2.42it/s, loss=0.0963, v_num=4]\n",
      "Validating:  69%|██████▉   | 77/112 [00:12<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 522/555 [03:35<00:13,  2.43it/s, loss=0.0963, v_num=4]\n",
      "Validating:  71%|███████   | 79/112 [00:13<00:05,  5.95it/s]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 524/555 [03:35<00:12,  2.43it/s, loss=0.0963, v_num=4]\n",
      "Validating:  72%|███████▏  | 81/112 [00:13<00:05,  5.95it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 526/555 [03:35<00:11,  2.44it/s, loss=0.0963, v_num=4]\n",
      "Validating:  74%|███████▍  | 83/112 [00:13<00:04,  5.95it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 528/555 [03:36<00:11,  2.44it/s, loss=0.0963, v_num=4]\n",
      "Validating:  76%|███████▌  | 85/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 530/555 [03:36<00:10,  2.45it/s, loss=0.0963, v_num=4]\n",
      "Validating:  78%|███████▊  | 87/112 [00:14<00:04,  5.95it/s]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 532/555 [03:36<00:09,  2.46it/s, loss=0.0963, v_num=4]\n",
      "Validating:  79%|███████▉  | 89/112 [00:14<00:03,  5.95it/s]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 534/555 [03:37<00:08,  2.46it/s, loss=0.0963, v_num=4]\n",
      "Validating:  81%|████████▏ | 91/112 [00:15<00:03,  5.95it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 536/555 [03:37<00:07,  2.47it/s, loss=0.0963, v_num=4]\n",
      "Validating:  83%|████████▎ | 93/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 538/555 [03:37<00:06,  2.47it/s, loss=0.0963, v_num=4]\n",
      "Validating:  85%|████████▍ | 95/112 [00:15<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 540/555 [03:38<00:06,  2.48it/s, loss=0.0963, v_num=4]\n",
      "Validating:  87%|████████▋ | 97/112 [00:16<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 542/555 [03:38<00:05,  2.48it/s, loss=0.0963, v_num=4]\n",
      "Validating:  88%|████████▊ | 99/112 [00:16<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 544/555 [03:38<00:04,  2.49it/s, loss=0.0963, v_num=4]\n",
      "Validating:  90%|█████████ | 101/112 [00:16<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 546/555 [03:39<00:03,  2.49it/s, loss=0.0963, v_num=4]\n",
      "Validating:  92%|█████████▏| 103/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▊| 548/555 [03:39<00:02,  2.50it/s, loss=0.0963, v_num=4]\n",
      "Validating:  94%|█████████▍| 105/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 550/555 [03:39<00:01,  2.50it/s, loss=0.0963, v_num=4]\n",
      "Validating:  96%|█████████▌| 107/112 [00:17<00:00,  5.95it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 552/555 [03:40<00:01,  2.51it/s, loss=0.0963, v_num=4]\n",
      "Validating:  97%|█████████▋| 109/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 7: 100%|█████████▉| 554/555 [03:40<00:00,  2.51it/s, loss=0.0963, v_num=4]\n",
      "Validating:  99%|█████████▉| 111/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 555/555 [03:40<00:00,  2.51it/s, loss=0.0963, v_num=4]\n",
      "Epoch 8:   0%|          | 0/555 [00:00<?, ?it/s, loss=0.0963, v_num=4]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  80%|████████  | 444/555 [03:21<00:50,  2.20it/s, loss=0.0948, v_num=4]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating:   1%|          | 1/112 [00:00<00:13,  8.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8:  80%|████████  | 446/555 [03:22<00:49,  2.21it/s, loss=0.0948, v_num=4]\n",
      "Validating:   3%|▎         | 3/112 [00:00<00:17,  6.37it/s]\u001b[A\n",
      "Epoch 8:  81%|████████  | 448/555 [03:22<00:48,  2.21it/s, loss=0.0948, v_num=4]\n",
      "Validating:   4%|▍         | 5/112 [00:00<00:17,  6.11it/s]\u001b[A\n",
      "Epoch 8:  81%|████████  | 450/555 [03:22<00:47,  2.22it/s, loss=0.0948, v_num=4]\n",
      "Validating:   6%|▋         | 7/112 [00:01<00:17,  6.00it/s]\u001b[A\n",
      "Epoch 8:  81%|████████▏ | 452/555 [03:23<00:46,  2.22it/s, loss=0.0948, v_num=4]\n",
      "Validating:   8%|▊         | 9/112 [00:01<00:17,  5.97it/s]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 454/555 [03:23<00:45,  2.23it/s, loss=0.0948, v_num=4]\n",
      "Validating:  10%|▉         | 11/112 [00:01<00:16,  5.96it/s]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 456/555 [03:23<00:44,  2.24it/s, loss=0.0948, v_num=4]\n",
      "Validating:  12%|█▏        | 13/112 [00:02<00:16,  5.94it/s]\u001b[A\n",
      "Epoch 8:  83%|████████▎ | 458/555 [03:24<00:43,  2.24it/s, loss=0.0948, v_num=4]\n",
      "Validating:  13%|█▎        | 15/112 [00:02<00:16,  5.95it/s]\u001b[A\n",
      "Epoch 8:  83%|████████▎ | 460/555 [03:24<00:42,  2.25it/s, loss=0.0948, v_num=4]\n",
      "Validating:  15%|█▌        | 17/112 [00:02<00:15,  5.95it/s]\u001b[A\n",
      "Epoch 8:  83%|████████▎ | 462/555 [03:24<00:41,  2.25it/s, loss=0.0948, v_num=4]\n",
      "Validating:  17%|█▋        | 19/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 8:  84%|████████▎ | 464/555 [03:25<00:40,  2.26it/s, loss=0.0948, v_num=4]\n",
      "Validating:  19%|█▉        | 21/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 466/555 [03:25<00:39,  2.27it/s, loss=0.0948, v_num=4]\n",
      "Validating:  21%|██        | 23/112 [00:03<00:14,  5.95it/s]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 468/555 [03:25<00:38,  2.27it/s, loss=0.0948, v_num=4]\n",
      "Validating:  22%|██▏       | 25/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 8:  85%|████████▍ | 470/555 [03:26<00:37,  2.28it/s, loss=0.0948, v_num=4]\n",
      "Validating:  24%|██▍       | 27/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 8:  85%|████████▌ | 472/555 [03:26<00:36,  2.28it/s, loss=0.0948, v_num=4]\n",
      "Validating:  26%|██▌       | 29/112 [00:04<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 8:  85%|████████▌ | 474/555 [03:26<00:35,  2.29it/s, loss=0.0948, v_num=4]\n",
      "Validating:  28%|██▊       | 31/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 8:  86%|████████▌ | 476/555 [03:27<00:34,  2.30it/s, loss=0.0948, v_num=4]\n",
      "Validating:  29%|██▉       | 33/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 8:  86%|████████▌ | 478/555 [03:27<00:33,  2.30it/s, loss=0.0948, v_num=4]\n",
      "Validating:  31%|███▏      | 35/112 [00:05<00:12,  5.95it/s]\u001b[A\n",
      "Epoch 8:  86%|████████▋ | 480/555 [03:27<00:32,  2.31it/s, loss=0.0948, v_num=4]\n",
      "Validating:  33%|███▎      | 37/112 [00:06<00:12,  5.95it/s]\u001b[A\n",
      "Epoch 8:  87%|████████▋ | 482/555 [03:28<00:31,  2.31it/s, loss=0.0948, v_num=4]\n",
      "Validating:  35%|███▍      | 39/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 8:  87%|████████▋ | 484/555 [03:28<00:30,  2.32it/s, loss=0.0948, v_num=4]\n",
      "Validating:  37%|███▋      | 41/112 [00:06<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 486/555 [03:28<00:29,  2.33it/s, loss=0.0948, v_num=4]\n",
      "Validating:  38%|███▊      | 43/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 488/555 [03:29<00:28,  2.33it/s, loss=0.0948, v_num=4]\n",
      "Validating:  40%|████      | 45/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 490/555 [03:29<00:27,  2.34it/s, loss=0.0948, v_num=4]\n",
      "Validating:  42%|████▏     | 47/112 [00:07<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 8:  89%|████████▊ | 492/555 [03:29<00:26,  2.34it/s, loss=0.0948, v_num=4]\n",
      "Validating:  44%|████▍     | 49/112 [00:08<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 494/555 [03:30<00:25,  2.35it/s, loss=0.0948, v_num=4]\n",
      "Validating:  46%|████▌     | 51/112 [00:08<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 496/555 [03:30<00:25,  2.35it/s, loss=0.0948, v_num=4]\n",
      "Validating:  47%|████▋     | 53/112 [00:08<00:09,  5.95it/s]\u001b[A\n",
      "Epoch 8:  90%|████████▉ | 498/555 [03:31<00:24,  2.36it/s, loss=0.0948, v_num=4]\n",
      "Validating:  49%|████▉     | 55/112 [00:09<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 8:  90%|█████████ | 500/555 [03:31<00:23,  2.37it/s, loss=0.0948, v_num=4]\n",
      "Validating:  51%|█████     | 57/112 [00:09<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 8:  90%|█████████ | 502/555 [03:31<00:22,  2.37it/s, loss=0.0948, v_num=4]\n",
      "Validating:  53%|█████▎    | 59/112 [00:09<00:08,  5.95it/s]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 504/555 [03:32<00:21,  2.38it/s, loss=0.0948, v_num=4]\n",
      "Validating:  54%|█████▍    | 61/112 [00:10<00:08,  5.95it/s]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 506/555 [03:32<00:20,  2.38it/s, loss=0.0948, v_num=4]\n",
      "Validating:  56%|█████▋    | 63/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 508/555 [03:32<00:19,  2.39it/s, loss=0.0948, v_num=4]\n",
      "Validating:  58%|█████▊    | 65/112 [00:10<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 510/555 [03:33<00:18,  2.39it/s, loss=0.0948, v_num=4]\n",
      "Validating:  60%|█████▉    | 67/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 512/555 [03:33<00:17,  2.40it/s, loss=0.0948, v_num=4]\n",
      "Validating:  62%|██████▏   | 69/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 514/555 [03:33<00:17,  2.41it/s, loss=0.0948, v_num=4]\n",
      "Validating:  63%|██████▎   | 71/112 [00:11<00:06,  5.95it/s]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 516/555 [03:34<00:16,  2.41it/s, loss=0.0948, v_num=4]\n",
      "Validating:  65%|██████▌   | 73/112 [00:12<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 518/555 [03:34<00:15,  2.42it/s, loss=0.0948, v_num=4]\n",
      "Validating:  67%|██████▋   | 75/112 [00:12<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 8:  94%|█████████▎| 520/555 [03:34<00:14,  2.42it/s, loss=0.0948, v_num=4]\n",
      "Validating:  69%|██████▉   | 77/112 [00:12<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 8:  94%|█████████▍| 522/555 [03:35<00:13,  2.43it/s, loss=0.0948, v_num=4]\n",
      "Validating:  71%|███████   | 79/112 [00:13<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 8:  94%|█████████▍| 524/555 [03:35<00:12,  2.43it/s, loss=0.0948, v_num=4]\n",
      "Validating:  72%|███████▏  | 81/112 [00:13<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▍| 526/555 [03:35<00:11,  2.44it/s, loss=0.0948, v_num=4]\n",
      "Validating:  74%|███████▍  | 83/112 [00:13<00:04,  5.95it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 528/555 [03:36<00:11,  2.44it/s, loss=0.0948, v_num=4]\n",
      "Validating:  76%|███████▌  | 85/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 530/555 [03:36<00:10,  2.45it/s, loss=0.0948, v_num=4]\n",
      "Validating:  78%|███████▊  | 87/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 532/555 [03:36<00:09,  2.45it/s, loss=0.0948, v_num=4]\n",
      "Validating:  79%|███████▉  | 89/112 [00:14<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 534/555 [03:37<00:08,  2.46it/s, loss=0.0948, v_num=4]\n",
      "Validating:  81%|████████▏ | 91/112 [00:15<00:03,  5.95it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 536/555 [03:37<00:07,  2.47it/s, loss=0.0948, v_num=4]\n",
      "Validating:  83%|████████▎ | 93/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 538/555 [03:37<00:06,  2.47it/s, loss=0.0948, v_num=4]\n",
      "Validating:  85%|████████▍ | 95/112 [00:15<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 540/555 [03:38<00:06,  2.48it/s, loss=0.0948, v_num=4]\n",
      "Validating:  87%|████████▋ | 97/112 [00:16<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 542/555 [03:38<00:05,  2.48it/s, loss=0.0948, v_num=4]\n",
      "Validating:  88%|████████▊ | 99/112 [00:16<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 544/555 [03:38<00:04,  2.49it/s, loss=0.0948, v_num=4]\n",
      "Validating:  90%|█████████ | 101/112 [00:16<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 546/555 [03:39<00:03,  2.49it/s, loss=0.0948, v_num=4]\n",
      "Validating:  92%|█████████▏| 103/112 [00:17<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 548/555 [03:39<00:02,  2.50it/s, loss=0.0948, v_num=4]\n",
      "Validating:  94%|█████████▍| 105/112 [00:17<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 550/555 [03:39<00:01,  2.50it/s, loss=0.0948, v_num=4]\n",
      "Validating:  96%|█████████▌| 107/112 [00:17<00:00,  5.95it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 552/555 [03:40<00:01,  2.51it/s, loss=0.0948, v_num=4]\n",
      "Validating:  97%|█████████▋| 109/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 554/555 [03:40<00:00,  2.51it/s, loss=0.0948, v_num=4]\n",
      "Validating:  99%|█████████▉| 111/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 555/555 [03:40<00:00,  2.51it/s, loss=0.0948, v_num=4]\n",
      "Epoch 9:   0%|          | 0/555 [00:00<?, ?it/s, loss=0.0948, v_num=4]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  80%|████████  | 444/555 [03:21<00:50,  2.20it/s, loss=0.116, v_num=4] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating:   1%|          | 1/112 [00:00<00:12,  8.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9:  80%|████████  | 446/555 [03:22<00:49,  2.21it/s, loss=0.116, v_num=4]\n",
      "Validating:   3%|▎         | 3/112 [00:00<00:16,  6.42it/s]\u001b[A\n",
      "Epoch 9:  81%|████████  | 448/555 [03:22<00:48,  2.21it/s, loss=0.116, v_num=4]\n",
      "Validating:   4%|▍         | 5/112 [00:00<00:17,  6.12it/s]\u001b[A\n",
      "Epoch 9:  81%|████████  | 450/555 [03:22<00:47,  2.22it/s, loss=0.116, v_num=4]\n",
      "Validating:   6%|▋         | 7/112 [00:01<00:17,  6.00it/s]\u001b[A\n",
      "Epoch 9:  81%|████████▏ | 452/555 [03:23<00:46,  2.22it/s, loss=0.116, v_num=4]\n",
      "Validating:   8%|▊         | 9/112 [00:01<00:17,  5.98it/s]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 454/555 [03:23<00:45,  2.23it/s, loss=0.116, v_num=4]\n",
      "Validating:  10%|▉         | 11/112 [00:01<00:16,  5.96it/s]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 456/555 [03:23<00:44,  2.24it/s, loss=0.116, v_num=4]\n",
      "Validating:  12%|█▏        | 13/112 [00:02<00:16,  5.94it/s]\u001b[A\n",
      "Epoch 9:  83%|████████▎ | 458/555 [03:24<00:43,  2.24it/s, loss=0.116, v_num=4]\n",
      "Validating:  13%|█▎        | 15/112 [00:02<00:16,  5.94it/s]\u001b[A\n",
      "Epoch 9:  83%|████████▎ | 460/555 [03:24<00:42,  2.25it/s, loss=0.116, v_num=4]\n",
      "Validating:  15%|█▌        | 17/112 [00:02<00:15,  5.95it/s]\u001b[A\n",
      "Epoch 9:  83%|████████▎ | 462/555 [03:24<00:41,  2.25it/s, loss=0.116, v_num=4]\n",
      "Validating:  17%|█▋        | 19/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 9:  84%|████████▎ | 464/555 [03:25<00:40,  2.26it/s, loss=0.116, v_num=4]\n",
      "Validating:  19%|█▉        | 21/112 [00:03<00:15,  5.94it/s]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 466/555 [03:25<00:39,  2.27it/s, loss=0.116, v_num=4]\n",
      "Validating:  21%|██        | 23/112 [00:03<00:14,  5.95it/s]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 468/555 [03:25<00:38,  2.27it/s, loss=0.116, v_num=4]\n",
      "Validating:  22%|██▏       | 25/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 9:  85%|████████▍ | 470/555 [03:26<00:37,  2.28it/s, loss=0.116, v_num=4]\n",
      "Validating:  24%|██▍       | 27/112 [00:04<00:14,  5.94it/s]\u001b[A\n",
      "Epoch 9:  85%|████████▌ | 472/555 [03:26<00:36,  2.28it/s, loss=0.116, v_num=4]\n",
      "Validating:  26%|██▌       | 29/112 [00:04<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 9:  85%|████████▌ | 474/555 [03:26<00:35,  2.29it/s, loss=0.116, v_num=4]\n",
      "Validating:  28%|██▊       | 31/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 9:  86%|████████▌ | 476/555 [03:27<00:34,  2.30it/s, loss=0.116, v_num=4]\n",
      "Validating:  29%|██▉       | 33/112 [00:05<00:13,  5.94it/s]\u001b[A\n",
      "Epoch 9:  86%|████████▌ | 478/555 [03:27<00:33,  2.30it/s, loss=0.116, v_num=4]\n",
      "Validating:  31%|███▏      | 35/112 [00:05<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 9:  86%|████████▋ | 480/555 [03:27<00:32,  2.31it/s, loss=0.116, v_num=4]\n",
      "Validating:  33%|███▎      | 37/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 9:  87%|████████▋ | 482/555 [03:28<00:31,  2.31it/s, loss=0.116, v_num=4]\n",
      "Validating:  35%|███▍      | 39/112 [00:06<00:12,  5.94it/s]\u001b[A\n",
      "Epoch 9:  87%|████████▋ | 484/555 [03:28<00:30,  2.32it/s, loss=0.116, v_num=4]\n",
      "Validating:  37%|███▋      | 41/112 [00:06<00:11,  5.95it/s]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 486/555 [03:28<00:29,  2.33it/s, loss=0.116, v_num=4]\n",
      "Validating:  38%|███▊      | 43/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 488/555 [03:29<00:28,  2.33it/s, loss=0.116, v_num=4]\n",
      "Validating:  40%|████      | 45/112 [00:07<00:11,  5.94it/s]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 490/555 [03:29<00:27,  2.34it/s, loss=0.116, v_num=4]\n",
      "Validating:  42%|████▏     | 47/112 [00:07<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 9:  89%|████████▊ | 492/555 [03:29<00:26,  2.34it/s, loss=0.116, v_num=4]\n",
      "Validating:  44%|████▍     | 49/112 [00:08<00:10,  5.95it/s]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 494/555 [03:30<00:25,  2.35it/s, loss=0.116, v_num=4]\n",
      "Validating:  46%|████▌     | 51/112 [00:08<00:10,  5.94it/s]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 496/555 [03:30<00:25,  2.35it/s, loss=0.116, v_num=4]\n",
      "Validating:  47%|████▋     | 53/112 [00:08<00:09,  5.95it/s]\u001b[A\n",
      "Epoch 9:  90%|████████▉ | 498/555 [03:30<00:24,  2.36it/s, loss=0.116, v_num=4]\n",
      "Validating:  49%|████▉     | 55/112 [00:09<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 9:  90%|█████████ | 500/555 [03:31<00:23,  2.37it/s, loss=0.116, v_num=4]\n",
      "Validating:  51%|█████     | 57/112 [00:09<00:09,  5.94it/s]\u001b[A\n",
      "Epoch 9:  90%|█████████ | 502/555 [03:31<00:22,  2.37it/s, loss=0.116, v_num=4]\n",
      "Validating:  53%|█████▎    | 59/112 [00:09<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 504/555 [03:31<00:21,  2.38it/s, loss=0.116, v_num=4]\n",
      "Validating:  54%|█████▍    | 61/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 506/555 [03:32<00:20,  2.38it/s, loss=0.116, v_num=4]\n",
      "Validating:  56%|█████▋    | 63/112 [00:10<00:08,  5.94it/s]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 508/555 [03:32<00:19,  2.39it/s, loss=0.116, v_num=4]\n",
      "Validating:  58%|█████▊    | 65/112 [00:10<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 510/555 [03:33<00:18,  2.39it/s, loss=0.116, v_num=4]\n",
      "Validating:  60%|█████▉    | 67/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 512/555 [03:33<00:17,  2.40it/s, loss=0.116, v_num=4]\n",
      "Validating:  62%|██████▏   | 69/112 [00:11<00:07,  5.94it/s]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 514/555 [03:33<00:17,  2.41it/s, loss=0.116, v_num=4]\n",
      "Validating:  63%|██████▎   | 71/112 [00:11<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 516/555 [03:34<00:16,  2.41it/s, loss=0.116, v_num=4]\n",
      "Validating:  65%|██████▌   | 73/112 [00:12<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 518/555 [03:34<00:15,  2.42it/s, loss=0.116, v_num=4]\n",
      "Validating:  67%|██████▋   | 75/112 [00:12<00:06,  5.94it/s]\u001b[A\n",
      "Epoch 9:  94%|█████████▎| 520/555 [03:34<00:14,  2.42it/s, loss=0.116, v_num=4]\n",
      "Validating:  69%|██████▉   | 77/112 [00:12<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 9:  94%|█████████▍| 522/555 [03:35<00:13,  2.43it/s, loss=0.116, v_num=4]\n",
      "Validating:  71%|███████   | 79/112 [00:13<00:05,  5.95it/s]\u001b[A\n",
      "Epoch 9:  94%|█████████▍| 524/555 [03:35<00:12,  2.43it/s, loss=0.116, v_num=4]\n",
      "Validating:  72%|███████▏  | 81/112 [00:13<00:05,  5.94it/s]\u001b[A\n",
      "Epoch 9:  95%|█████████▍| 526/555 [03:35<00:11,  2.44it/s, loss=0.116, v_num=4]\n",
      "Validating:  74%|███████▍  | 83/112 [00:13<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 9:  95%|█████████▌| 528/555 [03:36<00:11,  2.44it/s, loss=0.116, v_num=4]\n",
      "Validating:  76%|███████▌  | 85/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 9:  95%|█████████▌| 530/555 [03:36<00:10,  2.45it/s, loss=0.116, v_num=4]\n",
      "Validating:  78%|███████▊  | 87/112 [00:14<00:04,  5.94it/s]\u001b[A\n",
      "Epoch 9:  96%|█████████▌| 532/555 [03:36<00:09,  2.45it/s, loss=0.116, v_num=4]\n",
      "Validating:  79%|███████▉  | 89/112 [00:14<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 9:  96%|█████████▌| 534/555 [03:37<00:08,  2.46it/s, loss=0.116, v_num=4]\n",
      "Validating:  81%|████████▏ | 91/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 536/555 [03:37<00:07,  2.47it/s, loss=0.116, v_num=4]\n",
      "Validating:  83%|████████▎ | 93/112 [00:15<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 538/555 [03:37<00:06,  2.47it/s, loss=0.116, v_num=4]\n",
      "Validating:  85%|████████▍ | 95/112 [00:15<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 540/555 [03:38<00:06,  2.48it/s, loss=0.116, v_num=4]\n",
      "Validating:  87%|████████▋ | 97/112 [00:16<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 542/555 [03:38<00:05,  2.48it/s, loss=0.116, v_num=4]\n",
      "Validating:  88%|████████▊ | 99/112 [00:16<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 544/555 [03:38<00:04,  2.49it/s, loss=0.116, v_num=4]\n",
      "Validating:  90%|█████████ | 101/112 [00:16<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 546/555 [03:39<00:03,  2.49it/s, loss=0.116, v_num=4]\n",
      "Validating:  92%|█████████▏| 103/112 [00:17<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 548/555 [03:39<00:02,  2.50it/s, loss=0.116, v_num=4]\n",
      "Validating:  94%|█████████▍| 105/112 [00:17<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 550/555 [03:39<00:01,  2.50it/s, loss=0.116, v_num=4]\n",
      "Validating:  96%|█████████▌| 107/112 [00:17<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 552/555 [03:40<00:01,  2.51it/s, loss=0.116, v_num=4]\n",
      "Validating:  97%|█████████▋| 109/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 554/555 [03:40<00:00,  2.51it/s, loss=0.116, v_num=4]\n",
      "Validating:  99%|█████████▉| 111/112 [00:18<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 555/555 [03:40<00:00,  2.51it/s, loss=0.116, v_num=4]\n",
      "Epoch 9: 100%|██████████| 555/555 [03:44<00:00,  2.47it/s, loss=0.116, v_num=4]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T15:15:30.833864Z",
     "iopub.status.busy": "2024-02-28T15:15:30.833522Z",
     "iopub.status.idle": "2024-02-28T15:15:37.034017Z",
     "shell.execute_reply": "2024-02-28T15:15:37.033415Z",
     "shell.execute_reply.started": "2024-02-28T15:15:30.833841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.load_from_checkpoint(\"/mnt/workspace/ORL/lightning_logs/version_4/checkpoints/epoch=9-step=279.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:15:39.989894Z",
     "iopub.status.busy": "2024-02-28T15:15:39.989324Z",
     "iopub.status.idle": "2024-02-28T15:15:53.553095Z",
     "shell.execute_reply": "2024-02-28T15:15:53.552563Z",
     "shell.execute_reply.started": "2024-02-28T15:15:39.989874Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: concerning the delimitation of the border between kazakhstan and russia , nazarbayev said that\n",
      "this process is continuing without any disagreements and with mutual respect for each other 's\n",
      "interests , and that documents on the final delimitation are likely to be signed next year .\n",
      "dse:disagreements\n",
      "\n",
      "Actual Entities: agent: kazakhstan and russia\n",
      "Predicted Entities: \n",
      "=====================================================================\n",
      "\n",
      "text: besides that , ever since the detainees started arriving on january 11 , gitmo and the joint\n",
      "forces being run under southern command have experienced the pr equivalent of what my ever-subtle\n",
      "colleagues -- borrowing from special forces terminology for disastrous missions -- call a  goat f --\n",
      ". '' dse:call\n",
      "\n",
      "Actual Entities: target: ever since the detainees started arriving on january 11 , gitmo and the joint forces being run under southern command; agent: my ever-subtle colleagues\n",
      "Predicted Entities: target: ever since the detainees started arriving on january 11 ,\n",
      "=====================================================================\n",
      "\n",
      "text: we are concerned about the events , '' white house spokesman ari fleischer told reporters at a\n",
      "regular news briefing . dse:are concerned\n",
      "\n",
      "Actual Entities: agent: we; target: the events\n",
      "Predicted Entities: agent: we; target: the events\n",
      "=====================================================================\n",
      "\n",
      "text: with its decision to ratify the protocol at eu level , the european union stays true to its\n",
      "ambition to enable the kyoto protocol to come into force by the world summit on sustainable\n",
      "development in august 2002 . dse:ambition\n",
      "\n",
      "Actual Entities: agent: its; target: enable the kyoto protocol to come into force by the world summit on sustainable development in august 2002\n",
      "Predicted Entities: agent: its; target: enable the kyoto protocol to come into force by the\n",
      "=====================================================================\n",
      "\n",
      "text: the speaker 's ardor was cooled by the well-known sergey kapitsa , who is not inclined to give\n",
      "way to rapture over the advantages promised to russia . dse:not inclined to give way to rapture\n",
      "\n",
      "Actual Entities: agent: sergey kapitsa\n",
      "Predicted Entities: agent: sergey kapitsa\n",
      "=====================================================================\n",
      "\n",
      "text: his second was to announce the end of the three-day general strike he had called with the head\n",
      "of the confederation of venezuelan workers -lrb- ctv -rrb- leader carlos ortega in support of\n",
      "protesting managers from state oil company pdvsa . dse:in support of\n",
      "\n",
      "Actual Entities: agent: he; target: protesting managers from state oil company pdvsa\n",
      "Predicted Entities: agent: he; target: protesting managers from state oil company pdvs\n",
      "=====================================================================\n",
      "\n",
      "text: but the rich russian fields that stretch across the arctic zone are small comfort to humankind\n",
      "as a whole , so gudkov proposes blocking off the sun with an umbrella that would be suspended in\n",
      "space . dse:small comfort to\n",
      "\n",
      "Actual Entities: target: the rich russian fields that stretch across the arctic zone; agent: humankind as a whole\n",
      "Predicted Entities: target: the rich russian fields that stretch across the arctic zone; agent:\n",
      "=====================================================================\n",
      "\n",
      "text: the ingredients for a decision are in large measure in place if they would only be admitted by\n",
      "the two sides . dse:admitted\n",
      "\n",
      "Actual Entities: target: the ingredients for a decision; agent: the two sides\n",
      "Predicted Entities: target: the ingredients for a decision; agent: the two sides\n",
      "=====================================================================\n",
      "\n",
      "text: addressing the meeting , denktas said that this week is  martryrs week ,  adding that  it is\n",
      "the 38th anniversary of the struggle started to annihilate turks in cyprus ... we fought for half of\n",
      "our lives to prevent the occupation of cyprus from greece and not to make the island a greek dagger\n",
      "that is thrust into the heart of anatolia . dse:adding\n",
      "\n",
      "Actual Entities: agent: denktas; target: greece\n",
      "Predicted Entities: agent: denktas; target: it; target: the struggle started to anni\n",
      "=====================================================================\n",
      "\n",
      "text: scholars speculate that shalim might have been an ancient semitic deity of peace , for the\n",
      "name resembles the modern hebrew and arabic words for  peace '' : shalom and salaam , respectively .\n",
      "dse:speculate\n",
      "\n",
      "Actual Entities: agent: scholars; target: an ancient semitic deity of peace\n",
      "Predicted Entities: agent: scholars; target: shalim\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "dataloader = DataLoader(input_dataset, batch_size=32, num_workers=2, shuffle=True)\n",
    "model.model.eval()\n",
    "model = model.to(\"cpu\")\n",
    "outputs = []\n",
    "targets = []\n",
    "texts = []\n",
    "for batch in dataloader:\n",
    "\n",
    "    outs = model.model.generate(input_ids=batch['source_ids'],\n",
    "                                attention_mask=batch['source_mask'])\n",
    "    dec = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip() for ids in outs]\n",
    "    target = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"target_ids\"]]\n",
    "    text = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"source_ids\"]]\n",
    "    texts.extend(text)\n",
    "    outputs.extend(dec)\n",
    "    targets.extend(target)\n",
    "    break\n",
    "\n",
    "for i in range(10):\n",
    "    c = texts[i]\n",
    "    lines = textwrap.wrap(\"text:\\n%s\\n\" % c, width=100)\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nActual Entities: %s\" % target[i])\n",
    "    print(\"Predicted Entities: %s\" % outputs[i])\n",
    "    print(\"=====================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:16:17.579251Z",
     "iopub.status.busy": "2024-02-28T15:16:17.578902Z",
     "iopub.status.idle": "2024-02-28T15:16:17.585178Z",
     "shell.execute_reply": "2024-02-28T15:16:17.584743Z",
     "shell.execute_reply.started": "2024-02-28T15:16:17.579228Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_sub_list(sl, l):\n",
    "    results = []\n",
    "    sll = len(sl)\n",
    "    for ind in (i for i, e in enumerate(l) if e == sl[0]):\n",
    "        if l[ind:ind+sll] == sl:\n",
    "            results.append((ind, ind+sll-1))\n",
    "    return results\n",
    "\n",
    "def generate_label(input: str, target: str):\n",
    "    mapper = {\n",
    "        \"O\": 0,\n",
    "        \"B-AGENT\": 1,\n",
    "        \"I-AGENT\": 2,\n",
    "        \"B-DSE\": 3,\n",
    "        \"I-DSE\": 4,\n",
    "        \"B-TARGET\": 5,\n",
    "        \"I-TARGET\": 6\n",
    "    }\n",
    "    inv_mapper = {v: k for k, v in mapper.items()}\n",
    "\n",
    "    input = input.split(\" \")\n",
    "    target = target.split(\"; \")\n",
    "\n",
    "    init_target_label = [mapper['O']]*len(input)\n",
    "\n",
    "    for ent in target:\n",
    "        ent = ent.split(\": \")\n",
    "        try:\n",
    "            sent_end = ent[1].split(\" \")\n",
    "            index = find_sub_list(sent_end, input)\n",
    "        except:\n",
    "            continue\n",
    "        # print(index)\n",
    "        try:\n",
    "            init_target_label[index[0][0]] = mapper[f\"B-{ent[0].upper()}\"]\n",
    "            for i in range(index[0][0]+1, index[0][1]+1):\n",
    "                init_target_label[i] = mapper[f\"I-{ent[0].upper()}\"]\n",
    "        except:\n",
    "            continue\n",
    "    init_target_label = [inv_mapper[j] for j in init_target_label]\n",
    "    return init_target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:16:22.561581Z",
     "iopub.status.busy": "2024-02-28T15:16:22.560990Z",
     "iopub.status.idle": "2024-02-28T15:16:57.335332Z",
     "shell.execute_reply": "2024-02-28T15:16:57.334689Z",
     "shell.execute_reply.started": "2024-02-28T15:16:22.561561Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 48/48 [00:33<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "test_dataset = MPQADataset(tokenizer=tokenizer, dataset=dataset, type_path='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=32,\n",
    "                             num_workers=2, shuffle=True)\n",
    "model.model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "outputs = []\n",
    "targets = []\n",
    "all_text = []\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "for batch in tqdm(test_loader):\n",
    "    input_ids = batch['source_ids'].to(\"cuda\")\n",
    "    attention_mask = batch['source_mask'].to(\"cuda\")\n",
    "    outs = model.model.generate(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "    dec = [tokenizer.decode(ids, skip_special_tokens=True,\n",
    "                            clean_up_tokenization_spaces=False).strip() for ids in outs]\n",
    "    target = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"target_ids\"]]\n",
    "    texts = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"source_ids\"]]\n",
    "    true_label = [generate_label(texts[i].strip(), target[i].strip()) if target[i].strip() != 'none' else [\n",
    "        \"O\"]*len(texts[i].strip().split()) for i in range(len(texts))]\n",
    "    pred_label = [generate_label(texts[i].strip(), dec[i].strip()) if dec[i].strip() != 'none' else [\n",
    "        \"O\"]*len(texts[i].strip().split()) for i in range(len(texts))]\n",
    "\n",
    "    outputs.extend(dec)\n",
    "    targets.extend(target)\n",
    "    true_labels.extend(true_label)\n",
    "    pred_labels.extend(pred_label)\n",
    "    all_text.extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:17:33.521899Z",
     "iopub.status.busy": "2024-02-28T15:17:33.521562Z",
     "iopub.status.idle": "2024-02-28T15:17:35.880177Z",
     "shell.execute_reply": "2024-02-28T15:17:35.879656Z",
     "shell.execute_reply.started": "2024-02-28T15:17:33.521876Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_341/1300780915.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/datasets/load.py:753: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.1/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  and the people who are here are going to voice their concerns and voice their demands . dse:and\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  the numbers are expected to increase as more journalists were accredited yesterday . dse:are expected\n",
      "Predicted Token Class:  ['B-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['B-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  the top us official handling taiwan affairs , richard bush -- no relation of the president -- also moved to ease taipei 's concerns during his visit to the island last month . dse:concerns\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  when asked whether the anti-terror alliance meant good relations between the country were based purely on expediency , tang disagreed , saying cooperation  was long-term '' . dse:asked\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  answer : the venezuelan experience during the past few days showed that regimes that are based on the votes and support of the masses and adopt relatively independent policies toward the big powers and especially america are not favored by the american leadership . dse:answer :\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'I-AGENT', 'I-AGENT', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  it is thus an illusion for these criminal administrations to imagine that they have triumphed and that they are now in a position to dictate their own conditions on this great people . dse:to dictate\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'I-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  the formerly close allies fell out in 1999 , the year after each sent troops to back rebel movements in the neighbouring democratic republic of congo , when mounting rivalry lead to violent clashes between their own armies there . dse:fell out\n",
      "Predicted Token Class:  ['B-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['B-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  overall , despite a  grim and complicated '' post september 11 international order , china still maintained that  peace , stability and development '' remained the main themes characterizing the world environment , tang said . dse:still maintained\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  the ! korean government is of the view that in order for the u.s. initiative to be discussed in more detail in future international fora , greater elaboration is needed , including concrete methods to establish the levels of greenhouse gas intensity , it continued . dse:is of the view\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'B-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  i have no doubt that , if given the opportunity , any of the detainees would have relished the chance to kill me . dse:would have relished\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-AGENT', 'I-AGENT', 'I-AGENT', 'I-AGENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'I-TARGET', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "{'AGENT': {'precision': 0.7463054187192119, 'recall': 0.7625838926174496, 'f1': 0.754356846473029, 'number': 1192}, 'TARGET': {'precision': 0.5105820105820106, 'recall': 0.4613545816733068, 'f1': 0.4847216408539138, 'number': 1255}, 'overall_precision': 0.6326530612244898, 'overall_recall': 0.6080915406620352, 'overall_f1': 0.6201291935819964, 'overall_accuracy': 0.8762390257717361}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Text:  {all_text[i]}\")\n",
    "    print(f\"Predicted Token Class:  {pred_labels[i]}\")\n",
    "    print(f\"True Token Class:  {true_labels[i]}\")\n",
    "    print(\"=====================================================================\\n\")\n",
    "\n",
    "print(metric.compute(predictions=pred_labels, references=true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8h8R2bLDhjlc"
   },
   "source": [
    "# Model\n",
    "\n",
    "Majority of the code here is adapted from [here](https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb) which uses the pytorch-lightning framework for training neural networks. T5 has shown that it can generate state of the art on many tasks as long as it can be cast as a text-to-text problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:24:59.853431Z",
     "iopub.status.busy": "2024-02-27T12:24:59.853050Z",
     "iopub.status.idle": "2024-02-27T12:24:59.864657Z",
     "shell.execute_reply": "2024-02-27T12:24:59.863958Z",
     "shell.execute_reply.started": "2024-02-27T12:24:59.853410Z"
    },
    "id": "KL8_p4YS6H0a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "    def __init__(self, hparam):\n",
    "        super(T5FineTuner, self).__init__()\n",
    "        self.hparam = hparam\n",
    "\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "            hparam.model_name_or_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            hparam.model_name_or_path\n",
    "        )\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def is_logger(self):\n",
    "        return True\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
    "    ):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=lm_labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            lm_labels=lm_labels,\n",
    "            decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        tensorboard_logs = {\"train_loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparam.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.hparam.learning_rate, eps=self.hparam.adam_epsilon)\n",
    "        self.opt = optimizer\n",
    "        return [optimizer]\n",
    "\n",
    "    def optimizer_step(self,\n",
    "                       epoch=None,\n",
    "                       batch_idx=None,\n",
    "                       optimizer=None,\n",
    "                       optimizer_idx=None,\n",
    "                       optimizer_closure=None,\n",
    "                       on_tpu=None,\n",
    "                       using_native_amp=None,\n",
    "                       using_lbfgs=None\n",
    "                       ):\n",
    "\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "        optimizer.zero_grad()\n",
    "        self.lr_scheduler.step()\n",
    "\n",
    "    def get_tqdm_dict(self):\n",
    "        tqdm_dict = {\"loss\": \"{:.3f}\".format(\n",
    "            self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "\n",
    "        return tqdm_dict\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = get_dataset(\n",
    "            tokenizer=self.tokenizer, type_path=\"train\", args=self.hparam)\n",
    "        dataloader = DataLoader(train_dataset, batch_size=self.hparam.train_batch_size,\n",
    "                                drop_last=True, shuffle=True, num_workers=2)\n",
    "        t_total = (\n",
    "            (len(dataloader.dataset) //\n",
    "             (self.hparam.train_batch_size * max(1, self.hparam.n_gpu)))\n",
    "            // self.hparam.gradient_accumulation_steps\n",
    "            * float(self.hparam.num_train_epochs)\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.opt, num_warmup_steps=self.hparam.warmup_steps, num_training_steps=t_total\n",
    "        )\n",
    "        self.lr_scheduler = scheduler\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = get_dataset(\n",
    "            tokenizer=self.tokenizer, type_path=\"validation\", args=self.hparam)\n",
    "        return DataLoader(val_dataset, batch_size=self.hparam.eval_batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:01.768401Z",
     "iopub.status.busy": "2024-02-27T12:25:01.767846Z",
     "iopub.status.idle": "2024-02-27T12:25:01.773286Z",
     "shell.execute_reply": "2024-02-27T12:25:01.772660Z",
     "shell.execute_reply.started": "2024-02-27T12:25:01.768381Z"
    },
    "id": "6VQpUMNe6Wf8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LoggingCallback(pl.Callback):\n",
    "  def on_validation_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Validation results *****\")\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "      # Log results\n",
    "      for key in sorted(metrics):\n",
    "        if key not in [\"log\", \"progress_bar\"]:\n",
    "          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "  def on_test_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Test results *****\")\n",
    "\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "\n",
    "      # Log and save results to file\n",
    "      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
    "      with open(output_test_results_file, \"w\") as writer:\n",
    "        for key in sorted(metrics):\n",
    "          if key not in [\"log\", \"progress_bar\"]:\n",
    "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:02.692693Z",
     "iopub.status.busy": "2024-02-27T12:25:02.692356Z",
     "iopub.status.idle": "2024-02-27T12:25:02.697059Z",
     "shell.execute_reply": "2024-02-27T12:25:02.696544Z",
     "shell.execute_reply.started": "2024-02-27T12:25:02.692672Z"
    },
    "id": "I55QMghp6YbE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args_dict = dict(\n",
    "    data_dir=\"wikiann\", # path for data files\n",
    "    output_dir=\"\", # path to save the checkpoints\n",
    "    model_name_or_path='t5-small',\n",
    "    tokenizer_name_or_path='t5-small',\n",
    "    max_seq_length=256,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    gradient_accumulation_steps=16,\n",
    "    n_gpu=1,\n",
    "    early_stop_callback=False,\n",
    "    fp_16=True, # if you want to enable 16-bit training then install apex and set this to true\n",
    "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
    "    max_grad_norm=1, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxV5l0Wcinfb"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "Here, I used the popular [WikiANN](https://https://huggingface.co/datasets/wikiann) dataset which is a multilingual named entity recognition dataset consisting of Wikipedia articles annotated with LOC (location), PER (person), and ORG (organisation) tags in the IOB2 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "b112c9a8184d4b479fc0e59698789b43",
      "e550224ab580420cb4973b805c2393af",
      "ebcc288979ff4cd5901e9223063751d1",
      "304c605d63584a298e8cefd4ffcf4ead",
      "7ca93c1fe9a9415e9c7d6f22a58b90d1",
      "56496f0e8cef4b5cb989f289af418f9f",
      "388d8e1e34a143c3afe9e4082be44ebb",
      "5d88a23982ac46b3b8077264a6998b9a",
      "dfdd904fb4924ad8948793222255cc3b",
      "43278de125c54c1e8b55baa0370c4cc1",
      "fa0489927bdd4bf4809c9fcc92d9d7b4"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:09.149655Z",
     "iopub.status.busy": "2024-02-27T12:25:09.149329Z",
     "iopub.status.idle": "2024-02-27T12:25:26.708433Z",
     "shell.execute_reply": "2024-02-27T12:25:26.707926Z",
     "shell.execute_reply.started": "2024-02-27T12:25:09.149635Z"
    },
    "id": "soCZS7n07Ts1",
    "outputId": "6e0d1772-838a-414e-b028-e6362faeb653",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikiann\", \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:26.709771Z",
     "iopub.status.busy": "2024-02-27T12:25:26.709381Z",
     "iopub.status.idle": "2024-02-27T12:25:26.713447Z",
     "shell.execute_reply": "2024-02-27T12:25:26.712901Z",
     "shell.execute_reply.started": "2024-02-27T12:25:26.709753Z"
    },
    "id": "7eSAir8g80rm",
    "outputId": "aaf53c53-939a-424a-e625-9ba8059fee67",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 20000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:26.714288Z",
     "iopub.status.busy": "2024-02-27T12:25:26.713990Z",
     "iopub.status.idle": "2024-02-27T12:25:26.720368Z",
     "shell.execute_reply": "2024-02-27T12:25:26.719900Z",
     "shell.execute_reply.started": "2024-02-27T12:25:26.714273Z"
    },
    "id": "cWCXP8F373Nm",
    "outputId": "bc803c3d-6947-4c16-eb68-0fde40b8289c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R.H. Saunders ( St. Lawrence River ) ( 968 MW )'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(dataset['train'][0]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:26.721462Z",
     "iopub.status.busy": "2024-02-27T12:25:26.721156Z",
     "iopub.status.idle": "2024-02-27T12:25:26.725372Z",
     "shell.execute_reply": "2024-02-27T12:25:26.724914Z",
     "shell.execute_reply.started": "2024-02-27T12:25:26.721445Z"
    },
    "id": "rXjs7Khn9oi6",
    "outputId": "c96fa06e-f32d-4cad-bd85-513ffde91282",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['R.H.',\n",
       "  'Saunders',\n",
       "  '(',\n",
       "  'St.',\n",
       "  'Lawrence',\n",
       "  'River',\n",
       "  ')',\n",
       "  '(',\n",
       "  '968',\n",
       "  'MW',\n",
       "  ')'],\n",
       " 'ner_tags': [3, 4, 0, 3, 4, 4, 0, 0, 0, 0, 0],\n",
       " 'langs': ['en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en'],\n",
       " 'spans': ['ORG: R.H. Saunders', 'ORG: St. Lawrence River']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5KDQPACi8FT"
   },
   "source": [
    "In this section, we create a custom dataset class where we cast the NER task as a text to text problem. This is done by concatenating the spans in the data as one line of string separated by a semi-colon (;). e.g\n",
    "\n",
    "*   **Input**: R.H. Saunders ( St. Lawrence River ) ( 968 MW )\n",
    "*   **Target**: ORG: R.H. Saunders; ORG: St. Lawrence River\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:28.595917Z",
     "iopub.status.busy": "2024-02-27T12:25:28.595563Z",
     "iopub.status.idle": "2024-02-27T12:25:28.602276Z",
     "shell.execute_reply": "2024-02-27T12:25:28.601623Z",
     "shell.execute_reply.started": "2024-02-27T12:25:28.595896Z"
    },
    "id": "LgZKb7T48Mzw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WikiAnnDataset(Dataset):\n",
    "  def __init__(self, tokenizer, dataset, type_path, max_len=512):\n",
    "\n",
    "    self.data = dataset[type_path]\n",
    "    self.max_len = max_len\n",
    "    self.tokenizer = tokenizer\n",
    "    self.tokenizer.max_length = max_len\n",
    "    self.tokenizer.model_max_length = max_len\n",
    "    self.inputs = []\n",
    "    self.targets = []\n",
    "\n",
    "    self._build()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.inputs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
    "    target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
    "\n",
    "    src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "    target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "\n",
    "    return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "\n",
    "  def _build(self):\n",
    "    for idx in range(len(self.data)):\n",
    "      input_, target = \" \".join(self.data[idx][\"tokens\"]), \"; \".join(self.data[idx][\"spans\"])\n",
    "\n",
    "      input_ = input_.lower() + ' </s>'\n",
    "      target = target.lower() + \" </s>\"\n",
    "\n",
    "       # tokenize inputs\n",
    "      tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
    "          [input_], max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "      )\n",
    "       # tokenize targets\n",
    "      tokenized_targets = self.tokenizer.batch_encode_plus(\n",
    "          [target],max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "      )\n",
    "\n",
    "      self.inputs.append(tokenized_inputs)\n",
    "      self.targets.append(tokenized_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:33.140341Z",
     "iopub.status.busy": "2024-02-27T12:25:33.140007Z",
     "iopub.status.idle": "2024-02-27T12:25:42.716000Z",
     "shell.execute_reply": "2024-02-27T12:25:42.715500Z",
     "shell.execute_reply.started": "2024-02-27T12:25:33.140323Z"
    },
    "id": "XrlJEayI-4tS",
    "outputId": "97284917-3b24-462e-fd2c-930f0061f79f",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5TokenizerFast(name_or_path='../T5-base', vocab_size=32100, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32000: AddedToken(\"<extra_id_99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32001: AddedToken(\"<extra_id_98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32002: AddedToken(\"<extra_id_97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32003: AddedToken(\"<extra_id_96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32004: AddedToken(\"<extra_id_95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32005: AddedToken(\"<extra_id_94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32006: AddedToken(\"<extra_id_93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32007: AddedToken(\"<extra_id_92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32008: AddedToken(\"<extra_id_91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32009: AddedToken(\"<extra_id_90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32010: AddedToken(\"<extra_id_89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32011: AddedToken(\"<extra_id_88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32012: AddedToken(\"<extra_id_87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32013: AddedToken(\"<extra_id_86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32014: AddedToken(\"<extra_id_85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32015: AddedToken(\"<extra_id_84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32016: AddedToken(\"<extra_id_83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32017: AddedToken(\"<extra_id_82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32018: AddedToken(\"<extra_id_81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32019: AddedToken(\"<extra_id_80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32020: AddedToken(\"<extra_id_79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32021: AddedToken(\"<extra_id_78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32022: AddedToken(\"<extra_id_77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32023: AddedToken(\"<extra_id_76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32024: AddedToken(\"<extra_id_75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32025: AddedToken(\"<extra_id_74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32026: AddedToken(\"<extra_id_73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32027: AddedToken(\"<extra_id_72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32028: AddedToken(\"<extra_id_71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32029: AddedToken(\"<extra_id_70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32030: AddedToken(\"<extra_id_69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32031: AddedToken(\"<extra_id_68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32032: AddedToken(\"<extra_id_67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32033: AddedToken(\"<extra_id_66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32034: AddedToken(\"<extra_id_65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32035: AddedToken(\"<extra_id_64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32036: AddedToken(\"<extra_id_63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32037: AddedToken(\"<extra_id_62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32038: AddedToken(\"<extra_id_61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32039: AddedToken(\"<extra_id_60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32040: AddedToken(\"<extra_id_59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32041: AddedToken(\"<extra_id_58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32042: AddedToken(\"<extra_id_57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32043: AddedToken(\"<extra_id_56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32044: AddedToken(\"<extra_id_55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32045: AddedToken(\"<extra_id_54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32046: AddedToken(\"<extra_id_53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32047: AddedToken(\"<extra_id_52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32048: AddedToken(\"<extra_id_51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32049: AddedToken(\"<extra_id_50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32050: AddedToken(\"<extra_id_49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32051: AddedToken(\"<extra_id_48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32052: AddedToken(\"<extra_id_47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32053: AddedToken(\"<extra_id_46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32054: AddedToken(\"<extra_id_45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32055: AddedToken(\"<extra_id_44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32056: AddedToken(\"<extra_id_43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32057: AddedToken(\"<extra_id_42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32058: AddedToken(\"<extra_id_41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32059: AddedToken(\"<extra_id_40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32060: AddedToken(\"<extra_id_39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32061: AddedToken(\"<extra_id_38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32062: AddedToken(\"<extra_id_37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32063: AddedToken(\"<extra_id_36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32064: AddedToken(\"<extra_id_35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32065: AddedToken(\"<extra_id_34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32066: AddedToken(\"<extra_id_33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32067: AddedToken(\"<extra_id_32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32068: AddedToken(\"<extra_id_31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32069: AddedToken(\"<extra_id_30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32070: AddedToken(\"<extra_id_29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32071: AddedToken(\"<extra_id_28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32072: AddedToken(\"<extra_id_27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32073: AddedToken(\"<extra_id_26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32074: AddedToken(\"<extra_id_25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32075: AddedToken(\"<extra_id_24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32076: AddedToken(\"<extra_id_23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32077: AddedToken(\"<extra_id_22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32078: AddedToken(\"<extra_id_21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32079: AddedToken(\"<extra_id_20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32080: AddedToken(\"<extra_id_19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32081: AddedToken(\"<extra_id_18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32082: AddedToken(\"<extra_id_17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32083: AddedToken(\"<extra_id_16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32084: AddedToken(\"<extra_id_15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32085: AddedToken(\"<extra_id_14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32086: AddedToken(\"<extra_id_13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32087: AddedToken(\"<extra_id_12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32088: AddedToken(\"<extra_id_11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32089: AddedToken(\"<extra_id_10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32090: AddedToken(\"<extra_id_9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32091: AddedToken(\"<extra_id_8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32092: AddedToken(\"<extra_id_7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32093: AddedToken(\"<extra_id_6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32094: AddedToken(\"<extra_id_5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32095: AddedToken(\"<extra_id_4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32096: AddedToken(\"<extra_id_3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32097: AddedToken(\"<extra_id_2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32098: AddedToken(\"<extra_id_1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32099: AddedToken(\"<extra_id_0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../T5-base\")\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "input_dataset = WikiAnnDataset(tokenizer=tokenizer, dataset=dataset, type_path='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:42.717524Z",
     "iopub.status.busy": "2024-02-27T12:25:42.717015Z",
     "iopub.status.idle": "2024-02-27T12:25:42.871971Z",
     "shell.execute_reply": "2024-02-27T12:25:42.871475Z",
     "shell.execute_reply.started": "2024-02-27T12:25:42.717506Z"
    },
    "id": "Cyrnvv1zTKaw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(input_dataset)):\n",
    "    _ = input_dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:42.873108Z",
     "iopub.status.busy": "2024-02-27T12:25:42.872825Z",
     "iopub.status.idle": "2024-02-27T12:25:42.876923Z",
     "shell.execute_reply": "2024-02-27T12:25:42.876466Z",
     "shell.execute_reply.started": "2024-02-27T12:25:42.873090Z"
    },
    "id": "OJ02SXgv_UW8",
    "outputId": "5c541c8e-9376-47ed-bc9f-7e138caee0e7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r.h. saunders ( st. lawrence river ) ( 968 mw )</s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "org: r.h. saunders; org: st. lawrence river</s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "data = input_dataset[0]\n",
    "\n",
    "print(tokenizer.decode(data[\"source_ids\"], skip_special_tokens=False))\n",
    "print(tokenizer.decode(data[\"target_ids\"], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:43.437406Z",
     "iopub.status.busy": "2024-02-27T12:25:43.437088Z",
     "iopub.status.idle": "2024-02-27T12:25:43.685932Z",
     "shell.execute_reply": "2024-02-27T12:25:43.685362Z",
     "shell.execute_reply.started": "2024-02-27T12:25:43.437387Z"
    },
    "id": "Sepl17_eCHy4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p t5_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:53.021540Z",
     "iopub.status.busy": "2024-02-27T12:25:53.021188Z",
     "iopub.status.idle": "2024-02-27T12:25:54.752236Z",
     "shell.execute_reply": "2024-02-27T12:25:54.751686Z",
     "shell.execute_reply.started": "2024-02-27T12:25:53.021519Z"
    },
    "id": "4Toa_qnXDrTw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace(**args_dict)\n",
    "model = T5FineTuner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:25:57.604520Z",
     "iopub.status.busy": "2024-02-27T12:25:57.604156Z",
     "iopub.status.idle": "2024-02-27T12:25:57.608734Z",
     "shell.execute_reply": "2024-02-27T12:25:57.608252Z",
     "shell.execute_reply.started": "2024-02-27T12:25:57.604493Z"
    },
    "id": "dIZ3LwE3DXNo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    filename=args.output_dir+\"/checkpoint.pth\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    #early_stop_callback=False,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    #amp_level=args.opt_level,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    callbacks=[LoggingCallback()],\n",
    ")\n",
    "\n",
    "# train_params = dict(\n",
    "#     accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "#     ## gpus=args.n_gpu,\n",
    "#     max_epochs=args.num_train_epochs,\n",
    "#     #early_stop_callback=False,\n",
    "#     precision= 16 if args.fp_16 else 32,\n",
    "#     #amp_level=args.opt_level,\n",
    "#     gradient_clip_val=args.max_grad_norm,\n",
    "#     # callbacks=[LoggingCallback()],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T12:26:01.158877Z",
     "iopub.status.busy": "2024-02-27T12:26:01.158529Z",
     "iopub.status.idle": "2024-02-27T12:26:01.162217Z",
     "shell.execute_reply": "2024-02-27T12:26:01.161716Z",
     "shell.execute_reply.started": "2024-02-27T12:26:01.158856Z"
    },
    "id": "MxBEgT6MDqe3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset(tokenizer, type_path, args):\n",
    "    tokenizer.max_length = args.max_seq_length\n",
    "    tokenizer.model_max_length = args.max_seq_length\n",
    "    dataset = load_dataset(args.data_dir, \"en\")\n",
    "    return WikiAnnDataset(tokenizer=tokenizer, dataset=dataset, type_path=type_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:26:01.731175Z",
     "iopub.status.busy": "2024-02-27T12:26:01.730847Z",
     "iopub.status.idle": "2024-02-27T12:26:01.738097Z",
     "shell.execute_reply": "2024-02-27T12:26:01.737626Z",
     "shell.execute_reply.started": "2024-02-27T12:26:01.731149Z"
    },
    "id": "KCKmlJ5DDaHw",
    "outputId": "e5db4e86-8699-475a-a794-cc03d8b615cc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f6e53eb2f70>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f6e53eb2f70>)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445,
     "referenced_widgets": [
      "d2b327e2b0074354a6b889afc169a62e",
      "84ab2eb4f0b74ac3a334eb7ecd7c4d63",
      "f8ebf6d2f2954cbbb525e67de58a766a",
      "a0a3db286a1843b293b1d3b944a3d33a",
      "d68d5a7c97bd47719eb1e19f67d64805",
      "1fac6af61b4d411a94f3916061731428",
      "127c67d7658d4bf392408e7d5600a09c",
      "25b71debb82040a2960eb8348df2a4ca",
      "9428191170994f0aa7fd400caf0d1d07",
      "ef4fa30c44df4726a36cfc1da100fb4f",
      "dffd33c1015f4bfd91fd702095c2127e",
      "ba1298c2f3db42c48b7e3e3ee83d5000",
      "0e46dd857d504def992f555a9e9c9c5f",
      "285649e2ae134f87bd2f8dcf40a7758d",
      "83ec7a9ea11e410bb3fcad13c082d664",
      "5fd2178313d34631a030d79934dcffe0",
      "c3c43f7938044239b4eca004d07874ae",
      "b3e24f0b77884455868b103ab69ddd5d",
      "79385887dd0f479d993b251748f8cb2f",
      "429fbc36c65446d09d32298cfc4b606e",
      "b449b3c3b1b944a38293f2f13d517860",
      "c4dc2a989d794b44b8000ca88cf095fa",
      "97e269fbcb954d629b2314d30c41c57b",
      "84c7612e3ed740958159eec4ee147476",
      "93c2ea7279794b88b6264f832400e3c7",
      "45340f3b0bf4413182060f27c7458334",
      "6bf0078bd11d4ed980f1b7a9b612a091",
      "4fb2b190729943cb8c1f1fd2b84d6935",
      "a5a571c48de54900b2b696f2c6817a2e",
      "966b77941ef046babfb1e9ed597a6aee",
      "f16174670d2c4182ace507dda7812328",
      "e61579f72d51414782f8fe3c28e12e86",
      "dbcd62725c684fcc897583042ca44888",
      "ba6f4922558c41fea4a4b171a021b871",
      "5587ced0255640dd9bec68478cd973fb",
      "48bb2d6d069e411a9e969187d5ddf17d",
      "4fffbd7c89314024a7b8c128ad1ba248",
      "dea06faaa22b41b6bbfd7ff6d8ee39f6",
      "347f2c97cd4f46aa8bd1d30f79041b29",
      "81211b58e69b4973a9e1b500e621656b",
      "ce97e8d1d6b54e17a16ec75e1b3abf7f",
      "5d4e33c5404f49caa4811bfd55b0bee5",
      "d37bf18a5e9346fcb59242e0e5288307",
      "005a930db3d242a4be28a9c5923eed76",
      "0573bd35717d4189ab4d74fdc489653b",
      "06e6627b73a24e4291f316a281a20aea",
      "bd7b7a9f5f80492997ec2cbd4bf22627",
      "1b08c691a8db4cb79e6f7837a08ac799",
      "b904bbebe38943728a23a0d630f86a88",
      "9cd468cf60c643db96d0cd35923c8258",
      "cddc7d98bbb740a9a81bf8e244d4595d",
      "cfcb95376da04ce884ab18c57c2d63ed",
      "f69895f136a14e629614a45f2e7d8557",
      "47144694b20f49f0aa54ee1d83119fda",
      "3898654592194daca51999f513192a24",
      "39ceb75a4fa14f6e9a8a5f4ae1324cbc",
      "49901550f7c14e439505f80faaaa8357",
      "4bba40ddade644b79cce613925a4f47e",
      "aa38ae45e85545bebec6c8b43db7abbf",
      "37a7f3f9244a4fd991fe9e8847268ec1",
      "b537afbec50e4567885220cf27a5b761",
      "ce10ff94a3454674a5deb511394387ff",
      "be10758757c1426c8779c6706a445ecd",
      "d26f30f1432e4f2ab1c53484b44989ee",
      "0305993a3c1a4f8296faeb1aba61fa38",
      "fce9ba2896164d4391fea7f32dc3d811",
      "ffe6027ef4bb4fd9964717116a39f1a3",
      "4b15ff3c6b044b40a15b21f051bf53c8",
      "3ddd6cf350fb4378ad6cf2698f67d68f",
      "ceca8a9a02fe46d5a1a3aa093fdbcde7",
      "20d7306a9b474da3b0c8e80a3d7abe09",
      "3b924323276f4f92a66a64d295ba6c78",
      "21b88aca18f048759fb25ce63540c992",
      "b58e5e54e53e46d7a4f196a93812373c",
      "b849b43f5c4649deb018fb959191edc5",
      "95d7c71216094ea0b466a79efc95341d",
      "264fdba12e854d54b3ed2510458c7a1b"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T12:26:10.156541Z",
     "iopub.status.busy": "2024-02-27T12:26:10.156209Z",
     "iopub.status.idle": "2024-02-27T12:50:26.838508Z",
     "shell.execute_reply": "2024-02-27T12:50:26.837953Z",
     "shell.execute_reply.started": "2024-02-27T12:26:10.156522Z"
    },
    "id": "sxQ-s0izFQGQ",
    "outputId": "fd7d2eef-efef-4367-dcc3-70ff9e3d18fb",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:102: UserWarning: When using `Trainer(accumulate_grad_batches != 1)` and overriding `LightningModule.optimizer_{step,zero_grad}`, the hooks will not be called on every batch (rather, they are called on every optimization step).\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "121.013   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/3750 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/closure.py:35: LightningDeprecationWarning: One of the returned values {'log'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|██████▋   | 2500/3750 [06:36<03:18,  6.30it/s, loss=0.138, v_num=0] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1250 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  67%|██████▋   | 2502/3750 [06:37<03:18,  6.30it/s, loss=0.138, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  67%|██████▋   | 2504/3750 [06:37<03:17,  6.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 2506/3750 [06:37<03:17,  6.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 2508/3750 [06:37<03:16,  6.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 2510/3750 [06:37<03:16,  6.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 2512/3750 [06:37<03:15,  6.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 2514/3750 [06:37<03:15,  6.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 2516/3750 [06:37<03:15,  6.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 2518/3750 [06:37<03:14,  6.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 2520/3750 [06:38<03:14,  6.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 2522/3750 [06:38<03:13,  6.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 2524/3750 [06:38<03:13,  6.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 2526/3750 [06:38<03:13,  6.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 2528/3750 [06:38<03:12,  6.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 2530/3750 [06:38<03:12,  6.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2532/3750 [06:38<03:11,  6.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2534/3750 [06:38<03:11,  6.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2536/3750 [06:38<03:10,  6.36it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2538/3750 [06:39<03:10,  6.36it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2540/3750 [06:39<03:10,  6.36it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2542/3750 [06:39<03:09,  6.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2544/3750 [06:39<03:09,  6.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2546/3750 [06:39<03:08,  6.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2548/3750 [06:39<03:08,  6.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2550/3750 [06:39<03:08,  6.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2552/3750 [06:39<03:07,  6.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2554/3750 [06:39<03:07,  6.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2556/3750 [06:40<03:06,  6.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2558/3750 [06:40<03:06,  6.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2560/3750 [06:40<03:06,  6.40it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2562/3750 [06:40<03:05,  6.40it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2564/3750 [06:40<03:05,  6.40it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2566/3750 [06:40<03:04,  6.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 2568/3750 [06:40<03:04,  6.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▊   | 2570/3750 [06:40<03:04,  6.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▊   | 2572/3750 [06:40<03:03,  6.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▊   | 2574/3750 [06:41<03:03,  6.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▊   | 2576/3750 [06:41<03:02,  6.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▊   | 2578/3750 [06:41<03:02,  6.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2580/3750 [06:41<03:02,  6.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2582/3750 [06:41<03:01,  6.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2584/3750 [06:41<03:01,  6.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2586/3750 [06:41<03:00,  6.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2588/3750 [06:41<03:00,  6.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2590/3750 [06:41<03:00,  6.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2592/3750 [06:42<02:59,  6.45it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2594/3750 [06:42<02:59,  6.45it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2596/3750 [06:42<02:58,  6.45it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2598/3750 [06:42<02:58,  6.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2600/3750 [06:42<02:58,  6.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2602/3750 [06:42<02:57,  6.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2604/3750 [06:42<02:57,  6.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 2606/3750 [06:42<02:56,  6.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|██████▉   | 2608/3750 [06:42<02:56,  6.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|██████▉   | 2610/3750 [06:43<02:56,  6.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|██████▉   | 2612/3750 [06:43<02:55,  6.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|██████▉   | 2614/3750 [06:43<02:55,  6.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|██████▉   | 2616/3750 [06:43<02:54,  6.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|██████▉   | 2618/3750 [06:43<02:54,  6.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|██████▉   | 2620/3750 [06:43<02:54,  6.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|██████▉   | 2622/3750 [06:43<02:53,  6.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|██████▉   | 2624/3750 [06:43<02:53,  6.50it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|███████   | 2626/3750 [06:43<02:52,  6.50it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|███████   | 2628/3750 [06:44<02:52,  6.50it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|███████   | 2630/3750 [06:44<02:52,  6.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|███████   | 2632/3750 [06:44<02:51,  6.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|███████   | 2634/3750 [06:44<02:51,  6.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|███████   | 2636/3750 [06:44<02:50,  6.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|███████   | 2638/3750 [06:44<02:50,  6.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|███████   | 2640/3750 [06:44<02:50,  6.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  70%|███████   | 2642/3750 [06:44<02:49,  6.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2644/3750 [06:45<02:49,  6.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2646/3750 [06:45<02:49,  6.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2648/3750 [06:45<02:48,  6.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2650/3750 [06:45<02:48,  6.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2652/3750 [06:45<02:47,  6.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2654/3750 [06:45<02:47,  6.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2656/3750 [06:45<02:47,  6.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2658/3750 [06:45<02:46,  6.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2660/3750 [06:45<02:46,  6.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2662/3750 [06:46<02:45,  6.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2664/3750 [06:46<02:45,  6.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2666/3750 [06:46<02:45,  6.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2668/3750 [06:46<02:44,  6.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████   | 2670/3750 [06:46<02:44,  6.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████▏  | 2672/3750 [06:46<02:44,  6.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████▏  | 2674/3750 [06:46<02:43,  6.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████▏  | 2676/3750 [06:46<02:43,  6.58it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████▏  | 2678/3750 [06:46<02:42,  6.58it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  71%|███████▏  | 2680/3750 [06:47<02:42,  6.58it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2682/3750 [06:47<02:42,  6.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2684/3750 [06:47<02:41,  6.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2686/3750 [06:47<02:41,  6.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2688/3750 [06:47<02:40,  6.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2690/3750 [06:47<02:40,  6.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2692/3750 [06:47<02:40,  6.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2694/3750 [06:47<02:39,  6.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2696/3750 [06:47<02:39,  6.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2698/3750 [06:48<02:39,  6.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2700/3750 [06:48<02:38,  6.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2702/3750 [06:48<02:38,  6.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2704/3750 [06:48<02:37,  6.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2706/3750 [06:48<02:37,  6.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2708/3750 [06:48<02:37,  6.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2710/3750 [06:48<02:36,  6.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2712/3750 [06:48<02:36,  6.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2714/3750 [06:48<02:36,  6.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2716/3750 [06:49<02:35,  6.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  72%|███████▏  | 2718/3750 [06:49<02:35,  6.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2720/3750 [06:49<02:34,  6.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2722/3750 [06:49<02:34,  6.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2724/3750 [06:49<02:34,  6.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2726/3750 [06:49<02:33,  6.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2728/3750 [06:49<02:33,  6.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2730/3750 [06:49<02:33,  6.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2732/3750 [06:49<02:32,  6.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2734/3750 [06:50<02:32,  6.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2736/3750 [06:50<02:32,  6.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2738/3750 [06:50<02:31,  6.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2740/3750 [06:50<02:31,  6.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2742/3750 [06:50<02:30,  6.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2744/3750 [06:50<02:30,  6.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2746/3750 [06:50<02:30,  6.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2748/3750 [06:50<02:29,  6.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2750/3750 [06:50<02:29,  6.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2752/3750 [06:51<02:29,  6.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2754/3750 [06:51<02:28,  6.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 2756/3750 [06:51<02:28,  6.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▎  | 2758/3750 [06:51<02:27,  6.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▎  | 2760/3750 [06:51<02:27,  6.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▎  | 2762/3750 [06:51<02:27,  6.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▎  | 2764/3750 [06:51<02:26,  6.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2766/3750 [06:51<02:26,  6.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2768/3750 [06:52<02:26,  6.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2770/3750 [06:52<02:25,  6.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2772/3750 [06:52<02:25,  6.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2774/3750 [06:52<02:25,  6.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2776/3750 [06:52<02:24,  6.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2778/3750 [06:52<02:24,  6.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2780/3750 [06:52<02:23,  6.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2782/3750 [06:52<02:23,  6.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2784/3750 [06:52<02:23,  6.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2786/3750 [06:53<02:22,  6.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2788/3750 [06:53<02:22,  6.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2790/3750 [06:53<02:22,  6.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 2792/3750 [06:53<02:21,  6.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▍  | 2794/3750 [06:53<02:21,  6.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▍  | 2796/3750 [06:53<02:21,  6.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▍  | 2798/3750 [06:53<02:20,  6.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▍  | 2800/3750 [06:53<02:20,  6.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▍  | 2802/3750 [06:53<02:20,  6.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▍  | 2804/3750 [06:54<02:19,  6.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▍  | 2806/3750 [06:54<02:19,  6.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▍  | 2808/3750 [06:54<02:18,  6.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▍  | 2810/3750 [06:54<02:18,  6.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▍  | 2812/3750 [06:54<02:18,  6.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▌  | 2814/3750 [06:54<02:17,  6.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▌  | 2816/3750 [06:54<02:17,  6.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▌  | 2818/3750 [06:54<02:17,  6.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▌  | 2820/3750 [06:54<02:16,  6.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▌  | 2822/3750 [06:55<02:16,  6.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▌  | 2824/3750 [06:55<02:16,  6.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▌  | 2826/3750 [06:55<02:15,  6.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▌  | 2828/3750 [06:55<02:15,  6.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  75%|███████▌  | 2830/3750 [06:55<02:15,  6.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2832/3750 [06:55<02:14,  6.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2834/3750 [06:55<02:14,  6.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2836/3750 [06:55<02:14,  6.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2838/3750 [06:55<02:13,  6.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2840/3750 [06:56<02:13,  6.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2842/3750 [06:56<02:12,  6.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2844/3750 [06:56<02:12,  6.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2846/3750 [06:56<02:12,  6.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2848/3750 [06:56<02:11,  6.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2850/3750 [06:56<02:11,  6.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2852/3750 [06:56<02:11,  6.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2854/3750 [06:56<02:10,  6.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2856/3750 [06:56<02:10,  6.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 2858/3750 [06:57<02:10,  6.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▋  | 2860/3750 [06:57<02:09,  6.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▋  | 2862/3750 [06:57<02:09,  6.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▋  | 2864/3750 [06:57<02:09,  6.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▋  | 2866/3750 [06:57<02:08,  6.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  76%|███████▋  | 2868/3750 [06:57<02:08,  6.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2870/3750 [06:57<02:08,  6.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2872/3750 [06:57<02:07,  6.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2874/3750 [06:57<02:07,  6.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2876/3750 [06:58<02:07,  6.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2878/3750 [06:58<02:06,  6.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2880/3750 [06:58<02:06,  6.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2882/3750 [06:58<02:06,  6.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2884/3750 [06:58<02:05,  6.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2886/3750 [06:58<02:05,  6.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2888/3750 [06:58<02:04,  6.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2890/3750 [06:58<02:04,  6.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2892/3750 [06:58<02:04,  6.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2894/3750 [06:59<02:03,  6.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2896/3750 [06:59<02:03,  6.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2898/3750 [06:59<02:03,  6.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2900/3750 [06:59<02:02,  6.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2902/3750 [06:59<02:02,  6.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2904/3750 [06:59<02:02,  6.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 2906/3750 [06:59<02:01,  6.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2908/3750 [06:59<02:01,  6.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2910/3750 [07:00<02:01,  6.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2912/3750 [07:00<02:00,  6.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2914/3750 [07:00<02:00,  6.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2916/3750 [07:00<02:00,  6.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2918/3750 [07:00<01:59,  6.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2920/3750 [07:00<01:59,  6.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2922/3750 [07:00<01:59,  6.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2924/3750 [07:00<01:58,  6.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2926/3750 [07:00<01:58,  6.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2928/3750 [07:01<01:58,  6.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2930/3750 [07:01<01:57,  6.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2932/3750 [07:01<01:57,  6.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2934/3750 [07:01<01:57,  6.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2936/3750 [07:01<01:56,  6.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2938/3750 [07:01<01:56,  6.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2940/3750 [07:01<01:56,  6.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  78%|███████▊  | 2942/3750 [07:01<01:55,  6.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▊  | 2944/3750 [07:01<01:55,  6.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▊  | 2946/3750 [07:02<01:55,  6.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▊  | 2948/3750 [07:02<01:54,  6.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▊  | 2950/3750 [07:02<01:54,  6.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▊  | 2952/3750 [07:02<01:54,  6.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2954/3750 [07:02<01:53,  6.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2956/3750 [07:02<01:53,  6.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2958/3750 [07:02<01:53,  7.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2960/3750 [07:02<01:52,  7.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2962/3750 [07:02<01:52,  7.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2964/3750 [07:03<01:52,  7.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2966/3750 [07:03<01:51,  7.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2968/3750 [07:03<01:51,  7.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2970/3750 [07:03<01:51,  7.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2972/3750 [07:03<01:50,  7.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2974/3750 [07:03<01:50,  7.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2976/3750 [07:03<01:50,  7.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2978/3750 [07:03<01:49,  7.03it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 2980/3750 [07:03<01:49,  7.03it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|███████▉  | 2982/3750 [07:04<01:49,  7.03it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|███████▉  | 2984/3750 [07:04<01:48,  7.03it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|███████▉  | 2986/3750 [07:04<01:48,  7.04it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|███████▉  | 2988/3750 [07:04<01:48,  7.04it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|███████▉  | 2990/3750 [07:04<01:47,  7.04it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|███████▉  | 2992/3750 [07:04<01:47,  7.05it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|███████▉  | 2994/3750 [07:04<01:47,  7.05it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|███████▉  | 2996/3750 [07:04<01:46,  7.05it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|███████▉  | 2998/3750 [07:04<01:46,  7.05it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|████████  | 3000/3750 [07:05<01:46,  7.06it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|████████  | 3002/3750 [07:05<01:45,  7.06it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|████████  | 3004/3750 [07:05<01:45,  7.06it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|████████  | 3006/3750 [07:05<01:45,  7.07it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|████████  | 3008/3750 [07:05<01:44,  7.07it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|████████  | 3010/3750 [07:05<01:44,  7.07it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|████████  | 3012/3750 [07:05<01:44,  7.07it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|████████  | 3014/3750 [07:05<01:43,  7.08it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|████████  | 3016/3750 [07:05<01:43,  7.08it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  80%|████████  | 3018/3750 [07:06<01:43,  7.08it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3020/3750 [07:06<01:43,  7.09it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3022/3750 [07:06<01:42,  7.09it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3024/3750 [07:06<01:42,  7.09it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3026/3750 [07:06<01:42,  7.09it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3028/3750 [07:06<01:41,  7.10it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3030/3750 [07:06<01:41,  7.10it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3032/3750 [07:06<01:41,  7.10it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3034/3750 [07:06<01:40,  7.11it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3036/3750 [07:07<01:40,  7.11it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3038/3750 [07:07<01:40,  7.11it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3040/3750 [07:07<01:39,  7.11it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3042/3750 [07:07<01:39,  7.12it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3044/3750 [07:07<01:39,  7.12it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████  | 3046/3750 [07:07<01:38,  7.12it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████▏ | 3048/3750 [07:07<01:38,  7.13it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████▏ | 3050/3750 [07:07<01:38,  7.13it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████▏ | 3052/3750 [07:08<01:37,  7.13it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████▏ | 3054/3750 [07:08<01:37,  7.13it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  81%|████████▏ | 3056/3750 [07:08<01:37,  7.14it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3058/3750 [07:08<01:36,  7.14it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3060/3750 [07:08<01:36,  7.14it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3062/3750 [07:08<01:36,  7.14it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3064/3750 [07:08<01:35,  7.15it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3066/3750 [07:08<01:35,  7.15it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3068/3750 [07:08<01:35,  7.15it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3070/3750 [07:09<01:35,  7.16it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3072/3750 [07:09<01:34,  7.16it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3074/3750 [07:09<01:34,  7.16it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3076/3750 [07:09<01:34,  7.16it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3078/3750 [07:09<01:33,  7.17it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3080/3750 [07:09<01:33,  7.17it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3082/3750 [07:09<01:33,  7.17it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3084/3750 [07:09<01:32,  7.18it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3086/3750 [07:09<01:32,  7.18it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3088/3750 [07:10<01:32,  7.18it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3090/3750 [07:10<01:31,  7.18it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 3092/3750 [07:10<01:31,  7.19it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3094/3750 [07:10<01:31,  7.19it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3096/3750 [07:10<01:30,  7.19it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3098/3750 [07:10<01:30,  7.19it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3100/3750 [07:10<01:30,  7.20it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3102/3750 [07:10<01:30,  7.20it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3104/3750 [07:10<01:29,  7.20it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3106/3750 [07:11<01:29,  7.21it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3108/3750 [07:11<01:29,  7.21it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3110/3750 [07:11<01:28,  7.21it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3112/3750 [07:11<01:28,  7.21it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3114/3750 [07:11<01:28,  7.22it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3116/3750 [07:11<01:27,  7.22it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3118/3750 [07:11<01:27,  7.22it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3120/3750 [07:11<01:27,  7.22it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3122/3750 [07:11<01:26,  7.23it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3124/3750 [07:12<01:26,  7.23it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3126/3750 [07:12<01:26,  7.23it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3128/3750 [07:12<01:25,  7.24it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 3130/3750 [07:12<01:25,  7.24it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▎ | 3132/3750 [07:12<01:25,  7.24it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▎ | 3134/3750 [07:12<01:25,  7.24it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▎ | 3136/3750 [07:12<01:24,  7.25it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▎ | 3138/3750 [07:12<01:24,  7.25it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▎ | 3140/3750 [07:12<01:24,  7.25it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3142/3750 [07:13<01:23,  7.25it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3144/3750 [07:13<01:23,  7.26it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3146/3750 [07:13<01:23,  7.26it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3148/3750 [07:13<01:22,  7.26it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3150/3750 [07:13<01:22,  7.27it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3152/3750 [07:13<01:22,  7.27it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3154/3750 [07:13<01:21,  7.27it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3156/3750 [07:13<01:21,  7.27it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3158/3750 [07:13<01:21,  7.28it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3160/3750 [07:14<01:21,  7.28it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3162/3750 [07:14<01:20,  7.28it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3164/3750 [07:14<01:20,  7.28it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3166/3750 [07:14<01:20,  7.29it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 3168/3750 [07:14<01:19,  7.29it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▍ | 3170/3750 [07:14<01:19,  7.29it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▍ | 3172/3750 [07:14<01:19,  7.30it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▍ | 3174/3750 [07:14<01:18,  7.30it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▍ | 3176/3750 [07:15<01:18,  7.30it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▍ | 3178/3750 [07:15<01:18,  7.30it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▍ | 3180/3750 [07:15<01:18,  7.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▍ | 3182/3750 [07:15<01:17,  7.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▍ | 3184/3750 [07:15<01:17,  7.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▍ | 3186/3750 [07:15<01:17,  7.31it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▌ | 3188/3750 [07:15<01:16,  7.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▌ | 3190/3750 [07:15<01:16,  7.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▌ | 3192/3750 [07:15<01:16,  7.32it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▌ | 3194/3750 [07:16<01:15,  7.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▌ | 3196/3750 [07:16<01:15,  7.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▌ | 3198/3750 [07:16<01:15,  7.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▌ | 3200/3750 [07:16<01:15,  7.33it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▌ | 3202/3750 [07:16<01:14,  7.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▌ | 3204/3750 [07:16<01:14,  7.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  85%|████████▌ | 3206/3750 [07:16<01:14,  7.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3208/3750 [07:16<01:13,  7.34it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3210/3750 [07:16<01:13,  7.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3212/3750 [07:17<01:13,  7.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3214/3750 [07:17<01:12,  7.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3216/3750 [07:17<01:12,  7.35it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3218/3750 [07:17<01:12,  7.36it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3220/3750 [07:17<01:12,  7.36it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3222/3750 [07:17<01:11,  7.36it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3224/3750 [07:17<01:11,  7.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3226/3750 [07:17<01:11,  7.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3228/3750 [07:17<01:10,  7.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3230/3750 [07:18<01:10,  7.37it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3232/3750 [07:18<01:10,  7.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 3234/3750 [07:18<01:09,  7.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▋ | 3236/3750 [07:18<01:09,  7.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▋ | 3238/3750 [07:18<01:09,  7.38it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▋ | 3240/3750 [07:18<01:09,  7.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  86%|████████▋ | 3242/3750 [07:18<01:08,  7.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3244/3750 [07:18<01:08,  7.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3246/3750 [07:18<01:08,  7.39it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3248/3750 [07:19<01:07,  7.40it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3250/3750 [07:19<01:07,  7.40it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3252/3750 [07:19<01:07,  7.40it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3254/3750 [07:19<01:06,  7.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3256/3750 [07:19<01:06,  7.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3258/3750 [07:19<01:06,  7.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3260/3750 [07:19<01:06,  7.41it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3262/3750 [07:19<01:05,  7.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3264/3750 [07:19<01:05,  7.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3266/3750 [07:20<01:05,  7.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3268/3750 [07:20<01:04,  7.42it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3270/3750 [07:20<01:04,  7.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3272/3750 [07:20<01:04,  7.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3274/3750 [07:20<01:04,  7.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3276/3750 [07:20<01:03,  7.43it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3278/3750 [07:20<01:03,  7.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 3280/3750 [07:20<01:03,  7.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3282/3750 [07:20<01:02,  7.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3284/3750 [07:21<01:02,  7.44it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3286/3750 [07:21<01:02,  7.45it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3288/3750 [07:21<01:02,  7.45it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3290/3750 [07:21<01:01,  7.45it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3292/3750 [07:21<01:01,  7.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3294/3750 [07:21<01:01,  7.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3296/3750 [07:21<01:00,  7.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3298/3750 [07:21<01:00,  7.46it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3300/3750 [07:22<01:00,  7.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3302/3750 [07:22<00:59,  7.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3304/3750 [07:22<00:59,  7.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3306/3750 [07:22<00:59,  7.47it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3308/3750 [07:22<00:59,  7.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3310/3750 [07:22<00:58,  7.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3312/3750 [07:22<00:58,  7.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3314/3750 [07:22<00:58,  7.48it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3316/3750 [07:22<00:57,  7.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 3318/3750 [07:23<00:57,  7.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▊ | 3320/3750 [07:23<00:57,  7.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▊ | 3322/3750 [07:23<00:57,  7.49it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▊ | 3324/3750 [07:23<00:56,  7.50it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▊ | 3326/3750 [07:23<00:56,  7.50it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▊ | 3328/3750 [07:23<00:56,  7.50it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3330/3750 [07:23<00:55,  7.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3332/3750 [07:23<00:55,  7.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3334/3750 [07:23<00:55,  7.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3336/3750 [07:24<00:55,  7.51it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3338/3750 [07:24<00:54,  7.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3340/3750 [07:24<00:54,  7.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3342/3750 [07:24<00:54,  7.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3344/3750 [07:24<00:53,  7.52it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3346/3750 [07:24<00:53,  7.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3348/3750 [07:24<00:53,  7.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3350/3750 [07:24<00:53,  7.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3352/3750 [07:24<00:52,  7.53it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3354/3750 [07:25<00:52,  7.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 3356/3750 [07:25<00:52,  7.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|████████▉ | 3358/3750 [07:25<00:51,  7.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|████████▉ | 3360/3750 [07:25<00:51,  7.54it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|████████▉ | 3362/3750 [07:25<00:51,  7.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|████████▉ | 3364/3750 [07:25<00:51,  7.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|████████▉ | 3366/3750 [07:25<00:50,  7.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|████████▉ | 3368/3750 [07:25<00:50,  7.55it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|████████▉ | 3370/3750 [07:25<00:50,  7.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|████████▉ | 3372/3750 [07:26<00:50,  7.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|████████▉ | 3374/3750 [07:26<00:49,  7.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|█████████ | 3376/3750 [07:26<00:49,  7.56it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|█████████ | 3378/3750 [07:26<00:49,  7.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|█████████ | 3380/3750 [07:26<00:48,  7.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|█████████ | 3382/3750 [07:26<00:48,  7.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|█████████ | 3384/3750 [07:26<00:48,  7.57it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|█████████ | 3386/3750 [07:26<00:48,  7.58it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|█████████ | 3388/3750 [07:26<00:47,  7.58it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|█████████ | 3390/3750 [07:27<00:47,  7.58it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  90%|█████████ | 3392/3750 [07:27<00:47,  7.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3394/3750 [07:27<00:46,  7.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3396/3750 [07:27<00:46,  7.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3398/3750 [07:27<00:46,  7.59it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3400/3750 [07:27<00:46,  7.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3402/3750 [07:27<00:45,  7.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3404/3750 [07:27<00:45,  7.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3406/3750 [07:27<00:45,  7.60it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3408/3750 [07:28<00:44,  7.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3410/3750 [07:28<00:44,  7.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3412/3750 [07:28<00:44,  7.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3414/3750 [07:28<00:44,  7.61it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3416/3750 [07:28<00:43,  7.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3418/3750 [07:28<00:43,  7.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 3420/3750 [07:28<00:43,  7.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████▏| 3422/3750 [07:28<00:43,  7.62it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████▏| 3424/3750 [07:28<00:42,  7.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████▏| 3426/3750 [07:29<00:42,  7.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████▏| 3428/3750 [07:29<00:42,  7.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  91%|█████████▏| 3430/3750 [07:29<00:41,  7.63it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3432/3750 [07:29<00:41,  7.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3434/3750 [07:29<00:41,  7.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3436/3750 [07:29<00:41,  7.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3438/3750 [07:29<00:40,  7.64it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3440/3750 [07:29<00:40,  7.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3442/3750 [07:30<00:40,  7.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3444/3750 [07:30<00:39,  7.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3446/3750 [07:30<00:39,  7.65it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3448/3750 [07:30<00:39,  7.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3450/3750 [07:30<00:39,  7.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3452/3750 [07:30<00:38,  7.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3454/3750 [07:30<00:38,  7.66it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3456/3750 [07:30<00:38,  7.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3458/3750 [07:30<00:38,  7.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3460/3750 [07:31<00:37,  7.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3462/3750 [07:31<00:37,  7.67it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3464/3750 [07:31<00:37,  7.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3466/3750 [07:31<00:36,  7.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 3468/3750 [07:31<00:36,  7.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3470/3750 [07:31<00:36,  7.68it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3472/3750 [07:31<00:36,  7.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3474/3750 [07:31<00:35,  7.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3476/3750 [07:31<00:35,  7.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3478/3750 [07:32<00:35,  7.69it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3480/3750 [07:32<00:35,  7.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3482/3750 [07:32<00:34,  7.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3484/3750 [07:32<00:34,  7.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3486/3750 [07:32<00:34,  7.70it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3488/3750 [07:32<00:33,  7.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3490/3750 [07:32<00:33,  7.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3492/3750 [07:32<00:33,  7.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3494/3750 [07:32<00:33,  7.71it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3496/3750 [07:33<00:32,  7.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3498/3750 [07:33<00:32,  7.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3500/3750 [07:33<00:32,  7.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3502/3750 [07:33<00:32,  7.72it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3504/3750 [07:33<00:31,  7.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 3506/3750 [07:33<00:31,  7.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▎| 3508/3750 [07:33<00:31,  7.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▎| 3510/3750 [07:33<00:31,  7.73it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▎| 3512/3750 [07:33<00:30,  7.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▎| 3514/3750 [07:34<00:30,  7.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3516/3750 [07:34<00:30,  7.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3518/3750 [07:34<00:29,  7.74it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3520/3750 [07:34<00:29,  7.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3522/3750 [07:34<00:29,  7.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3524/3750 [07:34<00:29,  7.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3526/3750 [07:34<00:28,  7.75it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3528/3750 [07:34<00:28,  7.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3530/3750 [07:34<00:28,  7.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3532/3750 [07:35<00:28,  7.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3534/3750 [07:35<00:27,  7.76it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3536/3750 [07:35<00:27,  7.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3538/3750 [07:35<00:27,  7.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3540/3750 [07:35<00:27,  7.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 3542/3750 [07:35<00:26,  7.77it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▍| 3544/3750 [07:35<00:26,  7.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▍| 3546/3750 [07:35<00:26,  7.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▍| 3548/3750 [07:35<00:25,  7.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▍| 3550/3750 [07:36<00:25,  7.78it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▍| 3552/3750 [07:36<00:25,  7.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▍| 3554/3750 [07:36<00:25,  7.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▍| 3556/3750 [07:36<00:24,  7.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▍| 3558/3750 [07:36<00:24,  7.79it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▍| 3560/3750 [07:36<00:24,  7.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▍| 3562/3750 [07:36<00:24,  7.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▌| 3564/3750 [07:36<00:23,  7.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▌| 3566/3750 [07:37<00:23,  7.80it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▌| 3568/3750 [07:37<00:23,  7.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▌| 3570/3750 [07:37<00:23,  7.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▌| 3572/3750 [07:37<00:22,  7.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▌| 3574/3750 [07:37<00:22,  7.81it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▌| 3576/3750 [07:37<00:22,  7.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▌| 3578/3750 [07:37<00:22,  7.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  95%|█████████▌| 3580/3750 [07:37<00:21,  7.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3582/3750 [07:37<00:21,  7.82it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3584/3750 [07:38<00:21,  7.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3586/3750 [07:38<00:20,  7.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3588/3750 [07:38<00:20,  7.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3590/3750 [07:38<00:20,  7.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3592/3750 [07:38<00:20,  7.83it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3594/3750 [07:38<00:19,  7.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3596/3750 [07:38<00:19,  7.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3598/3750 [07:38<00:19,  7.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3600/3750 [07:38<00:19,  7.84it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3602/3750 [07:39<00:18,  7.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3604/3750 [07:39<00:18,  7.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3606/3750 [07:39<00:18,  7.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▌| 3608/3750 [07:39<00:18,  7.85it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▋| 3610/3750 [07:39<00:17,  7.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▋| 3612/3750 [07:39<00:17,  7.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▋| 3614/3750 [07:39<00:17,  7.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▋| 3616/3750 [07:39<00:17,  7.86it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  96%|█████████▋| 3618/3750 [07:39<00:16,  7.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3620/3750 [07:40<00:16,  7.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3622/3750 [07:40<00:16,  7.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3624/3750 [07:40<00:16,  7.87it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3626/3750 [07:40<00:15,  7.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3628/3750 [07:40<00:15,  7.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3630/3750 [07:40<00:15,  7.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3632/3750 [07:40<00:14,  7.88it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3634/3750 [07:40<00:14,  7.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3636/3750 [07:40<00:14,  7.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3638/3750 [07:41<00:14,  7.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3640/3750 [07:41<00:13,  7.89it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3642/3750 [07:41<00:13,  7.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3644/3750 [07:41<00:13,  7.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3646/3750 [07:41<00:13,  7.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3648/3750 [07:41<00:12,  7.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3650/3750 [07:41<00:12,  7.90it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3652/3750 [07:41<00:12,  7.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3654/3750 [07:41<00:12,  7.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 3656/3750 [07:42<00:11,  7.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3658/3750 [07:42<00:11,  7.91it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3660/3750 [07:42<00:11,  7.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3662/3750 [07:42<00:11,  7.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3664/3750 [07:42<00:10,  7.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3666/3750 [07:42<00:10,  7.92it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3668/3750 [07:42<00:10,  7.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3670/3750 [07:42<00:10,  7.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3672/3750 [07:42<00:09,  7.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3674/3750 [07:43<00:09,  7.93it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3676/3750 [07:43<00:09,  7.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3678/3750 [07:43<00:09,  7.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3680/3750 [07:43<00:08,  7.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3682/3750 [07:43<00:08,  7.94it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3684/3750 [07:43<00:08,  7.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3686/3750 [07:43<00:08,  7.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3688/3750 [07:43<00:07,  7.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3690/3750 [07:43<00:07,  7.95it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 3692/3750 [07:44<00:07,  7.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▊| 3694/3750 [07:44<00:07,  7.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▊| 3696/3750 [07:44<00:06,  7.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▊| 3698/3750 [07:44<00:06,  7.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▊| 3700/3750 [07:44<00:06,  7.96it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▊| 3702/3750 [07:44<00:06,  7.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3704/3750 [07:44<00:05,  7.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3706/3750 [07:44<00:05,  7.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3708/3750 [07:45<00:05,  7.97it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3710/3750 [07:45<00:05,  7.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3712/3750 [07:45<00:04,  7.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3714/3750 [07:45<00:04,  7.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3716/3750 [07:45<00:04,  7.98it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3718/3750 [07:45<00:04,  7.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3720/3750 [07:45<00:03,  7.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3722/3750 [07:45<00:03,  7.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3724/3750 [07:45<00:03,  7.99it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3726/3750 [07:46<00:03,  8.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3728/3750 [07:46<00:02,  8.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 3730/3750 [07:46<00:02,  8.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|█████████▉| 3732/3750 [07:46<00:02,  8.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|█████████▉| 3734/3750 [07:46<00:01,  8.00it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|█████████▉| 3736/3750 [07:46<00:01,  8.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|█████████▉| 3738/3750 [07:46<00:01,  8.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|█████████▉| 3740/3750 [07:46<00:01,  8.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|█████████▉| 3742/3750 [07:46<00:00,  8.01it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|█████████▉| 3744/3750 [07:47<00:00,  8.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|█████████▉| 3746/3750 [07:47<00:00,  8.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|█████████▉| 3748/3750 [07:47<00:00,  8.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 0: 100%|██████████| 3750/3750 [07:47<00:00,  8.02it/s, loss=0.138, v_num=0]\n",
      "Epoch 1:   0%|          | 0/3750 [00:00<?, ?it/s, loss=0.138, v_num=0]           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  67%|██████▋   | 2500/3750 [06:38<03:19,  6.28it/s, loss=0.125, v_num=0] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1250 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:  67%|██████▋   | 2502/3750 [06:38<03:18,  6.28it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2504/3750 [06:38<03:18,  6.28it/s, loss=0.125, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:  67%|██████▋   | 2506/3750 [06:38<03:17,  6.29it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2508/3750 [06:38<03:17,  6.29it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2510/3750 [06:38<03:17,  6.29it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2512/3750 [06:38<03:16,  6.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2514/3750 [06:39<03:16,  6.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2516/3750 [06:39<03:15,  6.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2518/3750 [06:39<03:15,  6.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2520/3750 [06:39<03:14,  6.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2522/3750 [06:39<03:14,  6.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2524/3750 [06:39<03:14,  6.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2526/3750 [06:39<03:13,  6.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2528/3750 [06:39<03:13,  6.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2530/3750 [06:39<03:12,  6.33it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2532/3750 [06:40<03:12,  6.33it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2534/3750 [06:40<03:12,  6.33it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2536/3750 [06:40<03:11,  6.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2538/3750 [06:40<03:11,  6.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2540/3750 [06:40<03:10,  6.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2542/3750 [06:40<03:10,  6.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2544/3750 [06:40<03:09,  6.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2546/3750 [06:40<03:09,  6.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2548/3750 [06:40<03:09,  6.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2550/3750 [06:41<03:08,  6.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2552/3750 [06:41<03:08,  6.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2554/3750 [06:41<03:07,  6.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2556/3750 [06:41<03:07,  6.37it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2558/3750 [06:41<03:07,  6.37it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2560/3750 [06:41<03:06,  6.37it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2562/3750 [06:41<03:06,  6.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2564/3750 [06:41<03:05,  6.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2566/3750 [06:42<03:05,  6.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  68%|██████▊   | 2568/3750 [06:42<03:05,  6.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▊   | 2570/3750 [06:42<03:04,  6.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▊   | 2572/3750 [06:42<03:04,  6.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▊   | 2574/3750 [06:42<03:03,  6.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▊   | 2576/3750 [06:42<03:03,  6.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▊   | 2578/3750 [06:42<03:03,  6.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2580/3750 [06:42<03:02,  6.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2582/3750 [06:42<03:02,  6.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2584/3750 [06:43<03:01,  6.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2586/3750 [06:43<03:01,  6.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2588/3750 [06:43<03:01,  6.42it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2590/3750 [06:43<03:00,  6.42it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2592/3750 [06:43<03:00,  6.42it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2594/3750 [06:43<02:59,  6.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2596/3750 [06:43<02:59,  6.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2598/3750 [06:43<02:59,  6.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2600/3750 [06:43<02:58,  6.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2602/3750 [06:44<02:58,  6.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2604/3750 [06:44<02:57,  6.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  69%|██████▉   | 2606/3750 [06:44<02:57,  6.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|██████▉   | 2608/3750 [06:44<02:57,  6.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|██████▉   | 2610/3750 [06:44<02:56,  6.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|██████▉   | 2612/3750 [06:44<02:56,  6.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|██████▉   | 2614/3750 [06:44<02:55,  6.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|██████▉   | 2616/3750 [06:44<02:55,  6.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|██████▉   | 2618/3750 [06:44<02:55,  6.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|██████▉   | 2620/3750 [06:45<02:54,  6.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|██████▉   | 2622/3750 [06:45<02:54,  6.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|██████▉   | 2624/3750 [06:45<02:53,  6.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|███████   | 2626/3750 [06:45<02:53,  6.48it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|███████   | 2628/3750 [06:45<02:53,  6.48it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|███████   | 2630/3750 [06:45<02:52,  6.48it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|███████   | 2632/3750 [06:45<02:52,  6.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|███████   | 2634/3750 [06:45<02:51,  6.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|███████   | 2636/3750 [06:45<02:51,  6.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|███████   | 2638/3750 [06:46<02:51,  6.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|███████   | 2640/3750 [06:46<02:50,  6.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  70%|███████   | 2642/3750 [06:46<02:50,  6.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2644/3750 [06:46<02:50,  6.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2646/3750 [06:46<02:49,  6.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2648/3750 [06:46<02:49,  6.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2650/3750 [06:46<02:48,  6.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2652/3750 [06:46<02:48,  6.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2654/3750 [06:46<02:48,  6.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2656/3750 [06:47<02:47,  6.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2658/3750 [06:47<02:47,  6.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2660/3750 [06:47<02:46,  6.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2662/3750 [06:47<02:46,  6.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2664/3750 [06:47<02:46,  6.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2666/3750 [06:47<02:45,  6.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2668/3750 [06:47<02:45,  6.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████   | 2670/3750 [06:47<02:44,  6.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████▏  | 2672/3750 [06:47<02:44,  6.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████▏  | 2674/3750 [06:48<02:44,  6.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████▏  | 2676/3750 [06:48<02:43,  6.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████▏  | 2678/3750 [06:48<02:43,  6.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  71%|███████▏  | 2680/3750 [06:48<02:43,  6.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2682/3750 [06:48<02:42,  6.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2684/3750 [06:48<02:42,  6.57it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2686/3750 [06:48<02:41,  6.57it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2688/3750 [06:48<02:41,  6.57it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2690/3750 [06:49<02:41,  6.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2692/3750 [06:49<02:40,  6.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2694/3750 [06:49<02:40,  6.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2696/3750 [06:49<02:40,  6.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2698/3750 [06:49<02:39,  6.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2700/3750 [06:49<02:39,  6.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2702/3750 [06:49<02:38,  6.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2704/3750 [06:49<02:38,  6.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2706/3750 [06:49<02:38,  6.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2708/3750 [06:50<02:37,  6.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2710/3750 [06:50<02:37,  6.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2712/3750 [06:50<02:37,  6.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2714/3750 [06:50<02:36,  6.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2716/3750 [06:50<02:36,  6.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  72%|███████▏  | 2718/3750 [06:50<02:35,  6.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2720/3750 [06:50<02:35,  6.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2722/3750 [06:50<02:35,  6.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2724/3750 [06:50<02:34,  6.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2726/3750 [06:51<02:34,  6.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2728/3750 [06:51<02:34,  6.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2730/3750 [06:51<02:33,  6.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2732/3750 [06:51<02:33,  6.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2734/3750 [06:51<02:32,  6.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2736/3750 [06:51<02:32,  6.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2738/3750 [06:51<02:32,  6.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2740/3750 [06:51<02:31,  6.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2742/3750 [06:51<02:31,  6.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2744/3750 [06:52<02:31,  6.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2746/3750 [06:52<02:30,  6.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2748/3750 [06:52<02:30,  6.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2750/3750 [06:52<02:29,  6.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2752/3750 [06:52<02:29,  6.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2754/3750 [06:52<02:29,  6.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  73%|███████▎  | 2756/3750 [06:52<02:28,  6.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▎  | 2758/3750 [06:52<02:28,  6.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▎  | 2760/3750 [06:52<02:28,  6.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▎  | 2762/3750 [06:53<02:27,  6.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▎  | 2764/3750 [06:53<02:27,  6.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2766/3750 [06:53<02:27,  6.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2768/3750 [06:53<02:26,  6.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2770/3750 [06:53<02:26,  6.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2772/3750 [06:53<02:25,  6.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2774/3750 [06:53<02:25,  6.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2776/3750 [06:53<02:25,  6.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2778/3750 [06:53<02:24,  6.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2780/3750 [06:54<02:24,  6.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2782/3750 [06:54<02:24,  6.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2784/3750 [06:54<02:23,  6.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2786/3750 [06:54<02:23,  6.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2788/3750 [06:54<02:23,  6.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2790/3750 [06:54<02:22,  6.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  74%|███████▍  | 2792/3750 [06:54<02:22,  6.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▍  | 2794/3750 [06:54<02:21,  6.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▍  | 2796/3750 [06:55<02:21,  6.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▍  | 2798/3750 [06:55<02:21,  6.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▍  | 2800/3750 [06:55<02:20,  6.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▍  | 2802/3750 [06:55<02:20,  6.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▍  | 2804/3750 [06:55<02:20,  6.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▍  | 2806/3750 [06:55<02:19,  6.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▍  | 2808/3750 [06:55<02:19,  6.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▍  | 2810/3750 [06:55<02:19,  6.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▍  | 2812/3750 [06:55<02:18,  6.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▌  | 2814/3750 [06:56<02:18,  6.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▌  | 2816/3750 [06:56<02:18,  6.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▌  | 2818/3750 [06:56<02:17,  6.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▌  | 2820/3750 [06:56<02:17,  6.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▌  | 2822/3750 [06:56<02:16,  6.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▌  | 2824/3750 [06:56<02:16,  6.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▌  | 2826/3750 [06:56<02:16,  6.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▌  | 2828/3750 [06:56<02:15,  6.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  75%|███████▌  | 2830/3750 [06:56<02:15,  6.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2832/3750 [06:57<02:15,  6.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2834/3750 [06:57<02:14,  6.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2836/3750 [06:57<02:14,  6.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2838/3750 [06:57<02:14,  6.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2840/3750 [06:57<02:13,  6.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2842/3750 [06:57<02:13,  6.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2844/3750 [06:57<02:13,  6.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2846/3750 [06:57<02:12,  6.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2848/3750 [06:57<02:12,  6.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2850/3750 [06:58<02:12,  6.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2852/3750 [06:58<02:11,  6.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2854/3750 [06:58<02:11,  6.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2856/3750 [06:58<02:10,  6.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▌  | 2858/3750 [06:58<02:10,  6.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▋  | 2860/3750 [06:58<02:10,  6.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▋  | 2862/3750 [06:58<02:09,  6.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▋  | 2864/3750 [06:58<02:09,  6.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▋  | 2866/3750 [06:58<02:09,  6.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  76%|███████▋  | 2868/3750 [06:59<02:08,  6.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2870/3750 [06:59<02:08,  6.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2872/3750 [06:59<02:08,  6.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2874/3750 [06:59<02:07,  6.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2876/3750 [06:59<02:07,  6.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2878/3750 [06:59<02:07,  6.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2880/3750 [06:59<02:06,  6.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2882/3750 [06:59<02:06,  6.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2884/3750 [06:59<02:06,  6.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2886/3750 [07:00<02:05,  6.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2888/3750 [07:00<02:05,  6.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2890/3750 [07:00<02:05,  6.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2892/3750 [07:00<02:04,  6.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2894/3750 [07:00<02:04,  6.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2896/3750 [07:00<02:04,  6.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2898/3750 [07:00<02:03,  6.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2900/3750 [07:00<02:03,  6.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2902/3750 [07:00<02:03,  6.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2904/3750 [07:01<02:02,  6.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  77%|███████▋  | 2906/3750 [07:01<02:02,  6.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2908/3750 [07:01<02:01,  6.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2910/3750 [07:01<02:01,  6.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2912/3750 [07:01<02:01,  6.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2914/3750 [07:01<02:00,  6.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2916/3750 [07:01<02:00,  6.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2918/3750 [07:01<02:00,  6.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2920/3750 [07:02<01:59,  6.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2922/3750 [07:02<01:59,  6.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2924/3750 [07:02<01:59,  6.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2926/3750 [07:02<01:58,  6.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2928/3750 [07:02<01:58,  6.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2930/3750 [07:02<01:58,  6.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2932/3750 [07:02<01:57,  6.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2934/3750 [07:02<01:57,  6.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2936/3750 [07:02<01:57,  6.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2938/3750 [07:03<01:56,  6.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2940/3750 [07:03<01:56,  6.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 2942/3750 [07:03<01:56,  6.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▊  | 2944/3750 [07:03<01:55,  6.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▊  | 2946/3750 [07:03<01:55,  6.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▊  | 2948/3750 [07:03<01:55,  6.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▊  | 2950/3750 [07:03<01:54,  6.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▊  | 2952/3750 [07:03<01:54,  6.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2954/3750 [07:03<01:54,  6.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2956/3750 [07:04<01:53,  6.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2958/3750 [07:04<01:53,  6.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2960/3750 [07:04<01:53,  6.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2962/3750 [07:04<01:52,  6.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2964/3750 [07:04<01:52,  6.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2966/3750 [07:04<01:52,  6.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2968/3750 [07:04<01:51,  6.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2970/3750 [07:04<01:51,  6.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2972/3750 [07:04<01:51,  6.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2974/3750 [07:05<01:50,  7.00it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2976/3750 [07:05<01:50,  7.00it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2978/3750 [07:05<01:50,  7.00it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  79%|███████▉  | 2980/3750 [07:05<01:49,  7.01it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|███████▉  | 2982/3750 [07:05<01:49,  7.01it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|███████▉  | 2984/3750 [07:05<01:49,  7.01it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|███████▉  | 2986/3750 [07:05<01:48,  7.01it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|███████▉  | 2988/3750 [07:05<01:48,  7.02it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|███████▉  | 2990/3750 [07:05<01:48,  7.02it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|███████▉  | 2992/3750 [07:06<01:47,  7.02it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|███████▉  | 2994/3750 [07:06<01:47,  7.02it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|███████▉  | 2996/3750 [07:06<01:47,  7.03it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|███████▉  | 2998/3750 [07:06<01:46,  7.03it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|████████  | 3000/3750 [07:06<01:46,  7.03it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|████████  | 3002/3750 [07:06<01:46,  7.04it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|████████  | 3004/3750 [07:06<01:45,  7.04it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|████████  | 3006/3750 [07:06<01:45,  7.04it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|████████  | 3008/3750 [07:06<01:45,  7.04it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|████████  | 3010/3750 [07:07<01:45,  7.05it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|████████  | 3012/3750 [07:07<01:44,  7.05it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|████████  | 3014/3750 [07:07<01:44,  7.05it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|████████  | 3016/3750 [07:07<01:44,  7.06it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  80%|████████  | 3018/3750 [07:07<01:43,  7.06it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3020/3750 [07:07<01:43,  7.06it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3022/3750 [07:07<01:43,  7.06it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3024/3750 [07:07<01:42,  7.07it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3026/3750 [07:08<01:42,  7.07it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3028/3750 [07:08<01:42,  7.07it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3030/3750 [07:08<01:41,  7.08it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3032/3750 [07:08<01:41,  7.08it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3034/3750 [07:08<01:41,  7.08it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3036/3750 [07:08<01:40,  7.08it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3038/3750 [07:08<01:40,  7.09it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3040/3750 [07:08<01:40,  7.09it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3042/3750 [07:08<01:39,  7.09it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3044/3750 [07:09<01:39,  7.10it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████  | 3046/3750 [07:09<01:39,  7.10it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████▏ | 3048/3750 [07:09<01:38,  7.10it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████▏ | 3050/3750 [07:09<01:38,  7.10it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████▏ | 3052/3750 [07:09<01:38,  7.11it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████▏ | 3054/3750 [07:09<01:37,  7.11it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  81%|████████▏ | 3056/3750 [07:09<01:37,  7.11it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3058/3750 [07:09<01:37,  7.11it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3060/3750 [07:09<01:36,  7.12it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3062/3750 [07:10<01:36,  7.12it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3064/3750 [07:10<01:36,  7.12it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3066/3750 [07:10<01:35,  7.13it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3068/3750 [07:10<01:35,  7.13it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3070/3750 [07:10<01:35,  7.13it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3072/3750 [07:10<01:35,  7.13it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3074/3750 [07:10<01:34,  7.14it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3076/3750 [07:10<01:34,  7.14it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3078/3750 [07:10<01:34,  7.14it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3080/3750 [07:11<01:33,  7.15it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3082/3750 [07:11<01:33,  7.15it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3084/3750 [07:11<01:33,  7.15it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3086/3750 [07:11<01:32,  7.15it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3088/3750 [07:11<01:32,  7.16it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3090/3750 [07:11<01:32,  7.16it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 3092/3750 [07:11<01:31,  7.16it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3094/3750 [07:11<01:31,  7.16it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3096/3750 [07:11<01:31,  7.17it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3098/3750 [07:12<01:30,  7.17it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3100/3750 [07:12<01:30,  7.17it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3102/3750 [07:12<01:30,  7.18it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3104/3750 [07:12<01:29,  7.18it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3106/3750 [07:12<01:29,  7.18it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3108/3750 [07:12<01:29,  7.18it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3110/3750 [07:12<01:29,  7.19it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3112/3750 [07:12<01:28,  7.19it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3114/3750 [07:12<01:28,  7.19it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3116/3750 [07:13<01:28,  7.19it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3118/3750 [07:13<01:27,  7.20it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3120/3750 [07:13<01:27,  7.20it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3122/3750 [07:13<01:27,  7.20it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3124/3750 [07:13<01:26,  7.21it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3126/3750 [07:13<01:26,  7.21it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3128/3750 [07:13<01:26,  7.21it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 3130/3750 [07:13<01:25,  7.21it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▎ | 3132/3750 [07:13<01:25,  7.22it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▎ | 3134/3750 [07:14<01:25,  7.22it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▎ | 3136/3750 [07:14<01:25,  7.22it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▎ | 3138/3750 [07:14<01:24,  7.22it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▎ | 3140/3750 [07:14<01:24,  7.23it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3142/3750 [07:14<01:24,  7.23it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3144/3750 [07:14<01:23,  7.23it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3146/3750 [07:14<01:23,  7.24it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3148/3750 [07:14<01:23,  7.24it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3150/3750 [07:15<01:22,  7.24it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3152/3750 [07:15<01:22,  7.24it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3154/3750 [07:15<01:22,  7.25it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3156/3750 [07:15<01:21,  7.25it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3158/3750 [07:15<01:21,  7.25it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3160/3750 [07:15<01:21,  7.25it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3162/3750 [07:15<01:21,  7.26it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3164/3750 [07:15<01:20,  7.26it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3166/3750 [07:15<01:20,  7.26it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  84%|████████▍ | 3168/3750 [07:16<01:20,  7.27it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▍ | 3170/3750 [07:16<01:19,  7.27it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▍ | 3172/3750 [07:16<01:19,  7.27it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▍ | 3174/3750 [07:16<01:19,  7.27it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▍ | 3176/3750 [07:16<01:18,  7.28it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▍ | 3178/3750 [07:16<01:18,  7.28it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▍ | 3180/3750 [07:16<01:18,  7.28it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▍ | 3182/3750 [07:16<01:17,  7.28it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▍ | 3184/3750 [07:16<01:17,  7.29it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▍ | 3186/3750 [07:17<01:17,  7.29it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▌ | 3188/3750 [07:17<01:17,  7.29it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▌ | 3190/3750 [07:17<01:16,  7.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▌ | 3192/3750 [07:17<01:16,  7.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▌ | 3194/3750 [07:17<01:16,  7.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▌ | 3196/3750 [07:17<01:15,  7.30it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▌ | 3198/3750 [07:17<01:15,  7.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▌ | 3200/3750 [07:17<01:15,  7.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▌ | 3202/3750 [07:17<01:14,  7.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▌ | 3204/3750 [07:18<01:14,  7.31it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  85%|████████▌ | 3206/3750 [07:18<01:14,  7.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3208/3750 [07:18<01:14,  7.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3210/3750 [07:18<01:13,  7.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3212/3750 [07:18<01:13,  7.32it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3214/3750 [07:18<01:13,  7.33it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3216/3750 [07:18<01:12,  7.33it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3218/3750 [07:18<01:12,  7.33it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3220/3750 [07:18<01:12,  7.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3222/3750 [07:19<01:11,  7.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3224/3750 [07:19<01:11,  7.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3226/3750 [07:19<01:11,  7.34it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3228/3750 [07:19<01:11,  7.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3230/3750 [07:19<01:10,  7.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3232/3750 [07:19<01:10,  7.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▌ | 3234/3750 [07:19<01:10,  7.35it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▋ | 3236/3750 [07:19<01:09,  7.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▋ | 3238/3750 [07:19<01:09,  7.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▋ | 3240/3750 [07:20<01:09,  7.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  86%|████████▋ | 3242/3750 [07:20<01:08,  7.36it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3244/3750 [07:20<01:08,  7.37it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3246/3750 [07:20<01:08,  7.37it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3248/3750 [07:20<01:08,  7.37it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3250/3750 [07:20<01:07,  7.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3252/3750 [07:20<01:07,  7.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3254/3750 [07:20<01:07,  7.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3256/3750 [07:21<01:06,  7.38it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3258/3750 [07:21<01:06,  7.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3260/3750 [07:21<01:06,  7.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3262/3750 [07:21<01:06,  7.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3264/3750 [07:21<01:05,  7.39it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3266/3750 [07:21<01:05,  7.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3268/3750 [07:21<01:05,  7.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3270/3750 [07:21<01:04,  7.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3272/3750 [07:21<01:04,  7.40it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3274/3750 [07:22<01:04,  7.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3276/3750 [07:22<01:03,  7.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3278/3750 [07:22<01:03,  7.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 3280/3750 [07:22<01:03,  7.41it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3282/3750 [07:22<01:03,  7.42it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3284/3750 [07:22<01:02,  7.42it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3286/3750 [07:22<01:02,  7.42it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3288/3750 [07:22<01:02,  7.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3290/3750 [07:22<01:01,  7.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3292/3750 [07:23<01:01,  7.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3294/3750 [07:23<01:01,  7.43it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3296/3750 [07:23<01:01,  7.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3298/3750 [07:23<01:00,  7.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3300/3750 [07:23<01:00,  7.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3302/3750 [07:23<01:00,  7.44it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3304/3750 [07:23<00:59,  7.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3306/3750 [07:23<00:59,  7.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3308/3750 [07:23<00:59,  7.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3310/3750 [07:24<00:59,  7.45it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3312/3750 [07:24<00:58,  7.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3314/3750 [07:24<00:58,  7.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3316/3750 [07:24<00:58,  7.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 3318/3750 [07:24<00:57,  7.46it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▊ | 3320/3750 [07:24<00:57,  7.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▊ | 3322/3750 [07:24<00:57,  7.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▊ | 3324/3750 [07:24<00:57,  7.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▊ | 3326/3750 [07:24<00:56,  7.47it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▊ | 3328/3750 [07:25<00:56,  7.48it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3330/3750 [07:25<00:56,  7.48it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3332/3750 [07:25<00:55,  7.48it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3334/3750 [07:25<00:55,  7.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3336/3750 [07:25<00:55,  7.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3338/3750 [07:25<00:55,  7.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3340/3750 [07:25<00:54,  7.49it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3342/3750 [07:25<00:54,  7.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3344/3750 [07:25<00:54,  7.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3346/3750 [07:26<00:53,  7.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3348/3750 [07:26<00:53,  7.50it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3350/3750 [07:26<00:53,  7.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3352/3750 [07:26<00:53,  7.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3354/3750 [07:26<00:52,  7.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  89%|████████▉ | 3356/3750 [07:26<00:52,  7.51it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|████████▉ | 3358/3750 [07:26<00:52,  7.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|████████▉ | 3360/3750 [07:26<00:51,  7.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|████████▉ | 3362/3750 [07:26<00:51,  7.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|████████▉ | 3364/3750 [07:27<00:51,  7.52it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|████████▉ | 3366/3750 [07:27<00:51,  7.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|████████▉ | 3368/3750 [07:27<00:50,  7.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|████████▉ | 3370/3750 [07:27<00:50,  7.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|████████▉ | 3372/3750 [07:27<00:50,  7.53it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|████████▉ | 3374/3750 [07:27<00:49,  7.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|█████████ | 3376/3750 [07:27<00:49,  7.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|█████████ | 3378/3750 [07:27<00:49,  7.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|█████████ | 3380/3750 [07:28<00:49,  7.54it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|█████████ | 3382/3750 [07:28<00:48,  7.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|█████████ | 3384/3750 [07:28<00:48,  7.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|█████████ | 3386/3750 [07:28<00:48,  7.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|█████████ | 3388/3750 [07:28<00:47,  7.55it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|█████████ | 3390/3750 [07:28<00:47,  7.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  90%|█████████ | 3392/3750 [07:28<00:47,  7.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3394/3750 [07:28<00:47,  7.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3396/3750 [07:28<00:46,  7.56it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3398/3750 [07:29<00:46,  7.57it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3400/3750 [07:29<00:46,  7.57it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3402/3750 [07:29<00:45,  7.57it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3404/3750 [07:29<00:45,  7.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3406/3750 [07:29<00:45,  7.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3408/3750 [07:29<00:45,  7.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3410/3750 [07:29<00:44,  7.58it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3412/3750 [07:29<00:44,  7.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3414/3750 [07:29<00:44,  7.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3416/3750 [07:30<00:44,  7.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3418/3750 [07:30<00:43,  7.59it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████ | 3420/3750 [07:30<00:43,  7.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████▏| 3422/3750 [07:30<00:43,  7.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████▏| 3424/3750 [07:30<00:42,  7.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████▏| 3426/3750 [07:30<00:42,  7.60it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████▏| 3428/3750 [07:30<00:42,  7.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  91%|█████████▏| 3430/3750 [07:30<00:42,  7.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3432/3750 [07:30<00:41,  7.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3434/3750 [07:31<00:41,  7.61it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3436/3750 [07:31<00:41,  7.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3438/3750 [07:31<00:40,  7.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3440/3750 [07:31<00:40,  7.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3442/3750 [07:31<00:40,  7.62it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3444/3750 [07:31<00:40,  7.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3446/3750 [07:31<00:39,  7.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3448/3750 [07:31<00:39,  7.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3450/3750 [07:31<00:39,  7.63it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3452/3750 [07:32<00:39,  7.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3454/3750 [07:32<00:38,  7.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3456/3750 [07:32<00:38,  7.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3458/3750 [07:32<00:38,  7.64it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3460/3750 [07:32<00:37,  7.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3462/3750 [07:32<00:37,  7.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3464/3750 [07:32<00:37,  7.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3466/3750 [07:32<00:37,  7.65it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 3468/3750 [07:32<00:36,  7.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3470/3750 [07:33<00:36,  7.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3472/3750 [07:33<00:36,  7.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3474/3750 [07:33<00:36,  7.66it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3476/3750 [07:33<00:35,  7.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3478/3750 [07:33<00:35,  7.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3480/3750 [07:33<00:35,  7.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3482/3750 [07:33<00:34,  7.67it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3484/3750 [07:33<00:34,  7.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3486/3750 [07:33<00:34,  7.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3488/3750 [07:34<00:34,  7.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3490/3750 [07:34<00:33,  7.68it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3492/3750 [07:34<00:33,  7.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3494/3750 [07:34<00:33,  7.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3496/3750 [07:34<00:33,  7.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3498/3750 [07:34<00:32,  7.69it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3500/3750 [07:34<00:32,  7.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3502/3750 [07:34<00:32,  7.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3504/3750 [07:35<00:31,  7.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  93%|█████████▎| 3506/3750 [07:35<00:31,  7.70it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▎| 3508/3750 [07:35<00:31,  7.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▎| 3510/3750 [07:35<00:31,  7.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▎| 3512/3750 [07:35<00:30,  7.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▎| 3514/3750 [07:35<00:30,  7.71it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3516/3750 [07:35<00:30,  7.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3518/3750 [07:35<00:30,  7.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3520/3750 [07:35<00:29,  7.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3522/3750 [07:36<00:29,  7.72it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3524/3750 [07:36<00:29,  7.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3526/3750 [07:36<00:28,  7.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3528/3750 [07:36<00:28,  7.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3530/3750 [07:36<00:28,  7.73it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3532/3750 [07:36<00:28,  7.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3534/3750 [07:36<00:27,  7.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3536/3750 [07:36<00:27,  7.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3538/3750 [07:36<00:27,  7.74it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3540/3750 [07:37<00:27,  7.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 3542/3750 [07:37<00:26,  7.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▍| 3544/3750 [07:37<00:26,  7.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▍| 3546/3750 [07:37<00:26,  7.75it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▍| 3548/3750 [07:37<00:26,  7.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▍| 3550/3750 [07:37<00:25,  7.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▍| 3552/3750 [07:37<00:25,  7.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▍| 3554/3750 [07:37<00:25,  7.76it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▍| 3556/3750 [07:37<00:24,  7.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▍| 3558/3750 [07:38<00:24,  7.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▍| 3560/3750 [07:38<00:24,  7.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▍| 3562/3750 [07:38<00:24,  7.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▌| 3564/3750 [07:38<00:23,  7.77it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▌| 3566/3750 [07:38<00:23,  7.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▌| 3568/3750 [07:38<00:23,  7.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▌| 3570/3750 [07:38<00:23,  7.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▌| 3572/3750 [07:38<00:22,  7.78it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▌| 3574/3750 [07:38<00:22,  7.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▌| 3576/3750 [07:39<00:22,  7.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▌| 3578/3750 [07:39<00:22,  7.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  95%|█████████▌| 3580/3750 [07:39<00:21,  7.79it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3582/3750 [07:39<00:21,  7.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3584/3750 [07:39<00:21,  7.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3586/3750 [07:39<00:21,  7.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3588/3750 [07:39<00:20,  7.80it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3590/3750 [07:39<00:20,  7.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3592/3750 [07:39<00:20,  7.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3594/3750 [07:40<00:19,  7.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3596/3750 [07:40<00:19,  7.81it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3598/3750 [07:40<00:19,  7.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3600/3750 [07:40<00:19,  7.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3602/3750 [07:40<00:18,  7.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3604/3750 [07:40<00:18,  7.82it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3606/3750 [07:40<00:18,  7.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▌| 3608/3750 [07:40<00:18,  7.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▋| 3610/3750 [07:40<00:17,  7.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▋| 3612/3750 [07:41<00:17,  7.83it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▋| 3614/3750 [07:41<00:17,  7.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▋| 3616/3750 [07:41<00:17,  7.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  96%|█████████▋| 3618/3750 [07:41<00:16,  7.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3620/3750 [07:41<00:16,  7.84it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3622/3750 [07:41<00:16,  7.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3624/3750 [07:41<00:16,  7.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3626/3750 [07:41<00:15,  7.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3628/3750 [07:42<00:15,  7.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3630/3750 [07:42<00:15,  7.85it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3632/3750 [07:42<00:15,  7.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3634/3750 [07:42<00:14,  7.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3636/3750 [07:42<00:14,  7.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3638/3750 [07:42<00:14,  7.86it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3640/3750 [07:42<00:13,  7.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3642/3750 [07:42<00:13,  7.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3644/3750 [07:42<00:13,  7.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3646/3750 [07:43<00:13,  7.87it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3648/3750 [07:43<00:12,  7.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3650/3750 [07:43<00:12,  7.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3652/3750 [07:43<00:12,  7.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3654/3750 [07:43<00:12,  7.88it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 3656/3750 [07:43<00:11,  7.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3658/3750 [07:43<00:11,  7.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3660/3750 [07:43<00:11,  7.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3662/3750 [07:43<00:11,  7.89it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3664/3750 [07:44<00:10,  7.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3666/3750 [07:44<00:10,  7.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3668/3750 [07:44<00:10,  7.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3670/3750 [07:44<00:10,  7.90it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3672/3750 [07:44<00:09,  7.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3674/3750 [07:44<00:09,  7.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3676/3750 [07:44<00:09,  7.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3678/3750 [07:44<00:09,  7.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3680/3750 [07:44<00:08,  7.91it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3682/3750 [07:45<00:08,  7.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3684/3750 [07:45<00:08,  7.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3686/3750 [07:45<00:08,  7.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3688/3750 [07:45<00:07,  7.92it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3690/3750 [07:45<00:07,  7.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3692/3750 [07:45<00:07,  7.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▊| 3694/3750 [07:45<00:07,  7.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▊| 3696/3750 [07:45<00:06,  7.93it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▊| 3698/3750 [07:45<00:06,  7.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▊| 3700/3750 [07:46<00:06,  7.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▊| 3702/3750 [07:46<00:06,  7.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3704/3750 [07:46<00:05,  7.94it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3706/3750 [07:46<00:05,  7.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3708/3750 [07:46<00:05,  7.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3710/3750 [07:46<00:05,  7.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3712/3750 [07:46<00:04,  7.95it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3714/3750 [07:46<00:04,  7.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3716/3750 [07:46<00:04,  7.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3718/3750 [07:47<00:04,  7.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3720/3750 [07:47<00:03,  7.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3722/3750 [07:47<00:03,  7.96it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3724/3750 [07:47<00:03,  7.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3726/3750 [07:47<00:03,  7.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3728/3750 [07:47<00:02,  7.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3730/3750 [07:47<00:02,  7.97it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3732/3750 [07:47<00:02,  7.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3734/3750 [07:48<00:02,  7.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3736/3750 [07:48<00:01,  7.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3738/3750 [07:48<00:01,  7.98it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3740/3750 [07:48<00:01,  7.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3742/3750 [07:48<00:01,  7.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3744/3750 [07:48<00:00,  7.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3746/3750 [07:48<00:00,  7.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3748/3750 [07:48<00:00,  7.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 1: 100%|██████████| 3750/3750 [07:49<00:00,  7.99it/s, loss=0.125, v_num=0]\n",
      "Epoch 2:   0%|          | 0/3750 [00:00<?, ?it/s, loss=0.125, v_num=0]           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  67%|██████▋   | 2500/3750 [06:38<03:19,  6.28it/s, loss=0.0849, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1250 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2:  67%|██████▋   | 2502/3750 [06:38<03:18,  6.28it/s, loss=0.0849, v_num=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  67%|██████▋   | 2504/3750 [06:38<03:18,  6.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|██████▋   | 2506/3750 [06:38<03:17,  6.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|██████▋   | 2508/3750 [06:38<03:17,  6.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|██████▋   | 2510/3750 [06:38<03:16,  6.30it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|██████▋   | 2512/3750 [06:38<03:16,  6.30it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|██████▋   | 2514/3750 [06:38<03:16,  6.30it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|██████▋   | 2516/3750 [06:39<03:15,  6.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|██████▋   | 2518/3750 [06:39<03:15,  6.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|██████▋   | 2520/3750 [06:39<03:14,  6.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|██████▋   | 2522/3750 [06:39<03:14,  6.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|██████▋   | 2524/3750 [06:39<03:14,  6.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|██████▋   | 2526/3750 [06:39<03:13,  6.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|██████▋   | 2528/3750 [06:39<03:13,  6.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  67%|██████▋   | 2530/3750 [06:39<03:12,  6.33it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2532/3750 [06:39<03:12,  6.33it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2534/3750 [06:40<03:11,  6.33it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2536/3750 [06:40<03:11,  6.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2538/3750 [06:40<03:11,  6.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2540/3750 [06:40<03:10,  6.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2542/3750 [06:40<03:10,  6.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2544/3750 [06:40<03:09,  6.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2546/3750 [06:40<03:09,  6.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2548/3750 [06:40<03:09,  6.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2550/3750 [06:40<03:08,  6.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2552/3750 [06:41<03:08,  6.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2554/3750 [06:41<03:07,  6.37it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2556/3750 [06:41<03:07,  6.37it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2558/3750 [06:41<03:07,  6.37it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2560/3750 [06:41<03:06,  6.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2562/3750 [06:41<03:06,  6.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2564/3750 [06:41<03:05,  6.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2566/3750 [06:41<03:05,  6.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  68%|██████▊   | 2568/3750 [06:41<03:05,  6.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▊   | 2570/3750 [06:42<03:04,  6.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▊   | 2572/3750 [06:42<03:04,  6.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▊   | 2574/3750 [06:42<03:03,  6.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▊   | 2576/3750 [06:42<03:03,  6.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▊   | 2578/3750 [06:42<03:03,  6.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2580/3750 [06:42<03:02,  6.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2582/3750 [06:42<03:02,  6.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2584/3750 [06:42<03:01,  6.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2586/3750 [06:42<03:01,  6.42it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2588/3750 [06:43<03:00,  6.42it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2590/3750 [06:43<03:00,  6.42it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2592/3750 [06:43<03:00,  6.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2594/3750 [06:43<02:59,  6.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2596/3750 [06:43<02:59,  6.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2598/3750 [06:43<02:58,  6.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2600/3750 [06:43<02:58,  6.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2602/3750 [06:43<02:58,  6.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2604/3750 [06:44<02:57,  6.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  69%|██████▉   | 2606/3750 [06:44<02:57,  6.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|██████▉   | 2608/3750 [06:44<02:57,  6.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|██████▉   | 2610/3750 [06:44<02:56,  6.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|██████▉   | 2612/3750 [06:44<02:56,  6.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|██████▉   | 2614/3750 [06:44<02:55,  6.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|██████▉   | 2616/3750 [06:44<02:55,  6.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|██████▉   | 2618/3750 [06:44<02:55,  6.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|██████▉   | 2620/3750 [06:44<02:54,  6.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|██████▉   | 2622/3750 [06:45<02:54,  6.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|██████▉   | 2624/3750 [06:45<02:53,  6.48it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|███████   | 2626/3750 [06:45<02:53,  6.48it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|███████   | 2628/3750 [06:45<02:53,  6.48it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|███████   | 2630/3750 [06:45<02:52,  6.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|███████   | 2632/3750 [06:45<02:52,  6.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|███████   | 2634/3750 [06:45<02:51,  6.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|███████   | 2636/3750 [06:45<02:51,  6.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|███████   | 2638/3750 [06:45<02:51,  6.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|███████   | 2640/3750 [06:46<02:50,  6.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  70%|███████   | 2642/3750 [06:46<02:50,  6.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2644/3750 [06:46<02:49,  6.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2646/3750 [06:46<02:49,  6.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2648/3750 [06:46<02:49,  6.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2650/3750 [06:46<02:48,  6.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2652/3750 [06:46<02:48,  6.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2654/3750 [06:46<02:48,  6.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2656/3750 [06:46<02:47,  6.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2658/3750 [06:47<02:47,  6.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2660/3750 [06:47<02:46,  6.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2662/3750 [06:47<02:46,  6.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2664/3750 [06:47<02:46,  6.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2666/3750 [06:47<02:45,  6.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2668/3750 [06:47<02:45,  6.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████   | 2670/3750 [06:47<02:44,  6.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████▏  | 2672/3750 [06:47<02:44,  6.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████▏  | 2674/3750 [06:47<02:44,  6.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████▏  | 2676/3750 [06:48<02:43,  6.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████▏  | 2678/3750 [06:48<02:43,  6.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  71%|███████▏  | 2680/3750 [06:48<02:43,  6.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2682/3750 [06:48<02:42,  6.57it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2684/3750 [06:48<02:42,  6.57it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2686/3750 [06:48<02:41,  6.57it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2688/3750 [06:48<02:41,  6.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2690/3750 [06:48<02:41,  6.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2692/3750 [06:48<02:40,  6.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2694/3750 [06:49<02:40,  6.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2696/3750 [06:49<02:39,  6.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2698/3750 [06:49<02:39,  6.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2700/3750 [06:49<02:39,  6.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2702/3750 [06:49<02:38,  6.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2704/3750 [06:49<02:38,  6.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2706/3750 [06:49<02:38,  6.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2708/3750 [06:49<02:37,  6.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2710/3750 [06:50<02:37,  6.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2712/3750 [06:50<02:36,  6.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2714/3750 [06:50<02:36,  6.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2716/3750 [06:50<02:36,  6.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  72%|███████▏  | 2718/3750 [06:50<02:35,  6.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2720/3750 [06:50<02:35,  6.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2722/3750 [06:50<02:35,  6.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2724/3750 [06:50<02:34,  6.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2726/3750 [06:50<02:34,  6.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2728/3750 [06:51<02:33,  6.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2730/3750 [06:51<02:33,  6.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2732/3750 [06:51<02:33,  6.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2734/3750 [06:51<02:32,  6.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2736/3750 [06:51<02:32,  6.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2738/3750 [06:51<02:32,  6.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2740/3750 [06:51<02:31,  6.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2742/3750 [06:51<02:31,  6.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2744/3750 [06:51<02:31,  6.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2746/3750 [06:52<02:30,  6.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2748/3750 [06:52<02:30,  6.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2750/3750 [06:52<02:29,  6.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2752/3750 [06:52<02:29,  6.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2754/3750 [06:52<02:29,  6.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  73%|███████▎  | 2756/3750 [06:52<02:28,  6.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▎  | 2758/3750 [06:52<02:28,  6.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▎  | 2760/3750 [06:52<02:28,  6.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▎  | 2762/3750 [06:52<02:27,  6.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▎  | 2764/3750 [06:53<02:27,  6.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2766/3750 [06:53<02:26,  6.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2768/3750 [06:53<02:26,  6.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2770/3750 [06:53<02:26,  6.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2772/3750 [06:53<02:25,  6.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2774/3750 [06:53<02:25,  6.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2776/3750 [06:53<02:25,  6.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2778/3750 [06:53<02:24,  6.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2780/3750 [06:53<02:24,  6.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2782/3750 [06:54<02:24,  6.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2784/3750 [06:54<02:23,  6.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2786/3750 [06:54<02:23,  6.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2788/3750 [06:54<02:22,  6.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2790/3750 [06:54<02:22,  6.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  74%|███████▍  | 2792/3750 [06:54<02:22,  6.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▍  | 2794/3750 [06:54<02:21,  6.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▍  | 2796/3750 [06:54<02:21,  6.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▍  | 2798/3750 [06:54<02:21,  6.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▍  | 2800/3750 [06:55<02:20,  6.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▍  | 2802/3750 [06:55<02:20,  6.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▍  | 2804/3750 [06:55<02:20,  6.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▍  | 2806/3750 [06:55<02:19,  6.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▍  | 2808/3750 [06:55<02:19,  6.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▍  | 2810/3750 [06:55<02:19,  6.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▍  | 2812/3750 [06:55<02:18,  6.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▌  | 2814/3750 [06:55<02:18,  6.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▌  | 2816/3750 [06:55<02:17,  6.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▌  | 2818/3750 [06:56<02:17,  6.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▌  | 2820/3750 [06:56<02:17,  6.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▌  | 2822/3750 [06:56<02:16,  6.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▌  | 2824/3750 [06:56<02:16,  6.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▌  | 2826/3750 [06:56<02:16,  6.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▌  | 2828/3750 [06:56<02:15,  6.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  75%|███████▌  | 2830/3750 [06:56<02:15,  6.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2832/3750 [06:56<02:15,  6.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2834/3750 [06:57<02:14,  6.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2836/3750 [06:57<02:14,  6.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2838/3750 [06:57<02:14,  6.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2840/3750 [06:57<02:13,  6.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2842/3750 [06:57<02:13,  6.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2844/3750 [06:57<02:13,  6.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2846/3750 [06:57<02:12,  6.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2848/3750 [06:57<02:12,  6.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2850/3750 [06:57<02:11,  6.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2852/3750 [06:58<02:11,  6.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2854/3750 [06:58<02:11,  6.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2856/3750 [06:58<02:10,  6.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▌  | 2858/3750 [06:58<02:10,  6.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▋  | 2860/3750 [06:58<02:10,  6.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▋  | 2862/3750 [06:58<02:09,  6.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▋  | 2864/3750 [06:58<02:09,  6.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▋  | 2866/3750 [06:58<02:09,  6.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  76%|███████▋  | 2868/3750 [06:58<02:08,  6.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2870/3750 [06:59<02:08,  6.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2872/3750 [06:59<02:08,  6.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2874/3750 [06:59<02:07,  6.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2876/3750 [06:59<02:07,  6.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2878/3750 [06:59<02:07,  6.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2880/3750 [06:59<02:06,  6.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2882/3750 [06:59<02:06,  6.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2884/3750 [06:59<02:06,  6.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2886/3750 [06:59<02:05,  6.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2888/3750 [07:00<02:05,  6.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2890/3750 [07:00<02:05,  6.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2892/3750 [07:00<02:04,  6.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2894/3750 [07:00<02:04,  6.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2896/3750 [07:00<02:04,  6.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2898/3750 [07:00<02:03,  6.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2900/3750 [07:00<02:03,  6.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2902/3750 [07:00<02:02,  6.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2904/3750 [07:00<02:02,  6.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  77%|███████▋  | 2906/3750 [07:01<02:02,  6.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2908/3750 [07:01<02:01,  6.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2910/3750 [07:01<02:01,  6.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2912/3750 [07:01<02:01,  6.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2914/3750 [07:01<02:00,  6.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2916/3750 [07:01<02:00,  6.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2918/3750 [07:01<02:00,  6.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2920/3750 [07:01<01:59,  6.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2922/3750 [07:01<01:59,  6.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2924/3750 [07:02<01:59,  6.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2926/3750 [07:02<01:58,  6.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2928/3750 [07:02<01:58,  6.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2930/3750 [07:02<01:58,  6.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2932/3750 [07:02<01:57,  6.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2934/3750 [07:02<01:57,  6.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2936/3750 [07:02<01:57,  6.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2938/3750 [07:02<01:56,  6.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2940/3750 [07:02<01:56,  6.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 2942/3750 [07:03<01:56,  6.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▊  | 2944/3750 [07:03<01:55,  6.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▊  | 2946/3750 [07:03<01:55,  6.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▊  | 2948/3750 [07:03<01:55,  6.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▊  | 2950/3750 [07:03<01:54,  6.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▊  | 2952/3750 [07:03<01:54,  6.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2954/3750 [07:03<01:54,  6.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2956/3750 [07:03<01:53,  6.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2958/3750 [07:04<01:53,  6.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2960/3750 [07:04<01:53,  6.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2962/3750 [07:04<01:52,  6.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2964/3750 [07:04<01:52,  6.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2966/3750 [07:04<01:52,  6.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2968/3750 [07:04<01:51,  6.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2970/3750 [07:04<01:51,  6.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2972/3750 [07:04<01:51,  7.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2974/3750 [07:04<01:50,  7.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2976/3750 [07:05<01:50,  7.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2978/3750 [07:05<01:50,  7.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  79%|███████▉  | 2980/3750 [07:05<01:49,  7.01it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|███████▉  | 2982/3750 [07:05<01:49,  7.01it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|███████▉  | 2984/3750 [07:05<01:49,  7.01it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|███████▉  | 2986/3750 [07:05<01:48,  7.02it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|███████▉  | 2988/3750 [07:05<01:48,  7.02it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|███████▉  | 2990/3750 [07:05<01:48,  7.02it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|███████▉  | 2992/3750 [07:05<01:47,  7.02it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|███████▉  | 2994/3750 [07:06<01:47,  7.03it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|███████▉  | 2996/3750 [07:06<01:47,  7.03it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|███████▉  | 2998/3750 [07:06<01:46,  7.03it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|████████  | 3000/3750 [07:06<01:46,  7.04it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|████████  | 3002/3750 [07:06<01:46,  7.04it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|████████  | 3004/3750 [07:06<01:45,  7.04it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|████████  | 3006/3750 [07:06<01:45,  7.04it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|████████  | 3008/3750 [07:06<01:45,  7.05it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|████████  | 3010/3750 [07:06<01:44,  7.05it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|████████  | 3012/3750 [07:07<01:44,  7.05it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|████████  | 3014/3750 [07:07<01:44,  7.06it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|████████  | 3016/3750 [07:07<01:43,  7.06it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  80%|████████  | 3018/3750 [07:07<01:43,  7.06it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3020/3750 [07:07<01:43,  7.06it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3022/3750 [07:07<01:43,  7.07it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3024/3750 [07:07<01:42,  7.07it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3026/3750 [07:07<01:42,  7.07it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3028/3750 [07:07<01:42,  7.08it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3030/3750 [07:08<01:41,  7.08it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3032/3750 [07:08<01:41,  7.08it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3034/3750 [07:08<01:41,  7.08it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3036/3750 [07:08<01:40,  7.09it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3038/3750 [07:08<01:40,  7.09it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3040/3750 [07:08<01:40,  7.09it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3042/3750 [07:08<01:39,  7.09it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3044/3750 [07:08<01:39,  7.10it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████  | 3046/3750 [07:08<01:39,  7.10it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████▏ | 3048/3750 [07:09<01:38,  7.10it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████▏ | 3050/3750 [07:09<01:38,  7.11it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████▏ | 3052/3750 [07:09<01:38,  7.11it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████▏ | 3054/3750 [07:09<01:37,  7.11it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  81%|████████▏ | 3056/3750 [07:09<01:37,  7.11it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3058/3750 [07:09<01:37,  7.12it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3060/3750 [07:09<01:36,  7.12it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3062/3750 [07:09<01:36,  7.12it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3064/3750 [07:10<01:36,  7.13it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3066/3750 [07:10<01:35,  7.13it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3068/3750 [07:10<01:35,  7.13it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3070/3750 [07:10<01:35,  7.13it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3072/3750 [07:10<01:35,  7.14it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3074/3750 [07:10<01:34,  7.14it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3076/3750 [07:10<01:34,  7.14it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3078/3750 [07:10<01:34,  7.14it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3080/3750 [07:10<01:33,  7.15it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3082/3750 [07:11<01:33,  7.15it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3084/3750 [07:11<01:33,  7.15it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3086/3750 [07:11<01:32,  7.16it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3088/3750 [07:11<01:32,  7.16it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3090/3750 [07:11<01:32,  7.16it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  82%|████████▏ | 3092/3750 [07:11<01:31,  7.16it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3094/3750 [07:11<01:31,  7.17it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3096/3750 [07:11<01:31,  7.17it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3098/3750 [07:11<01:30,  7.17it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3100/3750 [07:12<01:30,  7.18it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3102/3750 [07:12<01:30,  7.18it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3104/3750 [07:12<01:29,  7.18it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3106/3750 [07:12<01:29,  7.18it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3108/3750 [07:12<01:29,  7.19it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3110/3750 [07:12<01:29,  7.19it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3112/3750 [07:12<01:28,  7.19it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3114/3750 [07:12<01:28,  7.19it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3116/3750 [07:12<01:28,  7.20it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3118/3750 [07:13<01:27,  7.20it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3120/3750 [07:13<01:27,  7.20it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3122/3750 [07:13<01:27,  7.21it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3124/3750 [07:13<01:26,  7.21it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3126/3750 [07:13<01:26,  7.21it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3128/3750 [07:13<01:26,  7.21it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 3130/3750 [07:13<01:25,  7.22it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▎ | 3132/3750 [07:13<01:25,  7.22it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▎ | 3134/3750 [07:13<01:25,  7.22it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▎ | 3136/3750 [07:14<01:24,  7.22it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▎ | 3138/3750 [07:14<01:24,  7.23it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▎ | 3140/3750 [07:14<01:24,  7.23it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3142/3750 [07:14<01:24,  7.23it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3144/3750 [07:14<01:23,  7.24it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3146/3750 [07:14<01:23,  7.24it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3148/3750 [07:14<01:23,  7.24it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3150/3750 [07:14<01:22,  7.24it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3152/3750 [07:14<01:22,  7.25it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3154/3750 [07:15<01:22,  7.25it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3156/3750 [07:15<01:21,  7.25it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3158/3750 [07:15<01:21,  7.25it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3160/3750 [07:15<01:21,  7.26it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3162/3750 [07:15<01:20,  7.26it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3164/3750 [07:15<01:20,  7.26it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3166/3750 [07:15<01:20,  7.27it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  84%|████████▍ | 3168/3750 [07:15<01:20,  7.27it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▍ | 3170/3750 [07:15<01:19,  7.27it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▍ | 3172/3750 [07:16<01:19,  7.27it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▍ | 3174/3750 [07:16<01:19,  7.28it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▍ | 3176/3750 [07:16<01:18,  7.28it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▍ | 3178/3750 [07:16<01:18,  7.28it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▍ | 3180/3750 [07:16<01:18,  7.28it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▍ | 3182/3750 [07:16<01:17,  7.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▍ | 3184/3750 [07:16<01:17,  7.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▍ | 3186/3750 [07:16<01:17,  7.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▌ | 3188/3750 [07:17<01:17,  7.29it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▌ | 3190/3750 [07:17<01:16,  7.30it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▌ | 3192/3750 [07:17<01:16,  7.30it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▌ | 3194/3750 [07:17<01:16,  7.30it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▌ | 3196/3750 [07:17<01:15,  7.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▌ | 3198/3750 [07:17<01:15,  7.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▌ | 3200/3750 [07:17<01:15,  7.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▌ | 3202/3750 [07:17<01:14,  7.31it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▌ | 3204/3750 [07:17<01:14,  7.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  85%|████████▌ | 3206/3750 [07:18<01:14,  7.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3208/3750 [07:18<01:14,  7.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3210/3750 [07:18<01:13,  7.32it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3212/3750 [07:18<01:13,  7.33it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3214/3750 [07:18<01:13,  7.33it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3216/3750 [07:18<01:12,  7.33it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3218/3750 [07:18<01:12,  7.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3220/3750 [07:18<01:12,  7.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3222/3750 [07:18<01:11,  7.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3224/3750 [07:19<01:11,  7.34it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3226/3750 [07:19<01:11,  7.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3228/3750 [07:19<01:11,  7.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3230/3750 [07:19<01:10,  7.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3232/3750 [07:19<01:10,  7.35it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▌ | 3234/3750 [07:19<01:10,  7.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▋ | 3236/3750 [07:19<01:09,  7.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▋ | 3238/3750 [07:19<01:09,  7.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▋ | 3240/3750 [07:19<01:09,  7.36it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  86%|████████▋ | 3242/3750 [07:20<01:08,  7.37it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3244/3750 [07:20<01:08,  7.37it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3246/3750 [07:20<01:08,  7.37it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3248/3750 [07:20<01:08,  7.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3250/3750 [07:20<01:07,  7.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3252/3750 [07:20<01:07,  7.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3254/3750 [07:20<01:07,  7.38it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3256/3750 [07:20<01:06,  7.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3258/3750 [07:20<01:06,  7.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3260/3750 [07:21<01:06,  7.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3262/3750 [07:21<01:06,  7.39it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3264/3750 [07:21<01:05,  7.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3266/3750 [07:21<01:05,  7.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3268/3750 [07:21<01:05,  7.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3270/3750 [07:21<01:04,  7.40it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3272/3750 [07:21<01:04,  7.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3274/3750 [07:21<01:04,  7.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3276/3750 [07:21<01:03,  7.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3278/3750 [07:22<01:03,  7.41it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 3280/3750 [07:22<01:03,  7.42it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3282/3750 [07:22<01:03,  7.42it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3284/3750 [07:22<01:02,  7.42it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3286/3750 [07:22<01:02,  7.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3288/3750 [07:22<01:02,  7.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3290/3750 [07:22<01:01,  7.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3292/3750 [07:22<01:01,  7.43it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3294/3750 [07:22<01:01,  7.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3296/3750 [07:23<01:01,  7.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3298/3750 [07:23<01:00,  7.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3300/3750 [07:23<01:00,  7.44it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3302/3750 [07:23<01:00,  7.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3304/3750 [07:23<00:59,  7.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3306/3750 [07:23<00:59,  7.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3308/3750 [07:23<00:59,  7.45it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3310/3750 [07:23<00:59,  7.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3312/3750 [07:24<00:58,  7.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3314/3750 [07:24<00:58,  7.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3316/3750 [07:24<00:58,  7.46it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 3318/3750 [07:24<00:57,  7.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▊ | 3320/3750 [07:24<00:57,  7.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▊ | 3322/3750 [07:24<00:57,  7.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▊ | 3324/3750 [07:24<00:56,  7.47it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▊ | 3326/3750 [07:24<00:56,  7.48it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▊ | 3328/3750 [07:24<00:56,  7.48it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3330/3750 [07:25<00:56,  7.48it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3332/3750 [07:25<00:55,  7.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3334/3750 [07:25<00:55,  7.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3336/3750 [07:25<00:55,  7.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3338/3750 [07:25<00:54,  7.49it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3340/3750 [07:25<00:54,  7.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3342/3750 [07:25<00:54,  7.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3344/3750 [07:25<00:54,  7.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3346/3750 [07:25<00:53,  7.50it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3348/3750 [07:26<00:53,  7.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3350/3750 [07:26<00:53,  7.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3352/3750 [07:26<00:52,  7.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3354/3750 [07:26<00:52,  7.51it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  89%|████████▉ | 3356/3750 [07:26<00:52,  7.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|████████▉ | 3358/3750 [07:26<00:52,  7.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|████████▉ | 3360/3750 [07:26<00:51,  7.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|████████▉ | 3362/3750 [07:26<00:51,  7.52it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|████████▉ | 3364/3750 [07:26<00:51,  7.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|████████▉ | 3366/3750 [07:27<00:51,  7.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|████████▉ | 3368/3750 [07:27<00:50,  7.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|████████▉ | 3370/3750 [07:27<00:50,  7.53it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|████████▉ | 3372/3750 [07:27<00:50,  7.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|████████▉ | 3374/3750 [07:27<00:49,  7.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|█████████ | 3376/3750 [07:27<00:49,  7.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|█████████ | 3378/3750 [07:27<00:49,  7.54it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|█████████ | 3380/3750 [07:27<00:49,  7.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|█████████ | 3382/3750 [07:27<00:48,  7.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|█████████ | 3384/3750 [07:28<00:48,  7.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|█████████ | 3386/3750 [07:28<00:48,  7.55it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|█████████ | 3388/3750 [07:28<00:47,  7.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|█████████ | 3390/3750 [07:28<00:47,  7.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  90%|█████████ | 3392/3750 [07:28<00:47,  7.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3394/3750 [07:28<00:47,  7.56it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3396/3750 [07:28<00:46,  7.57it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3398/3750 [07:28<00:46,  7.57it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3400/3750 [07:28<00:46,  7.57it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3402/3750 [07:29<00:45,  7.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3404/3750 [07:29<00:45,  7.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3406/3750 [07:29<00:45,  7.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3408/3750 [07:29<00:45,  7.58it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3410/3750 [07:29<00:44,  7.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3412/3750 [07:29<00:44,  7.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3414/3750 [07:29<00:44,  7.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3416/3750 [07:29<00:43,  7.59it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3418/3750 [07:30<00:43,  7.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 3420/3750 [07:30<00:43,  7.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████▏| 3422/3750 [07:30<00:43,  7.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████▏| 3424/3750 [07:30<00:42,  7.60it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████▏| 3426/3750 [07:30<00:42,  7.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████▏| 3428/3750 [07:30<00:42,  7.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  91%|█████████▏| 3430/3750 [07:30<00:42,  7.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3432/3750 [07:30<00:41,  7.61it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3434/3750 [07:30<00:41,  7.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3436/3750 [07:31<00:41,  7.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3438/3750 [07:31<00:40,  7.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3440/3750 [07:31<00:40,  7.62it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3442/3750 [07:31<00:40,  7.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3444/3750 [07:31<00:40,  7.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3446/3750 [07:31<00:39,  7.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3448/3750 [07:31<00:39,  7.63it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3450/3750 [07:31<00:39,  7.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3452/3750 [07:31<00:39,  7.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3454/3750 [07:32<00:38,  7.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3456/3750 [07:32<00:38,  7.64it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3458/3750 [07:32<00:38,  7.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3460/3750 [07:32<00:37,  7.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3462/3750 [07:32<00:37,  7.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3464/3750 [07:32<00:37,  7.65it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3466/3750 [07:32<00:37,  7.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 3468/3750 [07:32<00:36,  7.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3470/3750 [07:32<00:36,  7.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3472/3750 [07:33<00:36,  7.66it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3474/3750 [07:33<00:36,  7.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3476/3750 [07:33<00:35,  7.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3478/3750 [07:33<00:35,  7.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3480/3750 [07:33<00:35,  7.67it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3482/3750 [07:33<00:34,  7.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3484/3750 [07:33<00:34,  7.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3486/3750 [07:33<00:34,  7.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3488/3750 [07:33<00:34,  7.68it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3490/3750 [07:34<00:33,  7.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3492/3750 [07:34<00:33,  7.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3494/3750 [07:34<00:33,  7.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3496/3750 [07:34<00:33,  7.69it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3498/3750 [07:34<00:32,  7.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3500/3750 [07:34<00:32,  7.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3502/3750 [07:34<00:32,  7.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3504/3750 [07:34<00:31,  7.70it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  93%|█████████▎| 3506/3750 [07:34<00:31,  7.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▎| 3508/3750 [07:35<00:31,  7.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▎| 3510/3750 [07:35<00:31,  7.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▎| 3512/3750 [07:35<00:30,  7.71it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▎| 3514/3750 [07:35<00:30,  7.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3516/3750 [07:35<00:30,  7.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3518/3750 [07:35<00:30,  7.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3520/3750 [07:35<00:29,  7.72it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3522/3750 [07:35<00:29,  7.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3524/3750 [07:35<00:29,  7.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3526/3750 [07:36<00:28,  7.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3528/3750 [07:36<00:28,  7.73it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3530/3750 [07:36<00:28,  7.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3532/3750 [07:36<00:28,  7.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3534/3750 [07:36<00:27,  7.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3536/3750 [07:36<00:27,  7.74it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3538/3750 [07:36<00:27,  7.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3540/3750 [07:36<00:27,  7.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 3542/3750 [07:37<00:26,  7.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▍| 3544/3750 [07:37<00:26,  7.75it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▍| 3546/3750 [07:37<00:26,  7.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▍| 3548/3750 [07:37<00:26,  7.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▍| 3550/3750 [07:37<00:25,  7.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▍| 3552/3750 [07:37<00:25,  7.76it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▍| 3554/3750 [07:37<00:25,  7.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▍| 3556/3750 [07:37<00:24,  7.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▍| 3558/3750 [07:37<00:24,  7.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▍| 3560/3750 [07:38<00:24,  7.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▍| 3562/3750 [07:38<00:24,  7.77it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▌| 3564/3750 [07:38<00:23,  7.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▌| 3566/3750 [07:38<00:23,  7.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▌| 3568/3750 [07:38<00:23,  7.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▌| 3570/3750 [07:38<00:23,  7.78it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▌| 3572/3750 [07:38<00:22,  7.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▌| 3574/3750 [07:38<00:22,  7.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▌| 3576/3750 [07:38<00:22,  7.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▌| 3578/3750 [07:39<00:22,  7.79it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  95%|█████████▌| 3580/3750 [07:39<00:21,  7.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3582/3750 [07:39<00:21,  7.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3584/3750 [07:39<00:21,  7.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3586/3750 [07:39<00:21,  7.80it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3588/3750 [07:39<00:20,  7.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3590/3750 [07:39<00:20,  7.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3592/3750 [07:39<00:20,  7.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3594/3750 [07:39<00:19,  7.81it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3596/3750 [07:40<00:19,  7.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3598/3750 [07:40<00:19,  7.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3600/3750 [07:40<00:19,  7.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3602/3750 [07:40<00:18,  7.82it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3604/3750 [07:40<00:18,  7.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3606/3750 [07:40<00:18,  7.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 3608/3750 [07:40<00:18,  7.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▋| 3610/3750 [07:40<00:17,  7.83it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▋| 3612/3750 [07:40<00:17,  7.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▋| 3614/3750 [07:41<00:17,  7.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▋| 3616/3750 [07:41<00:17,  7.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  96%|█████████▋| 3618/3750 [07:41<00:16,  7.84it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3620/3750 [07:41<00:16,  7.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3622/3750 [07:41<00:16,  7.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3624/3750 [07:41<00:16,  7.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3626/3750 [07:41<00:15,  7.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3628/3750 [07:41<00:15,  7.85it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3630/3750 [07:41<00:15,  7.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3632/3750 [07:42<00:15,  7.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3634/3750 [07:42<00:14,  7.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3636/3750 [07:42<00:14,  7.86it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3638/3750 [07:42<00:14,  7.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3640/3750 [07:42<00:13,  7.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3642/3750 [07:42<00:13,  7.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3644/3750 [07:42<00:13,  7.87it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3646/3750 [07:42<00:13,  7.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3648/3750 [07:43<00:12,  7.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3650/3750 [07:43<00:12,  7.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3652/3750 [07:43<00:12,  7.88it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3654/3750 [07:43<00:12,  7.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 3656/3750 [07:43<00:11,  7.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3658/3750 [07:43<00:11,  7.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3660/3750 [07:43<00:11,  7.89it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3662/3750 [07:43<00:11,  7.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3664/3750 [07:43<00:10,  7.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3666/3750 [07:44<00:10,  7.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3668/3750 [07:44<00:10,  7.90it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3670/3750 [07:44<00:10,  7.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3672/3750 [07:44<00:09,  7.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3674/3750 [07:44<00:09,  7.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3676/3750 [07:44<00:09,  7.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3678/3750 [07:44<00:09,  7.91it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3680/3750 [07:44<00:08,  7.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3682/3750 [07:44<00:08,  7.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3684/3750 [07:45<00:08,  7.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3686/3750 [07:45<00:08,  7.92it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3688/3750 [07:45<00:07,  7.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3690/3750 [07:45<00:07,  7.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  98%|█████████▊| 3692/3750 [07:45<00:07,  7.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▊| 3694/3750 [07:45<00:07,  7.93it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▊| 3696/3750 [07:45<00:06,  7.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▊| 3698/3750 [07:45<00:06,  7.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▊| 3700/3750 [07:45<00:06,  7.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▊| 3702/3750 [07:46<00:06,  7.94it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3704/3750 [07:46<00:05,  7.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3706/3750 [07:46<00:05,  7.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3708/3750 [07:46<00:05,  7.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3710/3750 [07:46<00:05,  7.95it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3712/3750 [07:46<00:04,  7.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3714/3750 [07:46<00:04,  7.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3716/3750 [07:46<00:04,  7.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3718/3750 [07:46<00:04,  7.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3720/3750 [07:47<00:03,  7.96it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3722/3750 [07:47<00:03,  7.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3724/3750 [07:47<00:03,  7.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3726/3750 [07:47<00:03,  7.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3728/3750 [07:47<00:02,  7.97it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 3730/3750 [07:47<00:02,  7.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|█████████▉| 3732/3750 [07:47<00:02,  7.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|█████████▉| 3734/3750 [07:47<00:02,  7.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|█████████▉| 3736/3750 [07:47<00:01,  7.98it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|█████████▉| 3738/3750 [07:48<00:01,  7.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|█████████▉| 3740/3750 [07:48<00:01,  7.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|█████████▉| 3742/3750 [07:48<00:01,  7.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|█████████▉| 3744/3750 [07:48<00:00,  7.99it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|█████████▉| 3746/3750 [07:48<00:00,  8.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|█████████▉| 3748/3750 [07:48<00:00,  8.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|██████████| 3750/3750 [07:48<00:00,  8.00it/s, loss=0.0849, v_num=0]\n",
      "Epoch 2: 100%|██████████| 3750/3750 [07:50<00:00,  7.98it/s, loss=0.0849, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nan0hu-nj5Zm"
   },
   "source": [
    "## Load the Stored Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T13:03:06.550253Z",
     "iopub.status.busy": "2024-02-27T13:03:06.549917Z",
     "iopub.status.idle": "2024-02-27T13:03:08.694709Z",
     "shell.execute_reply": "2024-02-27T13:03:08.694174Z",
     "shell.execute_reply.started": "2024-02-27T13:03:06.550225Z"
    },
    "id": "27yNiUp_W1pn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.load_from_checkpoint(\"/mnt/workspace/ORL/lightning_logs/version_0/checkpoints/epoch=2-step=470.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T13:03:16.977947Z",
     "iopub.status.busy": "2024-02-27T13:03:16.977623Z",
     "iopub.status.idle": "2024-02-27T13:03:24.844373Z",
     "shell.execute_reply": "2024-02-27T13:03:24.843720Z",
     "shell.execute_reply.started": "2024-02-27T13:03:16.977926Z"
    },
    "id": "-yVoc97oPged",
    "outputId": "06ddd83e-dae5-43f4-b585-fd1056192d07",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pai/envs/T5/lib/python3.9/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: calhoun city , mississippi\n",
      "\n",
      "Actual Entities: loc: calhoun city , mississippi\n",
      "Predicted Entities: loc: calhoun city , mississippi\n",
      "=====================================================================\n",
      "\n",
      "text: honorary fellow of the american institute of architects ( 1993 ) and of the royal institute of\n",
      "british architects ( 1995 ) .\n",
      "\n",
      "Actual Entities: org: american institute of architects; org: royal institute of british architects\n",
      "Predicted Entities: org: american institute of architects; org: royal institute of british architects\n",
      "=====================================================================\n",
      "\n",
      "text: museo di storia naturale di venezia , venice\n",
      "\n",
      "Actual Entities: org: museo di storia naturale di venezia; loc: venice\n",
      "Predicted Entities: loc: museo di storia naturale di venezia\n",
      "=====================================================================\n",
      "\n",
      "text: edgar allan poe in popular culture\n",
      "\n",
      "Actual Entities: org: edgar allan poe in popular culture\n",
      "Predicted Entities: per: edgar allan poe in popular culture\n",
      "=====================================================================\n",
      "\n",
      "text: '' shine my shoes ''\n",
      "\n",
      "Actual Entities: org: shine my shoes\n",
      "Predicted Entities: org: shine my shoes\n",
      "=====================================================================\n",
      "\n",
      "text: värmlands län , seat no .\n",
      "\n",
      "Actual Entities: org: värmlands län\n",
      "Predicted Entities: loc: värmlands län\n",
      "=====================================================================\n",
      "\n",
      "text: their first retail store was set up at shaw house and centre on scotts road .\n",
      "\n",
      "Actual Entities: org: shaw house and centre; loc: scotts road\n",
      "Predicted Entities: org: shaw house and centre; loc: scotts road\n",
      "=====================================================================\n",
      "\n",
      "text: on 28 july 2006 , it was sold to air greenland .\n",
      "\n",
      "Actual Entities: org: air greenland\n",
      "Predicted Entities: org: air greenland\n",
      "=====================================================================\n",
      "\n",
      "text: buchanan 's birthplace state park ( franklin county )\n",
      "\n",
      "Actual Entities: org: buchanan 's birthplace state park; loc: franklin county\n",
      "Predicted Entities: loc: buchanan 's birthplace state park; loc: frankli\n",
      "=====================================================================\n",
      "\n",
      "text: *american singer-guitarist glen campbell covered the song on his 12th album wichita lineman ''\n",
      ", released in 1968 by capitol records .\n",
      "\n",
      "Actual Entities: per: glen campbell; org: wichita lineman; org: capitol records\n",
      "Predicted Entities: per: glen campbell; org: wichita lineman;\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "dataloader = DataLoader(input_dataset, batch_size=32, num_workers=2, shuffle=True)\n",
    "model.model.eval()\n",
    "model = model.to(\"cpu\")\n",
    "outputs = []\n",
    "targets = []\n",
    "texts = []\n",
    "for batch in dataloader:\n",
    "\n",
    "    outs = model.model.generate(input_ids=batch['source_ids'],\n",
    "                                attention_mask=batch['source_mask'])\n",
    "    dec = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip() for ids in outs]\n",
    "    target = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"target_ids\"]]\n",
    "    text = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"source_ids\"]]\n",
    "    texts.extend(text)\n",
    "    outputs.extend(dec)\n",
    "    targets.extend(target)\n",
    "    break\n",
    "\n",
    "for i in range(10):\n",
    "    c = texts[i]\n",
    "    lines = textwrap.wrap(\"text:\\n%s\\n\" % c, width=100)\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nActual Entities: %s\" % target[i])\n",
    "    print(\"Predicted Entities: %s\" % outputs[i])\n",
    "    print(\"=====================================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T13:04:07.805434Z",
     "iopub.status.busy": "2024-02-27T13:04:07.805085Z",
     "iopub.status.idle": "2024-02-27T13:04:07.811701Z",
     "shell.execute_reply": "2024-02-27T13:04:07.811208Z",
     "shell.execute_reply.started": "2024-02-27T13:04:07.805408Z"
    },
    "id": "Q358Ph_JUeSA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_sub_list(sl, l):\n",
    "    results = []\n",
    "    sll = len(sl)\n",
    "    for ind in (i for i, e in enumerate(l) if e == sl[0]):\n",
    "        if l[ind:ind+sll] == sl:\n",
    "            results.append((ind, ind+sll-1))\n",
    "    return results\n",
    "\n",
    "def generate_label(input: str, target: str):\n",
    "    mapper = {'O': 0, 'B-DATE': 1, 'I-DATE': 2, 'B-PER': 3,\n",
    "              'I-PER': 4, 'B-ORG': 5, 'I-ORG': 6, 'B-LOC': 7, 'I-LOC': 8}\n",
    "    inv_mapper = {v: k for k, v in mapper.items()}\n",
    "\n",
    "    input = input.split(\" \")\n",
    "    target = target.split(\"; \")\n",
    "\n",
    "    init_target_label = [mapper['O']]*len(input)\n",
    "\n",
    "    for ent in target:\n",
    "        ent = ent.split(\": \")\n",
    "        try:\n",
    "            sent_end = ent[1].split(\" \")\n",
    "            index = find_sub_list(sent_end, input)\n",
    "        except:\n",
    "            continue\n",
    "        # print(index)\n",
    "        try:\n",
    "            init_target_label[index[0][0]] = mapper[f\"B-{ent[0].upper()}\"]\n",
    "            for i in range(index[0][0]+1, index[0][1]+1):\n",
    "                init_target_label[i] = mapper[f\"I-{ent[0].upper()}\"]\n",
    "        except:\n",
    "            continue\n",
    "    init_target_label = [inv_mapper[j] for j in init_target_label]\n",
    "    return init_target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T13:04:11.030985Z",
     "iopub.status.busy": "2024-02-27T13:04:11.030664Z",
     "iopub.status.idle": "2024-02-27T13:05:34.504615Z",
     "shell.execute_reply": "2024-02-27T13:05:34.504054Z",
     "shell.execute_reply.started": "2024-02-27T13:04:11.030962Z"
    },
    "id": "s8b7-Y07T5qV",
    "outputId": "6ff28c77-103b-4a3a-f50b-0b3c1dbee16c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 313/313 [01:18<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "test_dataset = WikiAnnDataset(tokenizer=tokenizer, dataset=dataset, type_path='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=32,\n",
    "                             num_workers=2, shuffle=True)\n",
    "model.model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "outputs = []\n",
    "targets = []\n",
    "all_text = []\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "for batch in tqdm(test_loader):\n",
    "    input_ids = batch['source_ids'].to(\"cuda\")\n",
    "    attention_mask = batch['source_mask'].to(\"cuda\")\n",
    "    outs = model.model.generate(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "    dec = [tokenizer.decode(ids, skip_special_tokens=True,\n",
    "                            clean_up_tokenization_spaces=False).strip() for ids in outs]\n",
    "    target = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"target_ids\"]]\n",
    "    texts = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"source_ids\"]]\n",
    "    true_label = [generate_label(texts[i].strip(), target[i].strip()) if target[i].strip() != 'none' else [\n",
    "        \"O\"]*len(texts[i].strip().split()) for i in range(len(texts))]\n",
    "    pred_label = [generate_label(texts[i].strip(), dec[i].strip()) if dec[i].strip() != 'none' else [\n",
    "        \"O\"]*len(texts[i].strip().split()) for i in range(len(texts))]\n",
    "\n",
    "    outputs.extend(dec)\n",
    "    targets.extend(target)\n",
    "    true_labels.extend(true_label)\n",
    "    pred_labels.extend(pred_label)\n",
    "    all_text.extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T13:05:43.154403Z",
     "iopub.status.busy": "2024-02-27T13:05:43.154049Z",
     "iopub.status.idle": "2024-02-27T13:05:43.159246Z",
     "shell.execute_reply": "2024-02-27T13:05:43.158785Z",
     "shell.execute_reply.started": "2024-02-27T13:05:43.154377Z"
    },
    "id": "MTDdTHwdadFx",
    "outputId": "845d8b90-cd00-490e-f0a9-96d71eff167e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"orguss '' - additional voices\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T13:06:23.049881Z",
     "iopub.status.busy": "2024-02-27T13:06:23.049554Z",
     "iopub.status.idle": "2024-02-27T13:06:28.187486Z",
     "shell.execute_reply": "2024-02-27T13:06:28.186898Z",
     "shell.execute_reply.started": "2024-02-27T13:06:23.049861Z"
    },
    "id": "ZrFA-BSHerhf",
    "outputId": "3df4f246-e26e-46ff-dd92-cf5a6da5cc4f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/T5/lib/python3.9/site-packages/datasets/load.py:753: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.1/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  reginald beckwith as kenniston .\n",
      "Predicted Token Class:  ['B-PER', 'I-PER', 'O', 'B-PER', 'O']\n",
      "True Token Class:  ['B-PER', 'I-PER', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  orguss '' - additional voices\n",
      "Predicted Token Class:  ['B-ORG', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['B-ORG', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  dihedral symmetry groups with even-orders have a number of subgroups .\n",
      "Predicted Token Class:  ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  council of southern africa football associations\n",
      "Predicted Token Class:  ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']\n",
      "True Token Class:  ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']\n",
      "=====================================================================\n",
      "\n",
      "Text:  he died in 1924 and was buried in the hôtel des invalides .\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  paul warren rieger .\n",
      "Predicted Token Class:  ['B-PER', 'I-PER', 'I-PER', 'O']\n",
      "True Token Class:  ['B-PER', 'I-PER', 'I-PER', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  diggy liggy lo '' ( j. d. miller ) – 2:16\n",
      "Predicted Token Class:  ['B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  '' pereza '' '\n",
      "Predicted Token Class:  ['O', 'B-LOC', 'O', 'O']\n",
      "True Token Class:  ['O', 'B-ORG', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "Text:  atkinson , new hampshire\n",
      "Predicted Token Class:  ['B-LOC', 'I-LOC', 'I-LOC', 'I-LOC']\n",
      "True Token Class:  ['B-LOC', 'I-LOC', 'I-LOC', 'I-LOC']\n",
      "=====================================================================\n",
      "\n",
      "Text:  san diego county , california\n",
      "Predicted Token Class:  ['B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC']\n",
      "True Token Class:  ['B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC']\n",
      "=====================================================================\n",
      "\n",
      "{'LOC': {'precision': 0.7034047919293821, 'recall': 0.6028966709900562, 'f1': 0.6492841345594227, 'number': 4626}, 'ORG': {'precision': 0.6855995410212278, 'recall': 0.5156418554476807, 'f1': 0.5885974633665805, 'number': 4635}, 'PER': {'precision': 0.7557732680195941, 'recall': 0.7139709122961657, 'f1': 0.7342776203966006, 'number': 4538}, 'overall_precision': 0.7172431419321861, 'overall_recall': 0.6101166751213856, 'overall_f1': 0.6593570113952305, 'overall_accuracy': 0.8310771188661119}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Text:  {all_text[i]}\")\n",
    "    print(f\"Predicted Token Class:  {pred_labels[i]}\")\n",
    "    print(f\"True Token Class:  {true_labels[i]}\")\n",
    "    print(\"=====================================================================\\n\")\n",
    "\n",
    "print(metric.compute(predictions=pred_labels, references=true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sF7loiUFVbQM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "T5",
   "language": "python",
   "name": "t5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "005a930db3d242a4be28a9c5923eed76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0305993a3c1a4f8296faeb1aba61fa38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0573bd35717d4189ab4d74fdc489653b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bd7b7a9f5f80492997ec2cbd4bf22627",
       "IPY_MODEL_1b08c691a8db4cb79e6f7837a08ac799",
       "IPY_MODEL_b904bbebe38943728a23a0d630f86a88"
      ],
      "layout": "IPY_MODEL_06e6627b73a24e4291f316a281a20aea"
     }
    },
    "06e6627b73a24e4291f316a281a20aea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "0e46dd857d504def992f555a9e9c9c5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "127c67d7658d4bf392408e7d5600a09c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b08c691a8db4cb79e6f7837a08ac799": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f69895f136a14e629614a45f2e7d8557",
      "max": 1250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cfcb95376da04ce884ab18c57c2d63ed",
      "value": 1250
     }
    },
    "1fac6af61b4d411a94f3916061731428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20d7306a9b474da3b0c8e80a3d7abe09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_264fdba12e854d54b3ed2510458c7a1b",
      "placeholder": "​",
      "style": "IPY_MODEL_95d7c71216094ea0b466a79efc95341d",
      "value": " 1250/1250 [02:30&lt;00:00,  8.20it/s]"
     }
    },
    "21b88aca18f048759fb25ce63540c992": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25b71debb82040a2960eb8348df2a4ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "264fdba12e854d54b3ed2510458c7a1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285649e2ae134f87bd2f8dcf40a7758d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3e24f0b77884455868b103ab69ddd5d",
      "placeholder": "​",
      "style": "IPY_MODEL_c3c43f7938044239b4eca004d07874ae",
      "value": "100%"
     }
    },
    "304c605d63584a298e8cefd4ffcf4ead": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfdd904fb4924ad8948793222255cc3b",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d88a23982ac46b3b8077264a6998b9a",
      "value": 3
     }
    },
    "347f2c97cd4f46aa8bd1d30f79041b29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37a7f3f9244a4fd991fe9e8847268ec1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fce9ba2896164d4391fea7f32dc3d811",
      "placeholder": "​",
      "style": "IPY_MODEL_0305993a3c1a4f8296faeb1aba61fa38",
      "value": " 1250/1250 [02:30&lt;00:00,  8.20it/s]"
     }
    },
    "388d8e1e34a143c3afe9e4082be44ebb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3898654592194daca51999f513192a24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39ceb75a4fa14f6e9a8a5f4ae1324cbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4bba40ddade644b79cce613925a4f47e",
       "IPY_MODEL_aa38ae45e85545bebec6c8b43db7abbf",
       "IPY_MODEL_37a7f3f9244a4fd991fe9e8847268ec1"
      ],
      "layout": "IPY_MODEL_49901550f7c14e439505f80faaaa8357"
     }
    },
    "3b924323276f4f92a66a64d295ba6c78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ddd6cf350fb4378ad6cf2698f67d68f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21b88aca18f048759fb25ce63540c992",
      "placeholder": "​",
      "style": "IPY_MODEL_3b924323276f4f92a66a64d295ba6c78",
      "value": "Validating: 100%"
     }
    },
    "429fbc36c65446d09d32298cfc4b606e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43278de125c54c1e8b55baa0370c4cc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45340f3b0bf4413182060f27c7458334": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f16174670d2c4182ace507dda7812328",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_966b77941ef046babfb1e9ed597a6aee",
      "value": 3
     }
    },
    "47144694b20f49f0aa54ee1d83119fda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48bb2d6d069e411a9e969187d5ddf17d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81211b58e69b4973a9e1b500e621656b",
      "placeholder": "​",
      "style": "IPY_MODEL_347f2c97cd4f46aa8bd1d30f79041b29",
      "value": "Epoch 2: 100%"
     }
    },
    "49901550f7c14e439505f80faaaa8357": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "4b15ff3c6b044b40a15b21f051bf53c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "4bba40ddade644b79cce613925a4f47e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce10ff94a3454674a5deb511394387ff",
      "placeholder": "​",
      "style": "IPY_MODEL_b537afbec50e4567885220cf27a5b761",
      "value": "Validating: 100%"
     }
    },
    "4fb2b190729943cb8c1f1fd2b84d6935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fffbd7c89314024a7b8c128ad1ba248": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d4e33c5404f49caa4811bfd55b0bee5",
      "max": 3750,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce97e8d1d6b54e17a16ec75e1b3abf7f",
      "value": 3750
     }
    },
    "5587ced0255640dd9bec68478cd973fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "56496f0e8cef4b5cb989f289af418f9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d4e33c5404f49caa4811bfd55b0bee5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d88a23982ac46b3b8077264a6998b9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5fd2178313d34631a030d79934dcffe0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4dc2a989d794b44b8000ca88cf095fa",
      "placeholder": "​",
      "style": "IPY_MODEL_b449b3c3b1b944a38293f2f13d517860",
      "value": " 3/3 [00:00&lt;00:00, 64.65it/s]"
     }
    },
    "6bf0078bd11d4ed980f1b7a9b612a091": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbcd62725c684fcc897583042ca44888",
      "placeholder": "​",
      "style": "IPY_MODEL_e61579f72d51414782f8fe3c28e12e86",
      "value": " 3/3 [00:00&lt;00:00, 73.09it/s]"
     }
    },
    "79385887dd0f479d993b251748f8cb2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ca93c1fe9a9415e9c7d6f22a58b90d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa0489927bdd4bf4809c9fcc92d9d7b4",
      "placeholder": "​",
      "style": "IPY_MODEL_43278de125c54c1e8b55baa0370c4cc1",
      "value": " 3/3 [00:00&lt;00:00, 48.52it/s]"
     }
    },
    "81211b58e69b4973a9e1b500e621656b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83ec7a9ea11e410bb3fcad13c082d664": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_429fbc36c65446d09d32298cfc4b606e",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79385887dd0f479d993b251748f8cb2f",
      "value": 3
     }
    },
    "84ab2eb4f0b74ac3a334eb7ecd7c4d63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "84c7612e3ed740958159eec4ee147476": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93c2ea7279794b88b6264f832400e3c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5a571c48de54900b2b696f2c6817a2e",
      "placeholder": "​",
      "style": "IPY_MODEL_4fb2b190729943cb8c1f1fd2b84d6935",
      "value": "100%"
     }
    },
    "9428191170994f0aa7fd400caf0d1d07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95d7c71216094ea0b466a79efc95341d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "966b77941ef046babfb1e9ed597a6aee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "97e269fbcb954d629b2314d30c41c57b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_93c2ea7279794b88b6264f832400e3c7",
       "IPY_MODEL_45340f3b0bf4413182060f27c7458334",
       "IPY_MODEL_6bf0078bd11d4ed980f1b7a9b612a091"
      ],
      "layout": "IPY_MODEL_84c7612e3ed740958159eec4ee147476"
     }
    },
    "9cd468cf60c643db96d0cd35923c8258": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0a3db286a1843b293b1d3b944a3d33a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9428191170994f0aa7fd400caf0d1d07",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_25b71debb82040a2960eb8348df2a4ca",
      "value": 2
     }
    },
    "a5a571c48de54900b2b696f2c6817a2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa38ae45e85545bebec6c8b43db7abbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d26f30f1432e4f2ab1c53484b44989ee",
      "max": 1250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be10758757c1426c8779c6706a445ecd",
      "value": 1250
     }
    },
    "b112c9a8184d4b479fc0e59698789b43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebcc288979ff4cd5901e9223063751d1",
       "IPY_MODEL_304c605d63584a298e8cefd4ffcf4ead",
       "IPY_MODEL_7ca93c1fe9a9415e9c7d6f22a58b90d1"
      ],
      "layout": "IPY_MODEL_e550224ab580420cb4973b805c2393af"
     }
    },
    "b3e24f0b77884455868b103ab69ddd5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b449b3c3b1b944a38293f2f13d517860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b537afbec50e4567885220cf27a5b761": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b58e5e54e53e46d7a4f196a93812373c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b849b43f5c4649deb018fb959191edc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b904bbebe38943728a23a0d630f86a88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3898654592194daca51999f513192a24",
      "placeholder": "​",
      "style": "IPY_MODEL_47144694b20f49f0aa54ee1d83119fda",
      "value": " 1250/1250 [02:30&lt;00:00,  8.22it/s]"
     }
    },
    "ba1298c2f3db42c48b7e3e3ee83d5000": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_285649e2ae134f87bd2f8dcf40a7758d",
       "IPY_MODEL_83ec7a9ea11e410bb3fcad13c082d664",
       "IPY_MODEL_5fd2178313d34631a030d79934dcffe0"
      ],
      "layout": "IPY_MODEL_0e46dd857d504def992f555a9e9c9c5f"
     }
    },
    "ba6f4922558c41fea4a4b171a021b871": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48bb2d6d069e411a9e969187d5ddf17d",
       "IPY_MODEL_4fffbd7c89314024a7b8c128ad1ba248",
       "IPY_MODEL_dea06faaa22b41b6bbfd7ff6d8ee39f6"
      ],
      "layout": "IPY_MODEL_5587ced0255640dd9bec68478cd973fb"
     }
    },
    "bd7b7a9f5f80492997ec2cbd4bf22627": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cddc7d98bbb740a9a81bf8e244d4595d",
      "placeholder": "​",
      "style": "IPY_MODEL_9cd468cf60c643db96d0cd35923c8258",
      "value": "Validating: 100%"
     }
    },
    "be10758757c1426c8779c6706a445ecd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c3c43f7938044239b4eca004d07874ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4dc2a989d794b44b8000ca88cf095fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cddc7d98bbb740a9a81bf8e244d4595d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce10ff94a3454674a5deb511394387ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce97e8d1d6b54e17a16ec75e1b3abf7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ceca8a9a02fe46d5a1a3aa093fdbcde7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b849b43f5c4649deb018fb959191edc5",
      "max": 1250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b58e5e54e53e46d7a4f196a93812373c",
      "value": 1250
     }
    },
    "cfcb95376da04ce884ab18c57c2d63ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d26f30f1432e4f2ab1c53484b44989ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2b327e2b0074354a6b889afc169a62e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f8ebf6d2f2954cbbb525e67de58a766a",
       "IPY_MODEL_a0a3db286a1843b293b1d3b944a3d33a",
       "IPY_MODEL_d68d5a7c97bd47719eb1e19f67d64805"
      ],
      "layout": "IPY_MODEL_84ab2eb4f0b74ac3a334eb7ecd7c4d63"
     }
    },
    "d37bf18a5e9346fcb59242e0e5288307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d68d5a7c97bd47719eb1e19f67d64805": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dffd33c1015f4bfd91fd702095c2127e",
      "placeholder": "​",
      "style": "IPY_MODEL_ef4fa30c44df4726a36cfc1da100fb4f",
      "value": " 2/2 [00:00&lt;00:00,  3.48it/s]"
     }
    },
    "dbcd62725c684fcc897583042ca44888": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dea06faaa22b41b6bbfd7ff6d8ee39f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_005a930db3d242a4be28a9c5923eed76",
      "placeholder": "​",
      "style": "IPY_MODEL_d37bf18a5e9346fcb59242e0e5288307",
      "value": " 3750/3750 [15:58&lt;00:00,  3.91it/s, loss=0.103, v_num=0]"
     }
    },
    "dfdd904fb4924ad8948793222255cc3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dffd33c1015f4bfd91fd702095c2127e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e550224ab580420cb4973b805c2393af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e61579f72d51414782f8fe3c28e12e86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebcc288979ff4cd5901e9223063751d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_388d8e1e34a143c3afe9e4082be44ebb",
      "placeholder": "​",
      "style": "IPY_MODEL_56496f0e8cef4b5cb989f289af418f9f",
      "value": "100%"
     }
    },
    "ef4fa30c44df4726a36cfc1da100fb4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f16174670d2c4182ace507dda7812328": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f69895f136a14e629614a45f2e7d8557": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8ebf6d2f2954cbbb525e67de58a766a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_127c67d7658d4bf392408e7d5600a09c",
      "placeholder": "​",
      "style": "IPY_MODEL_1fac6af61b4d411a94f3916061731428",
      "value": "Validation sanity check: 100%"
     }
    },
    "fa0489927bdd4bf4809c9fcc92d9d7b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fce9ba2896164d4391fea7f32dc3d811": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffe6027ef4bb4fd9964717116a39f1a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3ddd6cf350fb4378ad6cf2698f67d68f",
       "IPY_MODEL_ceca8a9a02fe46d5a1a3aa093fdbcde7",
       "IPY_MODEL_20d7306a9b474da3b0c8e80a3d7abe09"
      ],
      "layout": "IPY_MODEL_4b15ff3c6b044b40a15b21f051bf53c8"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
